- [1. Виды параллельной обработки данных, их особенности.](#1-виды-параллельной-обработки-данных-их-особенности)
- [2. Вычислительно сложные задачи. Примеры оценки вычислительной сложности школьных, научных и промышленных задач.](#2-вычислительно-сложные-задачи-примеры-оценки-вычислительной-сложности-школьных-научных-и-промышленных-задач)
- [3. Современные технологии и парадигмы решения задач с использованием суперкомпьютеров.](#3-современные-технологии-и-парадигмы-решения-задач-с-использованием-суперкомпьютеров)
- [4. Микроэлектроника и архитектура: оценка вклада в увеличение производительности компьютеров.](#4-микроэлектроника-и-архитектура-оценка-вклада-в-увеличение-производительности-компьютеров)
- [5. Архитектура и параметры суперкомпьютерных систем – лидеров списка Top500 (примеры): производительность, эффективность, энергопотребление, энергоэффективность, степень параллельности.](#5-архитектура-и-параметры-суперкомпьютерных-систем--лидеров-списка-top500-примеры-производительность-эффективность-энергопотребление-энергоэффективность-степень-параллельности)
- [6. Этапы решения задач на параллельных вычислительных системах. Пиковая и реальная производительность компьютеров. Понятие суперкомпьютерного кодизайна.](#6-этапы-решения-задач-на-параллельных-вычислительных-системах-пиковая-и-реальная-производительность-компьютеров-понятие-суперкомпьютерного-кодизайна)
- [7. Список Top500: принципы формирования, структура, параметры, рост производительности суперкомпьютерных систем, значения N и N1/2.](#7-список-top500-принципы-формирования-структура-параметры-рост-производительности-суперкомпьютерных-систем-значения-n-и-n12)
- [8. Иерархия памяти, локальность вычислений, локальность использования данных.](#8-иерархия-памяти-локальность-вычислений-локальность-использования-данных)
- [9. Закон Амдала, его следствия, суперлинейное ускорение.](#9-закон-амдала-его-следствия-суперлинейное-ускорение)
- [10. Показатели качества параллельных программ: ускорение, эффективность реализации, эффективность распараллеливания, масштабируемость.](#10-показатели-качества-параллельных-программ-ускорение-эффективность-реализации-эффективность-распараллеливания-масштабируемость)
- [11. Сильная масштабируемость, масштабируемость вширь, слабая масштабируемость. Функция изоэффективности.](#11-сильная-масштабируемость-масштабируемость-вширь-слабая-масштабируемость-функция-изоэффективности)
- [12. Классификация Флинна архитектур вычислительных систем.](#12-классификация-флинна-архитектур-вычислительных-систем)
- [13. Компьютеры с общей и распредёленной памятью. Две задачи параллельных вычислений.](#13-компьютеры-с-общей-и-распредёленной-памятью-две-задачи-параллельных-вычислений)
- [14. UMA, NUMA и ccNUMA архитектуры. Компьютеры Cm*, BBN Butterfly.](#14-uma-numa-и-ccnuma-архитектуры-компьютеры-cm-bbn-butterfly)
- [15. Общая структура ccNUMA компьютера на примере Hewlett-Packard Superdome.](#15-общая-структура-ccnuma-компьютера-на-примере-hewlett-packard-superdome)
- [16. Причины уменьшения производительности компьютеров с общей памятью.](#16-причины-уменьшения-производительности-компьютеров-с-общей-памятью)
- [17. Коммуникационные топологии. Длина критического пути, связность, сложность.](#17-коммуникационные-топологии-длина-критического-пути-связность-сложность)
- [18. Особенности компьютеров семейства CRAY XT: вычислительные узлы, процессорные элементы, коммуникационная сеть.](#18-особенности-компьютеров-семейства-cray-xt-вычислительные-узлы-процессорные-элементы-коммуникационная-сеть)
- [19. Особенности компьютеров семейства CRAY XT: аппаратная поддержка синхронизации параллельных процессов.](#19-особенности-компьютеров-семейства-cray-xt-аппаратная-поддержка-синхронизации-параллельных-процессов)
- [20. Вычислительные кластеры: узлы, коммуникационная сеть (латентность, пропускная способность), способы построения.](#20-вычислительные-кластеры-узлы-коммуникационная-сеть-латентность-пропускная-способность-способы-построения)
- [21. Архитектура суперкомпьютеров СКИФ МГУ «Чебышев», «Ломоносов» и «Ломоносов-2».](#21-архитектура-суперкомпьютеров-скиф-мгу-чебышев-ломоносов-и-ломоносов-2)
- [22. Топология коммуникационной сети «толстое дерево» (fat tree) на примере реализации в суперкомпьютерах СКИФ МГУ «Чебышёв» или «Ломоносов».](#22-топология-коммуникационной-сети-толстое-дерево-fat-tree-на-примере-реализации-в-суперкомпьютерах-скиф-мгу-чебышёв-или-ломоносов)
- [23. Причины уменьшения производительности компьютеров с распределённой памятью.](#23-причины-уменьшения-производительности-компьютеров-с-распределённой-памятью)
- [24. Соотношение между понятиями: функциональное устройство, команда (операция), компьютер и их характеристиками: скалярный, векторный, конвейерный.](#24-соотношение-между-понятиями-функциональное-устройство-команда-операция-компьютер-и-их-характеристиками-скалярный-векторный-конвейерный)
- [25. Векторизация программ, необходимые условия векторизации, препятствия для векторизации.](#25-векторизация-программ-необходимые-условия-векторизации-препятствия-для-векторизации)
- [26. Общая структура векторно-конвейерного компьютера на примере CRAY C90. Параллелизм в архитектуре компьютера CRAY C90.](#26-общая-структура-векторно-конвейерного-компьютера-на-примере-cray-c90-параллелизм-в-архитектуре-компьютера-cray-c90)
- [27. Суперкомпьютеры NEC SX-Aurora TSUBASA.](#27-суперкомпьютеры-nec-sx-aurora-tsubasa)
- [28. Элементы векторной обработки в современных компьютерах. Наборы инструкций MMX, SSE, AVX, AVX2, AVX-512, AltiVec, ARM SVE.](#28-элементы-векторной-обработки-в-современных-компьютерах-наборы-инструкций-mmx-sse-avx-avx2-avx-512-altivec-arm-sve)
- [29. Причины уменьшения производительности векторно-конвейерных компьютеров.](#29-причины-уменьшения-производительности-векторно-конвейерных-компьютеров)
- [30. Метакомпьютер и метакомпьютинг. Отличительные свойства распределенных вычислительных сред.](#30-метакомпьютер-и-метакомпьютинг-отличительные-свойства-распределенных-вычислительных-сред)
- [31. Параллелизм на уровне машинных команд. Суперскалярность, VLIW, EPIC.](#31-параллелизм-на-уровне-машинных-команд-суперскалярность-vliw-epic)
- [32. Производительность вычислительных систем, методы оценки и измерения.](#32-производительность-вычислительных-систем-методы-оценки-и-измерения)
- [33. Технологии параллельного программирования: способы и подходы создания параллельных программ.](#33-технологии-параллельного-программирования-способы-и-подходы-создания-параллельных-программ)
- [34. MPI: параллельная программа, сообщение, понятия групп и коммуникаторов.](#34-mpi-параллельная-программа-сообщение-понятия-групп-и-коммуникаторов)
- [35. MPI: синхронное взаимодействие процессов, виды операторов Send (Bsend, Ssend, Rsend). Тупиковые ситуации.](#35-mpi-синхронное-взаимодействие-процессов-виды-операторов-send-bsend-ssend-rsend-тупиковые-ситуации)
- [36. MPI: асинхронное взаимодействие процессов.](#36-mpi-асинхронное-взаимодействие-процессов)
- [37. MPI: коллективные операции.](#37-mpi-коллективные-операции)
- [38. MPI: пересылка разнотипных данных, пересылка упакованных данных.](#38-mpi-пересылка-разнотипных-данных-пересылка-упакованных-данных)
- [39. OpenMP: параллельная программа, нити, конструкции для организации параллельных и последовательных секций.](#39-openmp-параллельная-программа-нити-конструкции-для-организации-параллельных-и-последовательных-секций)
- [40. OpenMP: основные конструкции для распределения работы между нитями.](#40-openmp-основные-конструкции-для-распределения-работы-между-нитями)
- [41. OpenMP: основные конструкции для синхронизации нитей и работы с общими и локальными данными.](#41-openmp-основные-конструкции-для-синхронизации-нитей-и-работы-с-общими-и-локальными-данными)
- [42. Графовые модели программ, их взаимосвязь.](#42-графовые-модели-программ-их-взаимосвязь)
- [43. Понятия информационной зависимости и информационной независимости: критерий эквивалентности преобразования программ, ресурс параллелизма программ и алгоритмов.](#43-понятия-информационной-зависимости-и-информационной-независимости-критерий-эквивалентности-преобразования-программ-ресурс-параллелизма-программ-и-алгоритмов)
- [44. Граф алгоритма. Взаимосвязь графа алгоритма и графовых моделей программ.](#44-граф-алгоритма-взаимосвязь-графа-алгоритма-и-графовых-моделей-программ)
- [45. Виды параллелизма: конечный, массовый, координатный, скошенный.](#45-виды-параллелизма-конечный-массовый-координатный-скошенный)
- [46. Ярусно-параллельная форма графа алгоритма, высота, ширина. Каноническая ЯПФ. Высота ЯПФ и длина критического пути графа алгоритма.](#46-ярусно-параллельная-форма-графа-алгоритма-высота-ширина-каноническая-япф-высота-япф-и-длина-критического-пути-графа-алгоритма)
- [47. Зависимость степени параллелизма от формы записи алгоритма (на примере реализации метода Гаусса).](#47-зависимость-степени-параллелизма-от-формы-записи-алгоритма-на-примере-реализации-метода-гаусса)


13 Компьютеры с общей и распредёленной памятью. Две задачи параллельных вычислений.
--------------------------------------------------
一、计算机按内存组织方式的两大类别  
I. Два класса компьютеров по организации памяти  
--------------------------------------------------
1. 共享内存系统（Shared-Memory, SMP/ccNUMA）  
   ‑ 所有 CPU 通过总线/交叉开关访问同一条物理地址空间  
   ‑ 通信 = 普通 load/store，编程简单，调试快  
   ‑ 瓶颈：总线带宽 & 缓存一致性 → CPU 数量≈数十颗  

   Системы с общей памятью (SMP/ccNUMA)  
   ‑ Все процессоры обращаются к единому физическому адресному пространству  
   ‑ Обмен данными через обычные операции чтения/записи; разработка и отладка проще  
   ‑ Ограничение: пропускная способность шины и когерентность кэшей → десятки ядер  

2. 分布式内存系统（Distributed-Memory, MPP/Cluster）  
   ‑ 每个节点 = CPU + 本地内存；节点间用高速网络或以太网互联  
   ‑ 远程数据只能显式收发消息（MPI/PVM）  
   ‑ 优点：可扩展至成千上万核；缺点：通信延迟高，编程复杂  

   Системы с распределённой памятью (MPP/кластер)  
   ‑ Узел = процессор + локальная память; соединение через высокоскоростную сеть  
   ‑ Доступ к чужим данным только через сообщения (MPI/PVM)  
   ‑ Плюс: линейный масштаб до тысяч ядер; минус: высокая задержка и сложная разработка  

--------------------------------------------------
二、并行计算永恒面对的“两大任务”  
II. Две основные задачи параллельных вычислений  
--------------------------------------------------
任务 1 · 极限性能 – “堆”出最高浮点能力  
├─ 手段：横向扩展（加节点）、提高网络带宽、优化拓扑  
├─ 代表：TOP500 上榜系统、云计算集群、甚至互联网本身  
└─ 关键瓶颈：节点间通信开销 → 需隐藏延迟、提升带宽  

Задача 1 · Максимальная производительность  
├─ Путь: горизонтальное масштабирование, увеличение пропускной способности сети  
├─ Примеры: системы TOP500, облачные кластеры, «Интернет как суперкомпьютер»  
└─ Главное препятствие: накладные расходы на обмен сообщениями → необходимо скрывать задержки  

任务 2 · 易用编程 – 让开发者轻松写出高效并行代码  
├─ 共享内存：OpenMP / Pthreads，逻辑简单，调试快，但 CPU 数量受限  
├─ 分布式：MPI/PVM，可扩展，却需手工分数据、管通信  
└─ 现代折中：节点内 OpenMP + 节点间 MPI，或 ccNUMA“逻辑共享、物理分布”  

Задача 2 · Удобное программирование  
├─ Shared-memory: OpenMP/Pthreads — проще отладка, но ограничено число ядер  
├─ Distributed: MPI/PVM — масштабно, но нужно вручную разбивать данные  
└─ Современный гибрид: внутри узла OpenMP, между узлами MPI; либо ccNUMA  

--------------------------------------------------
速记口诀 / Краткая формула  
--------------------------------------------------
“共享”易编程，难扩展；  
“分布”可扩展，难编程。  
两大任务：①堆性能 ②降开发难度。  

«Shared» — проще код, сложнее масштаб;  
«Distributed» — легко масштаб, сложен код.  
Две задачи: ① максимум FLOPS ② минимум усилий разработчика.




14 UMA, NUMA и ccNUMA архитектуры. Компьютеры Cm*, BBN Butterfly  
--------------------------------------------------
一、三种“内存访问距离”逐渐拉长的体系结构  
I. Три архитектуры с возрастающим «расстоянием» до памяти  
--------------------------------------------------
1. UMA（Uniform Memory Access）  
   ‑ 所有 CPU 通过单一总线或交叉开关访问“等距”的共享内存  
   ‑ 延迟一致，编程简单；瓶颈在总线带宽，规模≈几十核  

   UMA (однородный доступ к памяти)  
   ‑ Все процессоры через общую шину обращаются к памяти с одинаковой задержкой  
   ‑ Простота программирования; узкое место — шина, масштаб ограничен десятками ядер  

2. NUMA（Non-Uniform Memory Access）  
   ‑ 系统 = 多簇“CPU+本地内存”，簇间用高速互连；本地访问远快于远程  
   ‑ 地址空间统一，但速度“不均匀”；规模可扩展到上百 CPU  

   NUMA (неоднородный доступ к памяти)  
   ‑ Система состоит из кластеров «процессор + локальная память», связанных межкластерной шиной  
   ‑ Общее адресное пространство, но разная скорость доступа; масштаб до сотен процессоров  

3. ccNUMA（cache-coherent NUMA）  
   ‑ 在 NUMA 基础上由硬件协议自动保证各 CPU 缓存一致性  
   ‑ 程序员仍视其为“单一大内存”，内核数可扩至 256–1024，且无需改写 SMP 代码  

   ccNUMA (когерентная NUMA)  
   ‑ Аппаратно решается проблема когерентности кэшей; для программиста видна как единое пространство  
   ‑ Позволяет масштабироваться до 256–1024 ядер без изменения SMP-программ  




## 15. Общая структура ccNUMA компьютера на примере Hewlett-Packard Superdome  
--------------------------------------------------  
一、ccNUMA 架构的核心特征  
I. Основные характеристики архитектуры ccNUMA  
--------------------------------------------------  
1. 统一地址空间与非均匀内存访问  
   ‑ 所有 CPU 共享统一的物理地址空间，但访问延迟因内存位置不同而异  
   ‑ 访问本地内存延迟最低，访问其他 cell 的内存延迟较高，跨交换机延迟最高  
   ‑ 硬件自动解决缓存一致性问题，简化编程模型  

   Единое адресное пространство и неравномерный доступ к памяти  
   ‑ Все процессоры имеют доступ к единому физическому адресному пространству, но время доступа к памяти зависит от её местоположения  
   ‑ Минимальная задержка при доступе к локальной памяти, большая — к памяти в других ячейках, максимальная — через коммутаторы  
   ‑ Аппаратное обеспечение когерентности кэшей упрощает разработку  

2. 分层的系统架构  
   ‑ 基于 cell 的设计：每个 cell 包含 4 个处理器、本地内存和专用控制器  
   ‑ Cell 通过高速交叉开关连接，形成大规模并行系统  
   ‑ 系统可扩展到 64 个处理器，支持灵活的配置和扩展  

   Иерархическая архитектура системы  
   ‑ Архитектура на основе ячеек: каждая ячейка включает 4 процессора, локальную память и контроллер  
   ‑ Ячейки соединены высокоскоростными коммутаторами, образуя крупную параллельную систему  
   ‑ Возможность масштабирования до 64 процессоров с гибкой настройкой  

3. 高速互连与扩展性  
   ‑ 使用 8 GB/s 的全双工交叉开关连接 cell，确保高带宽和低延迟通信  
   ‑ 支持多机柜扩展，通过级联实现超过 64 个处理器的系统配置  
   ‑ 提供强大的 I/O 功能和热插拔支持，增强系统的可靠性和可用性  

   Высокоскоростное взаимосоединение и масштабируемость  
   ‑ Использование 8-ГБ/с полнодуплексных коммутаторов для соединения ячеек с низкой задержкой и высокой пропускной способностью  
   ‑ Возможность расширения за пределы одного шкафа, каскадное подключение для систем с более чем 64 процессорами  
   ‑ Поддержка мощных функций ввода/вывода и горячей замены компонентов для повышения надёжности и доступности

## 16 Причины уменьшения производительности компьютеров с общей памятью  
--------------------------------------------------  
一、共享内存系统性能下降的六大根源  
I. Шесть основных причин снижения производительности систем с общей памятью  
--------------------------------------------------  
1. 阿姆达尔定律——“串行天花板”  
   ‑ 即使处理器再多，程序里 20 % 的串行段把加速比硬锁在 ≤5 倍  
   ‑ “Если в программе 20 % операций строго последовательны, ускорения больше 5 не бывает”  

   Закон Амдала — «потолок последовательности»  
   ‑ Даже при бесконечном росте числа процессоров последовательная часть ограничивает ускорение ≤5×  

2. NUMA 非一致访存——“远程内存慢几倍”  
   ‑ 本地与远程访问时差可达 5–10 倍，用户必须像分布式系统一样重新排布数据  
   ‑ “Разница во времени доступа к локальной и удалённой памяти в несколько раз потребует… аккуратного программирования”  

   Неоднородность доступа к памяти — «удалённая память в несколько раз медленнее»  
   ‑ Различие в задержках заставляет программиста решать задачи, аналогичные распределению данных в кластерах  

3. 内存访问冲突——“多核撞车”  
   ‑ 多 CPU 同时命中同一内存体或缓存行，硬件串行化，带宽骤降  
   ‑ “Конфликты при обращении к памяти… характерны для многих SMP-систем”  

   Конфликты при доступе к памяти — «многие ядра сталкиваются в одном банке»  
   ‑ Одновременные обращения к одной и той же кэш-линии вызывают сериализацию и падение пропускной способности  

4. 缓存一致性开销——“ccNUMA 的 cc 就是这样来的”  
   ‑ 每颗 CPU 私有缓存必须持续侦听/广播一致性消息，占用互联带宽  
   ‑ “Необходимость обеспечения согласованности содержимого кэш-памяти… первые две буквы в аббревиатуре ccNUMA”  

   Поддержание когерентности кэшей — «отсюда появились первые две буквы ccNUMA»  
   ‑ Чем чаще аппаратура вмешивается, тем выше накладные расходы на протоколы согласования  

5. 负载不均衡——“有人闲、有人累”  
   ‑ 线程任务量差异大，总时间被最慢线程拖长；所幸 SMP 处理器同构，策略简单  
   ‑ “Сбалансированность нагрузки… в случае общей памяти системы почти всегда однородны”  

   Сбалансированность нагрузки — «одинаковые процессоры упрощают стратегию распределения»  
   ‑ Хотя распределение работы проще, неравномерная загрузка всё равно оставляет часть ядер в простое  

6. 单核实际性能落差——“峰值与现实的鸿沟”  
   ‑ 现代 CPU 峰值与实测性能可差十倍；若代码吃不满流水线、向量化单元，整机吞吐量随之下滑  
   ‑ “Реальная производительность отдельного процессора может отличаться… в десятки раз”  

   Реальная производительность ядра — «пиковая и фактическая могут различаться в десятки раз»  
   ‑ Чем полнее используются возможности каждого процессора, тем выше суммарная мощность всей системы
