1.
2.
3.
4.
5.
6.
7.
8.
9.
 Виды параллельной обработки данных, их особенности.
 Вычислительно сложные задачи. Примеры оценки вычислительной сложности школьных, научных и промышленных задач.
 Современные технологии и парадигмы решения задач с использованием суперкомпьютеров.
 Микроэлектроника и архитектура: оценка вклада в увеличение производительности компьютеров.
 Архитектура и параметры суперкомпьютерных систем – лидеров списка Top500 (примеры): производительность, эффективность, 
энергопотребление, энергоэффективность, степень параллельности.
 Этапы решения задач на параллельных вычислительных системах. Пиковая и реальная производительность компьютеров. Понятие 
суперкомпьютерного кодизайна.
 Список Top500: принципы формирования, структура, параметры, рост производительности суперкомпьютерных систем, значения N 
и N1/2.
 Иерархия памяти, локальность вычислений, локальность использования данных.
 Закон Амдала, его следствия, суперлинейное ускорение.
10. Показатели качества параллельных программ: ускорение, эффективность реализации, эффективность распараллеливания, 
масштабируемость.
11. Сильная масштабируемость, масштабируемость вширь, слабая масштабируемость. Функция изоэффективности.
12. Классификация Флинна архитектур вычислительных систем.
13. Компьютеры с общей и распредёленной памятью. Две задачи параллельных вычислений.
14. UMA, NUMA и ccNUMA архитектуры. Компьютеры Cm*, BBN Butterfly.
15. Общая структура ccNUMA компьютера на примере Hewlett-Packard Superdome.
16. Причины уменьшения производительности компьютеров с общей памятью.
17. Коммуникационные топологии. Длина критического пути, связность, сложность.
18. Особенности компьютеров семейства CRAY XT: вычислительные узлы, процессорные элементы, коммуникационная сеть.
19. Особенности компьютеров семейства CRAY XT: аппаратная поддержка синхронизации параллельных процессов.
20. Вычислительные кластеры: узлы, коммуникационная сеть (латентность, пропускная способность), способы построения.
21. Архитектура суперкомпьютеров СКИФ МГУ «Чебышев», «Ломоносов» и «Ломоносов-2».
22. Топология коммуникационной сети «толстое дерево» (fat tree) на примере реализации в суперкомпьютерах СКИФ МГУ «Чебышёв» 
или «Ломоносов».
23. Причины уменьшения производительности компьютеров с распределённой памятью.
24. Соотношение между понятиями: функциональное устройство, команда (операция), компьютер и их характеристиками: скалярный, 
векторный, конвейерный.
25. Векторизация программ, необходимые условия векторизации, препятствия для векторизации.
26. Общая структура векторно-конвейерного компьютера на примере CRAY C90. Параллелизм в архитектуре компьютера CRAY C90.
27. Суперкомпьютеры NEC SX-Aurora TSUBASA.
28. Элементы векторной обработки в современных компьютерах. Наборы инструкций MMX, SSE, AVX, AVX2, AVX-512, AltiVec, ARM 
SVE.
29. Причины уменьшения производительности векторно-конвейерных компьютеров.
30. Метакомпьютер и метакомпьютинг. Отличительные свойства распределенных вычислительных сред.
31. Параллелизм на уровне машинных команд. Суперскалярность, VLIW, EPIC.
32. Производительность вычислительных систем, методы оценки и измерения.
33. Технологии параллельного программирования: способы и подходы создания параллельных программ.
34. MPI: параллельная программа, сообщение, понятия групп и коммуникаторов.
35. MPI: синхронное взаимодействие процессов, виды операторов Send (Bsend, Ssend, Rsend). Тупиковые ситуации.
36. MPI: асинхронное взаимодействие процессов.
37. MPI: коллективные операции.
38. MPI: пересылка разнотипных данных, пересылка упакованных данных.
39. OpenMP: параллельная программа, нити, конструкции для организации параллельных и последовательных секций.
40. OpenMP: основные конструкции для распределения работы между нитями.
41. OpenMP: основные конструкции для синхронизации нитей и работы с общими и локальными данными.
42. Графовые модели программ, их взаимосвязь.
43. Понятия информационной зависимости и информационной независимости: критерий эквивалентности преобразования программ, 
ресурс параллелизма программ и алгоритмов.
44. Граф алгоритма. Взаимосвязь графа алгоритма и графовых моделей программ.
45. Виды параллелизма: конечный, массовый, координатный, скошенный.
46. Ярусно-параллельная форма графа алгоритма, высота, ширина. Каноническая ЯПФ. Высота ЯПФ и длина критического пути графа 
алгоритма.
47. Зависимость степени параллелизма от формы записи алгоритма (на примере реализации метода Гаусса).
Материалы для подготовки.
1.
2.
3.
4.
5.
6.
7.
Воеводин В.В., Воеводин Вл.В. Параллельные вычисления. - СПб.: БХВ-Петербург, 2002. - 608 с.
Антонов А.С. Технологии параллельного программирования MPI и OpenMP: Учеб. пособие. Предисл.: В.А.Садовничий. - М.: 
Издательство Московского университета, 2012.-344 с.-(Серия «Суперкомпьютерное образование»).
А.С.Антонов. Параллельное программирование с использованием технологии MPI.-М.: Изд-во МГУ, 2004.-71с. 
(http://parallel.ru/info/parallel/)
Антонов А.С. Параллельное программирование с использованием технологии OpenMP: Учебное пособие.-М.: Изд-во МГУ, 2009. - 77 
с. (http://parallel.ru/info/parallel/)
Вл.В.Воеводин, С.А.Жуматий. Вычислительное дело и кластерные системы.-М.: Изд-во МГУ, 2007.-150с. 
(http://parallel.ru/info/parallel/cluster/)
Материалы информационно-аналитического центра Parallel.ru
Открытая энциклопедия свойств алгоритмов AlgoWiki (https://algowiki-project.org










12.Этапы решения задач на параллельных вычислительных системах  
并行计算系统解题阶段（每段附俄语原文）

1. 明确问题  
中文：先弄清楚“算什么、算多快、在哪台机器上算、内存/时间限制是多少”。  
俄语：Чётко определить: что считать, насколько быстро, на какой машине, какие ограничения по памяти и железу.

2. 找出可并行计算部分  
中文：分析算法，找出互不依赖的计算段（循环、任务、图节点）；评估粒度：太细会频繁同步，太粗会闲置核心。  
俄语：Найти независимые вычислительные ветви (loop-ы, задачи, потоки). Оценить гранулярность: «мелко» → много синхронизации, «крупно» → риск нераспараллеленных участков.

3. 选编程模型与技术栈  
中文：想快速出原型→OpenMP/TBB/Ray/Dask；要极限性能→MPI/CUDA/OpenCL；同时考虑开发时间、可移植性、后续维护。  
俄语：Быстрое прототипирование → OpenMP, TBB, Ray, Dask. Максимальная производительность → MPI, CUDA, OpenCL, oneAPI. Учитывать: время разработки, переносимость, жизненный цикл программы.

4. 数据划分  
中文：把数组/图/模型按节点本地内存或NUMA域切开，使通信量最小，避免“远程吃内存”现象。  
俄语：Разбить массивы/графы/модели по локальным памятям узлов или NUMA-областям так, чтобы минимизировать обмен и «ложные» шеринги.

5. 数据与计算对齐  
中文：让“数据地图”与“计算地图”重合；否则90 %时间花在搬数据而非计算， scalability 免谈。  
俄语：Карта «данные ↔ процессор» должна совпадать с картой «вычисления ↔ процессор». Иначе 90 % времени уйдёт на пересылку.

6. 编码与调试  
中文：先写能跑的最小并行版本，加检查点与可视化工具（Vampir/Nsight/ITAC），快速定位死锁、数据竞态。  
俄语：Написать минимально-рабочий параллельный вариант, добавить контрольные точки и средства визуализации (Vampir, Score-P, Nsight, ITAC).

7. 性能与可扩展性测试  
中文：在1→N核/节点测加速比和效率；画强/弱可扩展曲线，找出同步、负载不均、通信瓶颈。  
俄语：Измерить ускорение и эффективность на 1 → N ядер/узлов. Построить сильную и слабую масштабируемость; найти узкие места (синхронизация, load imbalance, коммуникации).

8. 优化  
中文：增大任务粒度、删冗余屏障、改用非阻塞通信、重叠通信与计算、向量化、循环展开等。  
俄语：Увеличить гранулярность, убрать лишние барьеры, перераспределить данные, применить неблокирующие отправки, overlap коммуникаций и вычислений, векторизовать/развернуть циклы.

9. 移植与维护  
中文：用标准(MPI-3/OpenMP 5/C++17)写代码，写好数据与通信文档，换新平台时只需调优而无需重写。  
俄语：Задокументировать модель данных и схему коммуникаций; держать код в стандартах (MPI-3, OpenMP 5, ISO C++17) для переноса на новое железо без полной переписи.

10. 运行与迭代  
中文：上线后随问题规模、物理模型、硬件升级（CPU+GPU混合架构）不断重复4-9步，持续演进。  
俄语：Добавлять новые физические эффекты, увеличивать размер сеток, переходить на гибридные CPU+GPU системы — повторять пункты 4-9 по мере роста задачи.

关键三要素（中俄对照）  
中文：1.找到并行度 2.数据靠近处理器 3.数据与计算对齐  
俄语：1) найти параллелизм, 2) разложить данные близко к процессорам, 3) согласовать эти два распределения.
