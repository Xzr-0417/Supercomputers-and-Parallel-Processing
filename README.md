1.      Виды параллельной обработки данных, их особенности .
2.      Вычислительно сложные задачи . Примеры оценки вычислительной сложности школьных, научных и промышленных задач .
3.      Современные технологии и парадигмы решения задач с использованием суперкомпьютеров .
4.      Микроэлектроника и архитектура: оценка вклада в увеличение производительности компьютеров .
5.     Архитектура и параметры суперкомпьютерных систем – лидеров списка Top500 (примеры): производительность, эффективность, энергопотребление, энергоэффективность, степень параллельности .
6.      Этапы решения задач на параллельных вычислительных системах . Пиковая и реальная производительность компьютеров . Понятие суперкомпьютерного кодизайна .
7.      Список Top500: принципы формирования, структура, параметры, рост производительности суперкомпьютерных систем, значения N и N1/2 .
8.      Иерархия памяти, локальность вычислений, локальность использования данных .
9.      Закон Амдала, его следствия, суперлинейное ускорение .
10.    Показатели качества параллельных программ: ускорение, эффективность реализации, эффективность распараллеливания, масштабируемость .
11.    Сильная масштабируемость, масштабируемость вширь, слабая масштабируемость . Функция изоэффективности .
12.    Классификация Флинна архитектур вычислительных систем .
13.    Компьютеры с общей и распредёленной памятью. Две задачи параллельных вычислений .
14.   UMA, NUMA и ccNUMA архитектуры . Компьютеры Cm*, BBN Butterfly.
15.    Общая структура ccNUMA компьютера на примере Hewlett-Packard Superdome.
16.    Причины уменьшения производительности компьютеров с общей памятью .
17.   Коммуникационные топологии. Длина критического пути, связность, сложность .
18.    Особенности компьютеров семейства CRAY XT: вычислительные узлы, процессорные элементы, коммуникационная сеть .
19.    Особенности компьютеров семейства CRAY XT: аппаратная поддержка синхронизации параллельных процессов .
20.    Вычислительные кластеры: узлы, коммуникационная сеть (латентность, пропускная способность), способы построения .
21.   Архитектура суперкомпьютеров СКИФ МГУ «Чебышев», «Ломоносов» и «Ломоносов-2» .
22.    Топология коммуникационной сети «толстое дерево» (fat tree) на примере реализации в суперкомпьютерах СКИФ МГУ «Чебышёв» или «Ломоносов» .
23.    Причины уменьшения производительности компьютеров с распределённой памятью .
24.    Соотношение между понятиями: функциональное устройство, команда (операция), компьютер и их характеристиками: скалярный, векторный, конвейерный .
25.    Векторизация программ, необходимые условия векторизации, препятствия для векторизации .
26.    Общая структура векторно-конвейерного компьютера на примере CRAY C90. Параллелизм в архитектуре компьютера CRAY C90.
27.    Суперкомпьютеры NEC SX-Aurora TSUBASA.
28.    Элементы векторной обработки в современных компьютерах . Наборы инструкций MMX, SSE, AVX, AVX2, AVX-512, AltiVec, ARM
SVE.
29.    Причины уменьшения производительности векторно-конвейерных компьютеров .
30.    Метакомпьютер и метакомпьютинг . Отличительные свойства распределенных вычислительных сред .
31.    Параллелизм на уровне машинных команд . Суперскалярность, VLIW, EPIC.
32.    Производительность вычислительных систем, методы оценки и измерения .
33.    Технологии параллельного программирования: способы и подходы создания параллельных программ .
34.    MPI: параллельная программа, сообщение, понятия групп и коммуникаторов .
35.    MPI: синхронное взаимодействие процессов, виды операторов Send (Bsend, Ssend, Rsend). Тупиковые ситуации .
36.    MPI: асинхронное взаимодействие процессов .
37.    MPI: коллективные операции .
38.    MPI: пересылка разнотипных данных, пересылка упакованных данных .
39.    OpenMP: параллельная программа, нити, конструкции для организации параллельных и последовательных секций .
40.    OpenMP: основные конструкции для распределения работы между нитями .
41.    OpenMP: основные конструкции для синхронизации нитей и работы с общими и локальными данными .
42.    Графовые модели программ, их взаимосвязь .
43.    Понятия информационной зависимости и информационной независимости: критерий эквивалентности преобразования программ, ресурс параллелизма программ и алгоритмов .
44.    Граф алгоритма . Взаимосвязь графа алгоритма и графовых моделей программ .
45.    Виды параллелизма: конечный, массовый, координатный, скошенный .
46.    Ярусно-параллельная форма графа алгоритма, высота, ширина . Каноническая ЯПФ . Высота ЯПФ и длина критического пути графа алгоритма .
47.    Зависимость степени параллелизма от формы записи алгоритма (на примере реализации метода Гаусса).
Материалы для подготовки .
1.     Воеводин В.В ., Воеводин Вл.В . Параллельные вычисления . - СПб.: БХВ-Петербург, 2002. - 608 с .
2.    Антонов А.С . Технологии параллельного программирования MPI и OpenMP: Учеб . пособие . Предисл.: В.А.Садовничий . - М.:
Издательство Московского университета, 2012.-344 с.-(Серия «Суперкомпьютерное образование»).
3.    А.С.Антонов . Параллельное программирование с использованием технологии MPI.-М.: Изд-во МГУ, 2004.-71с .
(http://parallel.ru/info/parallel/)
4.    Антонов А.С . Параллельное программирование с использованием технологии OpenMP: Учебное пособие .-М.: Изд-во МГУ, 2009. - 77 с. (http://parallel.ru/info/parallel/)
5.     Вл.В.Воеводин, С.А.Жуматий . Вычислительное дело и кластерные системы.-М.: Изд-во МГУ, 2007.-150с .
(http://parallel.ru/info/parallel/cluster/)
6.     Материалы информационно-аналитического центра Parallel.ru
7.     Открытая энциклопедия свойств алгоритмов AlgoWiki (https://algowiki-project.org)
