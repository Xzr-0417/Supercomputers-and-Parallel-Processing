- [1. Виды параллельной обработки данных, их особенности.](#1-виды-параллельной-обработки-данных-их-особенности)
- [2. Вычислительно сложные задачи. Примеры оценки вычислительной сложности школьных, научных и промышленных задач.](#2-вычислительно-сложные-задачи-примеры-оценки-вычислительной-сложности-школьных-научных-и-промышленных-задач)
- [3. Современные технологии и парадигмы решения задач с использованием суперкомпьютеров.](#3-современные-технологии-и-парадигмы-решения-задач-с-использованием-суперкомпьютеров)
- [4. Микроэлектроника и архитектура: оценка вклада в увеличение производительности компьютеров.](#4-микроэлектроника-и-архитектура-оценка-вклада-в-увеличение-производительности-компьютеров)
- [5. Архитектура и параметры суперкомпьютерных систем – лидеров списка Top500 (примеры): производительность, эффективность, энергопотребление, энергоэффективность, степень параллельности.](#5-архитектура-и-параметры-суперкомпьютерных-систем--лидеров-списка-top500-примеры-производительность-эффективность-энергопотребление-энергоэффективность-степень-параллельности)
- [6. Этапы решения задач на параллельных вычислительных системах. Пиковая и реальная производительность компьютеров. Понятие суперкомпьютерного кодизайна.](#6-этапы-решения-задач-на-параллельных-вычислительных-системах-пиковая-и-реальная-производительность-компьютеров-понятие-суперкомпьютерного-кодизайна)
- [7. Список Top500: принципы формирования, структура, параметры, рост производительности суперкомпьютерных систем, значения N и N1/2.](#7-список-top500-принципы-формирования-структура-параметры-рост-производительности-суперкомпьютерных-систем-значения-n-и-n12)
- [8. Иерархия памяти, локальность вычислений, локальность использования данных.](#8-иерархия-памяти-локальность-вычислений-локальность-использования-данных)
- [9. Закон Амдала, его следствия, суперлинейное ускорение.](#9-закон-амдала-его-следствия-суперлинейное-ускорение)
- [10. Показатели качества параллельных программ: ускорение, эффективность реализации, эффективность распараллеливания, масштабируемость.](#10-показатели-качества-параллельных-программ-ускорение-эффективность-реализации-эффективность-распараллеливания-масштабируемость)
- [11. Сильная масштабируемость, масштабируемость вширь, слабая масштабируемость. Функция изоэффективности.](#11-сильная-масштабируемость-масштабируемость-вширь-слабая-масштабируемость-функция-изоэффективности)
- [12. Классификация Флинна архитектур вычислительных систем.](#12-классификация-флинна-архитектур-вычислительных-систем)
- [13. Компьютеры с общей и распредёленной памятью. Две задачи параллельных вычислений.](#13-компьютеры-с-общей-и-распредёленной-памятью-две-задачи-параллельных-вычислений)
- [14. UMA, NUMA и ccNUMA архитектуры. Компьютеры Cm*, BBN Butterfly.](#14-uma-numa-и-ccnuma-архитектуры-компьютеры-cm-bbn-butterfly)
- [15. Общая структура ccNUMA компьютера на примере Hewlett-Packard Superdome.](#15-общая-структура-ccnuma-компьютера-на-примере-hewlett-packard-superdome)
- [16. Причины уменьшения производительности компьютеров с общей памятью.](#16-причины-уменьшения-производительности-компьютеров-с-общей-памятью)
- [17. Коммуникационные топологии. Длина критического пути, связность, сложность.](#17-коммуникационные-топологии-длина-критического-пути-связность-сложность)
- [18. Особенности компьютеров семейства CRAY XT: вычислительные узлы, процессорные элементы, коммуникационная сеть.](#18-особенности-компьютеров-семейства-cray-xt-вычислительные-узлы-процессорные-элементы-коммуникационная-сеть)
- [19. Особенности компьютеров семейства CRAY XT: аппаратная поддержка синхронизации параллельных процессов.](#19-особенности-компьютеров-семейства-cray-xt-аппаратная-поддержка-синхронизации-параллельных-процессов)
- [20. Вычислительные кластеры: узлы, коммуникационная сеть (латентность, пропускная способность), способы построения.](#20-вычислительные-кластеры-узлы-коммуникационная-сеть-латентность-пропускная-способность-способы-построения)
- [21. Архитектура суперкомпьютеров СКИФ МГУ «Чебышев», «Ломоносов» и «Ломоносов-2».](#21-архитектура-суперкомпьютеров-скиф-мгу-чебышев-ломоносов-и-ломоносов-2)
- [22. Топология коммуникационной сети «толстое дерево» (fat tree) на примере реализации в суперкомпьютерах СКИФ МГУ «Чебышёв» или «Ломоносов».](#22-топология-коммуникационной-сети-толстое-дерево-fat-tree-на-примере-реализации-в-суперкомпьютерах-скиф-мгу-чебышёв-или-ломоносов)
- [23. Причины уменьшения производительности компьютеров с распределённой памятью.](#23-причины-уменьшения-производительности-компьютеров-с-распределённой-памятью)
- [24. Соотношение между понятиями: функциональное устройство, команда (операция), компьютер и их характеристиками: скалярный, векторный, конвейерный.](#24-соотношение-между-понятиями-функциональное-устройство-команда-операция-компьютер-и-их-характеристиками-скалярный-векторный-конвейерный)
- [25. Векторизация программ, необходимые условия векторизации, препятствия для векторизации.](#25-векторизация-программ-необходимые-условия-векторизации-препятствия-для-векторизации)
- [26. Общая структура векторно-конвейерного компьютера на примере CRAY C90. Параллелизм в архитектуре компьютера CRAY C90.](#26-общая-структура-векторно-конвейерного-компьютера-на-примере-cray-c90-параллелизм-в-архитектуре-компьютера-cray-c90)
- [27. Суперкомпьютеры NEC SX-Aurora TSUBASA.](#27-суперкомпьютеры-nec-sx-aurora-tsubasa)
- [28. Элементы векторной обработки в современных компьютерах. Наборы инструкций MMX, SSE, AVX, AVX2, AVX-512, AltiVec, ARM SVE.](#28-элементы-векторной-обработки-в-современных-компьютерах-наборы-инструкций-mmx-sse-avx-avx2-avx-512-altivec-arm-sve)
- [29. Причины уменьшения производительности векторно-конвейерных компьютеров.](#29-причины-уменьшения-производительности-векторно-конвейерных-компьютеров)
- [30. Метакомпьютер и метакомпьютинг. Отличительные свойства распределенных вычислительных сред.](#30-метакомпьютер-и-метакомпьютинг-отличительные-свойства-распределенных-вычислительных-сред)
- [31. Параллелизм на уровне машинных команд. Суперскалярность, VLIW, EPIC.](#31-параллелизм-на-уровне-машинных-команд-суперскалярность-vliw-epic)
- [32. Производительность вычислительных систем, методы оценки и измерения.](#32-производительность-вычислительных-систем-методы-оценки-и-измерения)
- [33. Технологии параллельного программирования: способы и подходы создания параллельных программ.](#33-технологии-параллельного-программирования-способы-и-подходы-создания-параллельных-программ)
- [34. MPI: параллельная программа, сообщение, понятия групп и коммуникаторов.](#34-mpi-параллельная-программа-сообщение-понятия-групп-и-коммуникаторов)
- [35. MPI: синхронное взаимодействие процессов, виды операторов Send (Bsend, Ssend, Rsend). Тупиковые ситуации.](#35-mpi-синхронное-взаимодействие-процессов-виды-операторов-send-bsend-ssend-rsend-тупиковые-ситуации)
- [36. MPI: асинхронное взаимодействие процессов.](#36-mpi-асинхронное-взаимодействие-процессов)
- [37. MPI: коллективные операции.](#37-mpi-коллективные-операции)
- [38. MPI: пересылка разнотипных данных, пересылка упакованных данных.](#38-mpi-пересылка-разнотипных-данных-пересылка-упакованных-данных)
- [39. OpenMP: параллельная программа, нити, конструкции для организации параллельных и последовательных секций.](#39-openmp-параллельная-программа-нити-конструкции-для-организации-параллельных-и-последовательных-секций)
- [40. OpenMP: основные конструкции для распределения работы между нитями.](#40-openmp-основные-конструкции-для-распределения-работы-между-нитями)
- [41. OpenMP: основные конструкции для синхронизации нитей и работы с общими и локальными данными.](#41-openmp-основные-конструкции-для-синхронизации-нитей-и-работы-с-общими-и-локальными-данными)
- [42. Графовые модели программ, их взаимосвязь.](#42-графовые-модели-программ-их-взаимосвязь)
- [43. Понятия информационной зависимости и информационной независимости: критерий эквивалентности преобразования программ, ресурс параллелизма программ и алгоритмов.](#43-понятия-информационной-зависимости-и-информационной-независимости-критерий-эквивалентности-преобразования-программ-ресурс-параллелизма-программ-и-алгоритмов)
- [44. Граф алгоритма. Взаимосвязь графа алгоритма и графовых моделей программ.](#44-граф-алгоритма-взаимосвязь-графа-алгоритма-и-графовых-моделей-программ)
- [45. Виды параллелизма: конечный, массовый, координатный, скошенный.](#45-виды-параллелизма-конечный-массовый-координатный-скошенный)
- [46. Ярусно-параллельная форма графа алгоритма, высота, ширина. Каноническая ЯПФ. Высота ЯПФ и длина критического пути графа алгоритма.](#46-ярусно-параллельная-форма-графа-алгоритма-высота-ширина-каноническая-япф-высота-япф-и-длина-критического-пути-графа-алгоритма)
- [47. Зависимость степени параллелизма от формы записи алгоритма (на примере реализации метода Гаусса).](#47-зависимость-степени-параллелизма-от-формы-записи-алгоритма-на-примере-реализации-метода-гаусса)


13 Компьютеры с общей и распредёленной памятью. Две задачи параллельных вычислений.
--------------------------------------------------
一、计算机按内存组织方式的两大类别  
I. Два класса компьютеров по организации памяти  
--------------------------------------------------
1. 共享内存系统（Shared-Memory, SMP/ccNUMA）  
   ‑ 所有 CPU 通过总线/交叉开关访问同一条物理地址空间  
   ‑ 通信 = 普通 load/store，编程简单，调试快  
   ‑ 瓶颈：总线带宽 & 缓存一致性 → CPU 数量≈数十颗  

   Системы с общей памятью (SMP/ccNUMA)  
   ‑ Все процессоры обращаются к единому физическому адресному пространству  
   ‑ Обмен данными через обычные операции чтения/записи; разработка и отладка проще  
   ‑ Ограничение: пропускная способность шины и когерентность кэшей → десятки ядер  

2. 分布式内存系统（Distributed-Memory, MPP/Cluster）  
   ‑ 每个节点 = CPU + 本地内存；节点间用高速网络或以太网互联  
   ‑ 远程数据只能显式收发消息（MPI/PVM）  
   ‑ 优点：可扩展至成千上万核；缺点：通信延迟高，编程复杂  

   Системы с распределённой памятью (MPP/кластер)  
   ‑ Узел = процессор + локальная память; соединение через высокоскоростную сеть  
   ‑ Доступ к чужим данным только через сообщения (MPI/PVM)  
   ‑ Плюс: линейный масштаб до тысяч ядер; минус: высокая задержка и сложная разработка  

--------------------------------------------------
二、并行计算永恒面对的“两大任务”  
II. Две основные задачи параллельных вычислений  
--------------------------------------------------
任务 1 · 极限性能 – “堆”出最高浮点能力  
├─ 手段：横向扩展（加节点）、提高网络带宽、优化拓扑  
├─ 代表：TOP500 上榜系统、云计算集群、甚至互联网本身  
└─ 关键瓶颈：节点间通信开销 → 需隐藏延迟、提升带宽  

Задача 1 · Максимальная производительность  
├─ Путь: горизонтальное масштабирование, увеличение пропускной способности сети  
├─ Примеры: системы TOP500, облачные кластеры, «Интернет как суперкомпьютер»  
└─ Главное препятствие: накладные расходы на обмен сообщениями → необходимо скрывать задержки  

任务 2 · 易用编程 – 让开发者轻松写出高效并行代码  
├─ 共享内存：OpenMP / Pthreads，逻辑简单，调试快，但 CPU 数量受限  
├─ 分布式：MPI/PVM，可扩展，却需手工分数据、管通信  
└─ 现代折中：节点内 OpenMP + 节点间 MPI，或 ccNUMA“逻辑共享、物理分布”  

Задача 2 · Удобное программирование  
├─ Shared-memory: OpenMP/Pthreads — проще отладка, но ограничено число ядер  
├─ Distributed: MPI/PVM — масштабно, но нужно вручную разбивать данные  
└─ Современный гибрид: внутри узла OpenMP, между узлами MPI; либо ccNUMA  

--------------------------------------------------
速记口诀 / Краткая формула  
--------------------------------------------------
“共享”易编程，难扩展；  
“分布”可扩展，难编程。  
两大任务：①堆性能 ②降开发难度。  

«Shared» — проще код, сложнее масштаб;  
«Distributed» — легко масштаб, сложен код.  
Две задачи: ① максимум FLOPS ② минимум усилий разработчика.




14 UMA, NUMA и ccNUMA архитектуры. Компьютеры Cm*, BBN Butterfly  
--------------------------------------------------
一、三种“内存访问距离”逐渐拉长的体系结构  
I. Три архитектуры с возрастающим «расстоянием» до памяти  
--------------------------------------------------
1. UMA（Uniform Memory Access）  
   ‑ 所有 CPU 通过单一总线或交叉开关访问“等距”的共享内存  
   ‑ 延迟一致，编程简单；瓶颈在总线带宽，规模≈几十核  

   UMA (однородный доступ к памяти)  
   ‑ Все процессоры через общую шину обращаются к памяти с одинаковой задержкой  
   ‑ Простота программирования; узкое место — шина, масштаб ограничен десятками ядер  

2. NUMA（Non-Uniform Memory Access）  
   ‑ 系统 = 多簇“CPU+本地内存”，簇间用高速互连；本地访问远快于远程  
   ‑ 地址空间统一，但速度“不均匀”；规模可扩展到上百 CPU  

   NUMA (неоднородный доступ к памяти)  
   ‑ Система состоит из кластеров «процессор + локальная память», связанных межкластерной шиной  
   ‑ Общее адресное пространство, но разная скорость доступа; масштаб до сотен процессоров  

3. ccNUMA（cache-coherent NUMA）  
   ‑ 在 NUMA 基础上由硬件协议自动保证各 CPU 缓存一致性  
   ‑ 程序员仍视其为“单一大内存”，内核数可扩至 256–1024，且无需改写 SMP 代码  

   ccNUMA (когерентная NUMA)  
   ‑ Аппаратно решается проблема когерентности кэшей; для программиста видна как единое пространство  
   ‑ Позволяет масштабироваться до 256–1024 ядер без изменения SMP-программ  

15. Общая структура ccNUMA компьютера на примере Hewlett-Packard Superdome.  
--------------------------------------------------
二、两台奠定 NUMA 思想的实验/商用机  
II. Две машины, заложившие основы NUMA 
--------------------------------------------------
Cm*（Carnegie Mellon，1970-е）  
‑ 最早把“处理器+存储器”做成小簇，用簇间总线拼成 NUMA 原型；验证了“本地快、远程慢”理念  

Cm* (Карнеги-Меллон, 1970-е)  
‑ Первый прототип NUMA: кластеры «CPU + память» соединены межкластерной шиной; подтверждён принцип «локально быстрее»  

BBN Butterfly（1980-е，最多 256 CPU）  
‑ 每个节点 = CPU + 本地内存 + Butterfly 交换网；本地 2 µs，远程 6 µs，从软件看仍是单地址空间  

BBN Butterfly (1980-е, до 256 процессоров)  
‑ Узел = процессор + память + коммутатор Butterfly; задержка 2 мкс локально, 6 мкс удалённо, единое адресное пространство



15. Общая структура ccNUMA компьютера на примере Hewlett-Packard Superdome.  
--------------------------------------------------  
一、ccNUMA 体系结构的“骨架”——以 HP Superdome 为例  
I. Каркас архитектуры ccNUMA на примере HP Superdome  
--------------------------------------------------  
1. 全局统一地址空间，由“计算单元 + 分层交换机”两级拼成  
   ‑ 最多 16 个 cell，每 cell 4 路 PA-8700，通过 8 GB/s 交叉开关互连  
   ‑ 所有 CPU 看到同一段 0–256 GB 物理地址，用普通 load/store 即可访问任意字节  

   Единое адресное пространство, собранное из «вычислительных ячеек + коммутаторов»  
   ‑ До 16 ячеек, по 4 процессора PA-8700 в каждой, соединены кроссбарами на 8 ГБ/с  
   ‑ Все CPU видят один диапазон 0–256 ГБ и обращаются к любому байту обычными командами чтения/записи  

2. 访存延迟“三段式”——用非均匀换可扩展  
   ‑ ① cell 内 < ② 同开关不同 cell < ③ 跨开关；64 路平均延迟仅比 4 路高 1.6 倍  
   ‑ 硬件自动维护缓存一致性，程序员仍按 SMP 思维写代码  

   Три уровня задержки памяти — неравномерность в обмен на масштабируемость  
   ‑ ① внутри ячейки < ② в той же группе коммутатора < ③ через два коммутатора; рост всего в 1,6 раза  
   ‑ Когерентность кэшей поддерживается аппаратно, разработчик продолжает думать как над SMP  

3. 物理实现：双机柜-四交换机拓扑，带宽随规模线性扩展  
   ‑ 每柜 2 台 8 口无阻塞交叉开关，各留 1 口可级联第二台 Superdome，突破 64 CPU 上限  
   ‑ 全链路 8 GB/s 全双工，确保“加节点”不“塞管道”  

   Физическая реализация: два шкафа, четыре коммутатора, пропускная способность растёт линейно  
   ‑ В каждом шкафу — по 2 кроссбара на 8 портов; один порт резервирован для второго Superdome, преодолевая предел в 64 CPU  
   ‑ Все линии полнодуплексные 8 ГБ/с, добавление узлов не превращается в узкое место
