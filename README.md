1. Виды параллельной обработки данных, их особенности.
   数据并行处理的种类及其特点。

2. Вычислительно сложные задачи. Примеры оценки вычислительной сложности школьных, научных и промышленных задач.
   计算复杂性问题。评估学校、科学和工业问题计算复杂性的例子。

3. Современные технологии и парадигмы решения задач с использованием суперкомпьютеров.
   使用超级计算机解决问题的现代技术和范式。

4. Микроэлектроника и архитектура: оценка вклада в увеличение производительности компьютеров.
   微电子学和架构：对提高计算机性能的贡献评估。

5. Архитектура и параметры суперкомпьютерных систем – лидеров списка Top500 (примеры): производительность, эффективность, энергопотребление, энергоэффективность, степень параллельности.
   超级计算机系统——Top500榜单领先者的架构和参数（示例）：性能、效率、能耗、能效、并行程度。

6. Этапы решения задач на параллельных вычислительных системах. Пиковая и реальная производительность компьютеров. Понятие суперкомпьютерного кодизайна.
   在并行计算系统上解决问题的阶段。计算机的峰值和实际性能。超级计算机协同设计的概念。

7. Список Top500: принципы формирования, структура, параметры, рост производительности суперкомпьютерных систем, значения N и N1/2.
   Top500榜单：形成原则、结构、参数、超级计算机系统性能增长、N和N1/2的值。

8. Иерархия памяти, локальность вычислений, локальность использования данных.
   内存层次结构、计算局部性、数据使用局部性。

9. Закон Амдала, его следствия, суперлинейное ускорение.
   阿姆达尔定律、其推论、超线性加速。

10. Показатели качества параллельных программ: ускорение, эффективность реализации, эффективность распараллеливания, масштабируемость.
    并行程序质量指标：加速比、实现效率、并行效率、可扩展性。

11. Сильная масштабируемость, масштабируемость вширь, слабая масштабируемость. Функция изоэффективности.
    强可扩展性、横向可扩展性、弱可扩展性。等效函数。

12. Классификация Флинна архитектур вычислительных систем.
    Flynn对计算系统架构的分类。

13. Компьютеры с общей и распредёленной памятью. Две задачи параллельных вычислений. (#Компьютеры с общей и распредёленной памятью. Две задачи параллельных вычислений.)
    具有共享内存和分布式内存的计算机。并行计算的两个任务。

14. UMA, NUMA и ccNUMA архитектуры. Компьютеры Cm*, BBN Butterfly.
    UMA、NUMA和ccNUMA架构。Cm*、BBN Butterfly计算机。

15. Общая структура ccNUMA компьютера на примере Hewlett-Packard Superdome.
    以惠普超级圆顶为例的ccNUMA计算机的总体结构。

16. Причины уменьшения производительности компьютеров с общей памятью.
    导致共享内存计算机性能下降的原因。

17. Коммуникационные топологии. Длина критического пути, связность, сложность.
    通信拓扑结构。临界路径长度、连通性、复杂性。

18. Особенности компьютеров семейства CRAY XT: вычислительные узлы, процессорные элементы, коммуникационная сеть.
    CRAY XT系列计算机的特点：计算节点、处理器单元、通信网络。

19. Особенности компьютеров семейства CRAY XT: аппаратная поддержка синхронизации параллельных процессов.
    CRAY XT系列计算机的特点：对并行进程同步的硬件支持。

20. Вычислительные кластеры: узлы, коммуникационная сеть (латентность, пропускная способность), способы построения.
    计算集群：节点、通信网络（延迟、带宽）、构建方式。

21. Архитектура суперкомпьютеров СКИФ МГУ «Чебышев», «Ломоносов» и «Ломоносов-2».
    莫斯科大学SKIF超级计算机“切比雪夫”、“罗蒙诺索夫”和“罗蒙诺索夫-2”的架构。

22. Топология коммуникационной сети «толстое дерево» (fat tree) на примере реализации в суперкомпьютерах СКИФ МГУ «Чебышёв» или «Ломоносов».
    以莫斯科大学SKIF超级计算机“切比雪夫”或“罗蒙诺索夫”为例的“胖树”通信网络拓扑结构。

23. Причины уменьшения производительности компьютеров с распределённой памятью.
    导致分布式内存计算机性能下降的原因。

24. Соотношение между понятиями: функциональное устройство, команда (операция), компьютер и их характеристиками: скалярный, векторный, конвейерный.
    功能单元、指令（操作）、计算机及其特性（标量、向量、流水线）之间的关系。

25. Векторизация программ, необходимые условия векторизации, препятствия для векторизации.
    程序向量化、向量化的必要条件、向量化的障碍。

26. Общая структура векторно-конвейерного компьютера на примере CRAY C90. Параллелизм в архитектуре компьютера CRAY C90.
    以CRAY C90为例的向量流水线计算机的总体结构。CRAY C90计算机架构中的并行性。

27. Суперкомпьютеры NEC SX-Aurora TSUBASA.
    NEC SX-Aurora TSUBASA超级计算机。

28. Элементы векторной обработки в современных компьютерах. Наборы инструкций MMX, SSE, AVX, AVX2, AVX-512, AltiVec, ARM SVE.
    现代计算机中的向量处理元素。MMX、SSE、AVX、AVX2、AVX-512、AltiVec、ARM SVE指令集。

29. Причины уменьшения производительности векторно-конвейерных компьютеров.
    导致向量流水线计算机性能下降的原因。

30. Метакомпьютер и метакомпьютинг. Отличительные свойства распределенных вычислительных сред.
    元计算和元计算。分布式计算环境的独特属性。

31. Параллелизм на уровне машинных команд. Суперскалярность, VLIW, EPIC.
    指令级并行。超标量、VLIW、EPIC。

32. Производительность вычислительных систем, методы оценки и измерения.
    计算系统的性能、评估和测量方法。

33. Технологии параллельного программирования: способы и подходы создания параллельных программ.
    并行编程技术：创建并行程序的方法和途径。

34. MPI: параллельная программа, сообщение, понятия групп и коммуникаторов.
    MPI：并行程序、消息、组和通信器的概念。

35. MPI: синхронное взаимодействие процессов, виды операторов Send (Bsend, Ssend, Rsend). Тупиковые ситуации.
    MPI：进程的同步交互、Send（Bsend、Ssend、Rsend）操作符的类型、死锁情况。

36. MPI: асинхронное взаимодействие процессов.
    MPI：进程的异步交互。

37. MPI: коллективные операции.
    MPI：集体操作。

38. MPI: пересылка разнотипных данных, пересылка упакованных данных.
    MPI：不同类型数据的传输、打包数据的传输。

39. OpenMP: параллельная программа, нити, конструкции для организации параллельных и последовательных секций.
    OpenMP：并行程序、线程、用于组织并行和顺序部分的结构。

40. OpenMP: основные конструкции для распределения работы между нитями.
    OpenMP：线程间工作分配的主要结构。

41. OpenMP: основные конструкции для синхронизации нитей и работы с общими и локальными данными.
    OpenMP：线程同步以及处理共享和本地数据的主要结构。

42. Графовые модели программ, их взаимосвязь.
    程序的图模型及其相互关系。

43. Понятия информационной зависимости и информационной независимости: критерий эквивалентности преобразования программ, ресурс параллелизма программ и алгоритмов.
    信息依赖和信息独立的概念：程序变换的等价性标准、程序和算法的并行资源。

44. Граф алгоритма. Взаимосвязь графа алгоритма и графовых моделей программ.
    算法图。算法图与程序图模型的相互关系。

45. Виды параллелизма: конечный, массовый, координатный, скошенный.
    并行的类型：有限并行、大量并行、坐标并行、倾斜并行。

46. Ярусно-параллельная форма графа алгоритма, высота, ширина. Каноническая ЯПФ. Высота ЯПФ и длина критического пути графа алгоритма.
    算法图的分层并行形式、高度、宽度。规范的分层并行形式。分层并行形式的高度和算法图的临界路径长度。

47. Зависимость степени параллелизма от формы записи алгоритма (на примере реализации метода Гаусса).
    并行程度与算法表示形式的关系（以高斯方法的实现为例）。

13 Компьютеры с общей и распредёленной памятью. Две задачи параллельных вычислений.
    具有共享内存和分布式内存的计算机。并行计算的两个任务。
--------------------------------------------------
一、计算机按内存组织方式的两大类别  
I. Два класса компьютеров по организации памяти  
--------------------------------------------------
1. 共享内存系统（Shared-Memory, SMP/ccNUMA）  
   ‑ 所有 CPU 通过总线/交叉开关访问同一条物理地址空间  
   ‑ 通信 = 普通 load/store，编程简单，调试快  
   ‑ 瓶颈：总线带宽 & 缓存一致性 → CPU 数量≈数十颗  

   Системы с общей памятью (SMP/ccNUMA)  
   ‑ Все процессоры обращаются к единому физическому адресному пространству  
   ‑ Обмен данными через обычные операции чтения/записи; разработка и отладка проще  
   ‑ Ограничение: пропускная способность шины и когерентность кэшей → десятки ядер  

2. 分布式内存系统（Distributed-Memory, MPP/Cluster）  
   ‑ 每个节点 = CPU + 本地内存；节点间用高速网络或以太网互联  
   ‑ 远程数据只能显式收发消息（MPI/PVM）  
   ‑ 优点：可扩展至成千上万核；缺点：通信延迟高，编程复杂  

   Системы с распределённой памятью (MPP/кластер)  
   ‑ Узел = процессор + локальная память; соединение через высокоскоростную сеть  
   ‑ Доступ к чужим данным только через сообщения (MPI/PVM)  
   ‑ Плюс: линейный масштаб до тысяч ядер; минус: высокая задержка и сложная разработка  

--------------------------------------------------
二、并行计算永恒面对的“两大任务”  
II. Две основные задачи параллельных вычислений  
--------------------------------------------------
任务 1 · 极限性能 – “堆”出最高浮点能力  
├─ 手段：横向扩展（加节点）、提高网络带宽、优化拓扑  
├─ 代表：TOP500 上榜系统、云计算集群、甚至互联网本身  
└─ 关键瓶颈：节点间通信开销 → 需隐藏延迟、提升带宽  

Задача 1 · Максимальная производительность  
├─ Путь: горизонтальное масштабирование, увеличение пропускной способности сети  
├─ Примеры: системы TOP500, облачные кластеры, «Интернет как суперкомпьютер»  
└─ Главное препятствие: накладные расходы на обмен сообщениями → необходимо скрывать задержки  

任务 2 · 易用编程 – 让开发者轻松写出高效并行代码  
├─ 共享内存：OpenMP / Pthreads，逻辑简单，调试快，但 CPU 数量受限  
├─ 分布式：MPI/PVM，可扩展，却需手工分数据、管通信  
└─ 现代折中：节点内 OpenMP + 节点间 MPI，或 ccNUMA“逻辑共享、物理分布”  

Задача 2 · Удобное программирование  
├─ Shared-memory: OpenMP/Pthreads — проще отладка, но ограничено число ядер  
├─ Distributed: MPI/PVM — масштабно, но нужно вручную разбивать данные  
└─ Современный гибрид: внутри узла OpenMP, между узлами MPI; либо ccNUMA  

--------------------------------------------------
速记口诀 / Краткая формула  
--------------------------------------------------
“共享”易编程，难扩展；  
“分布”可扩展，难编程。  
两大任务：①堆性能 ②降开发难度。  

«Shared» — проще код, сложнее масштаб;  
«Distributed» — легко масштаб, сложен код.  
Две задачи: ① максимум FLOPS ② минимум усилий разработчика.
