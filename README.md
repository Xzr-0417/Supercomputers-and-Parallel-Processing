- [1. Виды параллельной обработки данных, их особенности.](#1-виды-параллельной-обработки-данных-их-особенности)
- [2. Вычислительно сложные задачи. Примеры оценки вычислительной сложности школьных, научных и промышленных задач.](#2-вычислительно-сложные-задачи-примеры-оценки-вычислительной-сложности-школьных-научных-и-промышленных-задач)
- [3. Современные технологии и парадигмы решения задач с использованием суперкомпьютеров.](#3-современные-технологии-и-парадигмы-решения-задач-с-использованием-суперкомпьютеров)
- [4. Микроэлектроника и архитектура: оценка вклада в увеличение производительности компьютеров.](#4-микроэлектроника-и-архитектура-оценка-вклада-в-увеличение-производительности-компьютеров)
- [5. Архитектура и параметры суперкомпьютерных систем – лидеров списка Top500 (примеры): производительность, эффективность, энергопотребление, энергоэффективность, степень параллельности.](#5-архитектура-и-параметры-суперкомпьютерных-систем--лидеров-списка-top500-примеры-производительность-эффективность-энергопотребление-энергоэффективность-степень-параллельности)
- [6. Этапы решения задач на параллельных вычислительных системах. Пиковая и реальная производительность компьютеров. Понятие суперкомпьютерного кодизайна.](#6-этапы-решения-задач-на-параллельных-вычислительных-системах-пиковая-и-реальная-производительность-компьютеров-понятие-суперкомпьютерного-кодизайна)
- [7. Список Top500: принципы формирования, структура, параметры, рост производительности суперкомпьютерных систем, значения N и N1/2.](#7-список-top500-принципы-формирования-структура-параметры-рост-производительности-суперкомпьютерных-систем-значения-n-и-n12)
- [8. Иерархия памяти, локальность вычислений, локальность использования данных.](#8-иерархия-памяти-локальность-вычислений-локальность-использования-данных)
- [9. Закон Амдала, его следствия, суперлинейное ускорение.](#9-закон-амдала-его-следствия-суперлинейное-ускорение)
- [10. Показатели качества параллельных программ: ускорение, эффективность реализации, эффективность распараллеливания, масштабируемость.](#10-показатели-качества-параллельных-программ-ускорение-эффективность-реализации-эффективность-распараллеливания-масштабируемость)
- [11. Сильная масштабируемость, масштабируемость вширь, слабая масштабируемость. Функция изоэффективности.](#11-сильная-масштабируемость-масштабируемость-вширь-слабая-масштабируемость-функция-изоэффективности)
- [12. Классификация Флинна архитектур вычислительных систем.](#12-классификация-флинна-архитектур-вычислительных-систем)
- [13. Компьютеры с общей и распредёленной памятью. Две задачи параллельных вычислений.](#13-компьютеры-с-общей-и-распредёленной-памятью-две-задачи-параллельных-вычислений)
- [14. UMA, NUMA и ccNUMA архитектуры. Компьютеры Cm*, BBN Butterfly.](#14-uma-numa-и-ccnuma-архитектуры-компьютеры-cm-bbn-butterfly)
- [15. Общая структура ccNUMA компьютера на примере Hewlett-Packard Superdome.](#15-общая-структура-ccnuma-компьютера-на-примере-hewlett-packard-superdome)
- [16. Причины уменьшения производительности компьютеров с общей памятью.](#16-причины-уменьшения-производительности-компьютеров-с-общей-памятью)
- [17. Коммуникационные топологии. Длина критического пути, связность, сложность.](#17-коммуникационные-топологии-длина-критического-пути-связность-сложность)
- [18. Особенности компьютеров семейства CRAY XT: вычислительные узлы, процессорные элементы, коммуникационная сеть.](#18-особенности-компьютеров-семейства-cray-xt-вычислительные-узлы-процессорные-элементы-коммуникационная-сеть)
- [19. Особенности компьютеров семейства CRAY XT: аппаратная поддержка синхронизации параллельных процессов.](#19-особенности-компьютеров-семейства-cray-xt-аппаратная-поддержка-синхронизации-параллельных-процессов)
- [20. Вычислительные кластеры: узлы, коммуникационная сеть (латентность, пропускная способность), способы построения.](#20-вычислительные-кластеры-узлы-коммуникационная-сеть-латентность-пропускная-способность-способы-построения)
- [21. Архитектура суперкомпьютеров СКИФ МГУ «Чебышев», «Ломоносов» и «Ломоносов-2».](#21-архитектура-суперкомпьютеров-скиф-мгу-чебышев-ломоносов-и-ломоносов-2)
- [22. Топология коммуникационной сети «толстое дерево» (fat tree) на примере реализации в суперкомпьютерах СКИФ МГУ «Чебышёв» или «Ломоносов».](#22-топология-коммуникационной-сети-толстое-дерево-fat-tree-на-примере-реализации-в-суперкомпьютерах-скиф-мгу-чебышёв-или-ломоносов)
- [23. Причины уменьшения производительности компьютеров с распределённой памятью.](#23-причины-уменьшения-производительности-компьютеров-с-распределённой-памятью)
- [24. Соотношение между понятиями: функциональное устройство, команда (операция), компьютер и их характеристиками: скалярный, векторный, конвейерный.](#24-соотношение-между-понятиями-функциональное-устройство-команда-операция-компьютер-и-их-характеристиками-скалярный-векторный-конвейерный)
- [25. Векторизация программ, необходимые условия векторизации, препятствия для векторизации.](#25-векторизация-программ-необходимые-условия-векторизации-препятствия-для-векторизации)
- [26. Общая структура векторно-конвейерного компьютера на примере CRAY C90. Параллелизм в архитектуре компьютера CRAY C90.](#26-общая-структура-векторно-конвейерного-компьютера-на-примере-cray-c90-параллелизм-в-архитектуре-компьютера-cray-c90)
- [27. Суперкомпьютеры NEC SX-Aurora TSUBASA.](#27-суперкомпьютеры-nec-sx-aurora-tsubasa)
- [28. Элементы векторной обработки в современных компьютерах. Наборы инструкций MMX, SSE, AVX, AVX2, AVX-512, AltiVec, ARM SVE.](#28-элементы-векторной-обработки-в-современных-компьютерах-наборы-инструкций-mmx-sse-avx-avx2-avx-512-altivec-arm-sve)
- [29. Причины уменьшения производительности векторно-конвейерных компьютеров.](#29-причины-уменьшения-производительности-векторно-конвейерных-компьютеров)
- [30. Метакомпьютер и метакомпьютинг. Отличительные свойства распределенных вычислительных сред.](#30-метакомпьютер-и-метакомпьютинг-отличительные-свойства-распределенных-вычислительных-сред)
- [31. Параллелизм на уровне машинных команд. Суперскалярность, VLIW, EPIC.](#31-параллелизм-на-уровне-машинных-команд-суперскалярность-vliw-epic)
- [32. Производительность вычислительных систем, методы оценки и измерения.](#32-производительность-вычислительных-систем-методы-оценки-и-измерения)
- [33. Технологии параллельного программирования: способы и подходы создания параллельных программ.](#33-технологии-параллельного-программирования-способы-и-подходы-создания-параллельных-программ)
- [34. MPI: параллельная программа, сообщение, понятия групп и коммуникаторов.](#34-mpi-параллельная-программа-сообщение-понятия-групп-и-коммуникаторов)
- [35. MPI: синхронное взаимодействие процессов, виды операторов Send (Bsend, Ssend, Rsend). Тупиковые ситуации.](#35-mpi-синхронное-взаимодействие-процессов-виды-операторов-send-bsend-ssend-rsend-тупиковые-ситуации)
- [36. MPI: асинхронное взаимодействие процессов.](#36-mpi-асинхронное-взаимодействие-процессов)
- [37. MPI: коллективные операции.](#37-mpi-коллективные-операции)
- [38. MPI: пересылка разнотипных данных, пересылка упакованных данных.](#38-mpi-пересылка-разнотипных-данных-пересылка-упакованных-данных)
- [39. OpenMP: параллельная программа, нити, конструкции для организации параллельных и последовательных секций.](#39-openmp-параллельная-программа-нити-конструкции-для-организации-параллельных-и-последовательных-секций)
- [40. OpenMP: основные конструкции для распределения работы между нитями.](#40-openmp-основные-конструкции-для-распределения-работы-между-нитями)
- [41. OpenMP: основные конструкции для синхронизации нитей и работы с общими и локальными данными.](#41-openmp-основные-конструкции-для-синхронизации-нитей-и-работы-с-общими-и-локальными-данными)
- [42. Графовые модели программ, их взаимосвязь.](#42-графовые-модели-программ-их-взаимосвязь)
- [43. Понятия информационной зависимости и информационной независимости: критерий эквивалентности преобразования программ, ресурс параллелизма программ и алгоритмов.](#43-понятия-информационной-зависимости-и-информационной-независимости-критерий-эквивалентности-преобразования-программ-ресурс-параллелизма-программ-и-алгоритмов)
- [44. Граф алгоритма. Взаимосвязь графа алгоритма и графовых моделей программ.](#44-граф-алгоритма-взаимосвязь-графа-алгоритма-и-графовых-моделей-программ)
- [45. Виды параллелизма: конечный, массовый, координатный, скошенный.](#45-виды-параллелизма-конечный-массовый-координатный-скошенный)
- [46. Ярусно-параллельная форма графа алгоритма, высота, ширина. Каноническая ЯПФ. Высота ЯПФ и длина критического пути графа алгоритма.](#46-ярусно-параллельная-форма-графа-алгоритма-высота-ширина-каноническая-япф-высота-япф-и-длина-критического-пути-графа-алгоритма)
- [47. Зависимость степени параллелизма от формы записи алгоритма (на примере реализации метода Гаусса).](#47-зависимость-степени-параллелизма-от-формы-записи-алгоритма-на-примере-реализации-метода-гаусса)

8 Иерархия памяти, локальность вычислений, локальность использования данных  
--------------------------------------------------
一、内存层次结构 —— “速度-成本-容量”金字塔  
I. Иерархия памяти — пирамида «скорость-цена-объём»  
--------------------------------------------------
1. 构造原则（引用原文）  
   ‑ “Чем выше уровень в иерархии, тем выше скорость работы с данными, тем дороже… объём каждого последующего уровня становится всё меньше”  
   ‑ 寄存器 → L1/L2/L3-кэш → ОЗУ → диск → лента/архив  

   Принцип построения (цитата из исходного текста)  
   ‑ «Чем выше уровень в иерархии, тем выше скорость работы с данными, тем дороже (в пересчёте на слово или байт) обходится память, поэтому объём каждого последующего уровня становится всё меньше и меньше».  
   ‑ Именно поэтому регистры процессора занимают считанные килобайты, кэш-память — единицы мегабайт, основная память — гигабайты, а дисковые и ленточные накопители — терабайты.  

2. 生活类比（引用原文）  
   ‑ 工作台=寄存器，抽屉=缓存，工具柜=主存，仓库=磁盘，外厂订单=磁带  
   ‑ 目的：让“手边”永远放着下一步最可能用的指令和数据  

   Бытовая аналогия (цитата дословно)  
   ‑ «Всё самое необходимое мастер всегда держит под рукой на рабочем столе (регистры), часто используемые предметы хранятся здесь же в ящиках стола (кэш-память), основной набор инструментов лежит в шкафу недалеко от стола (основная память), за чем-то приходится иногда спускаться на склад (дисковая память), а что-то время от времени приходится заказывать даже из другой мастерской (архив на магнитной ленте)».  
   ‑ Эта картина показывает, почему компьютер автоматически «подтягивает» горячие данные ближе к процессору, а холодные — отправляет на медленные, но ёмкие носители.  

--------------------------------------------------
二、计算局部性 —— 时间上的“反复执行同一段代码”  
II. Локальность вычислений — временное повторение одного кода  
--------------------------------------------------
1. 定义与典型场景（引用原文）  
   ‑ “Идеальный пример фрагмента программы с высокой локальностью вычислений — это цикл с телом из одного оператора и большим числом итераций.”  
   ‑ 一旦进入循环，CPU 将无数次取同一条指令 → 适合锁进缓存或预取  

   Определение и пример (цитата)  
   ‑ «Идеальный пример фрагмента программы с высокой локальностью вычислений — это цикл с телом из одного оператора и большим числом итераций.»  
   ‑ Такой цикл позволяет процессору снова и снова обращаться к уже загруженным в кэш инструкциям, минимизируя обращения к медленной основной памяти.  

2. 破坏因素  
   ‑ 频繁过程调用、条件跳转、间接分支 → 指令流“跳远”，局部性下降  

   Факторы, ослабляющие локальность (из текста)  
   ‑ «Вызовы подпрограмм и функций, … использование разного рода условных операторов — это лишь небольшой список причин, по которым свойства локальности в реальных программах могут значительно ослабевать.»  
   ‑ Каждый переход на новый адрес заставляет процессор тратить циклы на выборку новых блоков команд, снижая эффективность кэш-памяти.  

--------------------------------------------------
三、数据局部性 —— 时间+空间上的“反复访问同一数据”  
III. Локальность использования данных — временная и пространственная  
--------------------------------------------------
1. 时间局部性（引用原文）  
   ‑ “Всё то, что используется часто, лучше хранить на регистрах, у которых времена чтения/записи всегда согласованы со скоростью работы процессора.”  
   ‑ 循环计数器、累加变量被反复读写 → 留在寄存器最划算  

   Временная локальность (цитата)  
   ‑ «Всё то, что используется часто, лучше хранить на регистрах, у которых времена чтения/записи всегда согласованы со скоростью работы процессора.»  
   ‑ Компилятор стремится разместить счётчики циклов и промежуточные переменные именно в регистрах, чтобы избежать даже обращений к L1-кэшу.  

2. 空间局部性（引用原文）  
   ‑ “Следующий необходимый для работы программы объект … расположен в оперативной памяти ‘недалеко’ от предыдущего.”  
   ‑ 顺序遍历数组、结构体字段相邻 → 一次缓存行加载可复用多次  

   Пространственная локальность (цитата)  
   ‑ «Следующий необходимый для работы программы объект (команда или операнд) расположен в оперативной памяти “недалеко” от предыдущего.»  
   ‑ При последовательном проходе по массиву процессор предварительно загружает в кэш целую строку (обычно 64 Б), и последующие элементы оказываются «под рукой» без дополнительных промахов.

 9 Закон Амдала, его следствия, суперлинейное ускорение  
--------------------------------------------------
一、阿姆达尔定律（Закон Амдала）  
I. Закон Амдала  
--------------------------------------------------
1. 定律本身  
   ‑ 若程序中必须串行执行的部分占 f，则在 p 个处理器上可获得的最大加速比  
     S ≤ 1 / [f + (1–f)/p]  
   ‑ “9/10 代码并行、1/10 串行 ⇒ 无论如何也超不过 10 倍”  

   Сам закон  
   ‑ Если доля последовательных операций равна f, то максимальное ускорение на p процессорах  
     S ≤ 1 / [f + (1–f)/p]  
   ‑ «9/10 программы параллельно, 1/10 последовательно ⇒ ускорение >10 раз невозможно»  

--------------------------------------------------
二、三大推论（Следствия）  
II. Следствия закона Амдала  
--------------------------------------------------
推论 1 · 性能天花板由最慢环节决定  
├─ “系统最大性能 r_max = s·min π_i” ⇒ 最慢设备拖死全局  
├─ 若串行部分 f>0，则无论 p→∞，S 上限 =1/f  
└─ 先找出瓶颈，再盲目加核  

Следствие 1 · Потолок задан самым медленным звеном  
├─ «r_max = s·min π_i» — самое непроизводительное устройство ограничивает всю систему  
├─ При f>0 предел ускорения =1/f, сколь угодно большое p не поможет  
└─ Сначала ищем узкое место, потом добавляем ядра  

推论 2 · 想整体快 q 倍，得把 (1–1/q) 部分无限加速  
├─ 100× 提速 ⇒ ≥99 % 代码要“瞬间完成”  
├─ 实践中几乎等于重写主要算法  
└─ 指导性能优化优先级：先削串行，再扩并行  

Следствие 2 · Чтобы ускорить в q раз, нужно бесконечно ускорить (1–1/q) часть  
├─ Ускорение в 100× требует ≥99 % «мгновенного» кода  
├─ На практике — почти полная переработка алгоритма  
└─ Приоритет оптимизации: сначала уменьшаем последовательную часть, потом масштабируем параллельную  

推论 3 · 均匀硬件 ⇒ 最大加速 = 设备数 × 最低负载  
├─ 若所有单元 π 相同且完全加载，则 R = s·p_min  
├─ 负载均衡+消除串行=逼近理论极限  
└─ 现代系统常采用“同构核+等长任务片”实现  

Следствие 3 · Однородное железо ⇒ максимум = число устройств × минимальная загруженность  
├─ При π_i≡π и полной загрузке R = s·p_min  
├─ Балансировка нагрузки + устранение серийных участков → предел  
└─ Современные системы: «одинаковые ядра + равные пачки задач»  

--------------------------------------------------
三、超线性加速（Суперлинейное ускорение）  
III. Суперлинейное ускорение  
--------------------------------------------------
现象 · 处理器翻倍，时间不到一半  
├─ 原因：子问题完全落入各核私有缓存，不再访问慢速主存  
├─ 例：256→512 CPU 时，任务由“内存带宽瓶颈”转为“缓存命中”  
└─ 条件：数据量、访问模式、缓存容量恰好匹配——罕见但真实  

Феномен · При удвоении процессоров время падает больше чем в 2 раза  
├─ Причина: подзадачи целиком помещаются в кэш ядер, исчезает обращение к медленной ОЗУ  
├─ Пример: переход от 256 к 512 CPU убирает «узкое место пропускной способности памяти»  
└─ Условие: объём данных, паттерн доступа и ёмкость кэша совпадают — редко, но бывает

## 10. Показатели качества параллельных программ: ускорение, эффективность реализации, эффективность распараллеливания, масштабируемость.  
--------------------------------------------------
一、Ускорение (Speed-up)  
I. Ускорение  
--------------------------------------------------
1. 定义：把同一算法在单处理器上的运行时间 T₁ 与在 s 个设备上并行运行的时间 Tₛ 之比  
   S = T₁ / Tₛ （经典定义）  
   原文通用定义：系统实际总性能 r 与最快设备峰值 πₛ 之比  
   R = r / πₛ ，其中 r 按“Утверждение 2.2”为  
   r = Σᵢ pᵢπᵢ ，0 ≤ pᵢ ≤ 1  

   Определение: отношение времени на одном процессоре T₁ ко времени на s устройствах Tₛ  
   S = T₁ / Tₛ (классика)  
   Общее определение текста: R = r / πₛ ,  
   r = Σᵢ pᵢπᵢ по формуле (2.1)  

2. 上限：R ≤ s，且仅当所有 πᵢ 相同且完全满载 (pᵢ = 1) 时可达 s  

   Верхняя граница: R ≤ s; достигается только при равных πᵢ и полной загрузке  

--------------------------------------------------
二、Эффективность реализации (Implementation Efficiency)  
II. Эффективность реализации  
--------------------------------------------------
1. 同构系统：E = S / s ，表示“每颗处理器平均贡献的加速”  
   0 < E ≤ 1；越接近 1，资源利用率越高  

   Однородная система: E = S / s — доля ускорения на один процессор; 0 < E ≤ 1  

2. 异构系统：按原文定义，系统“负载”即为效率  
   先算权重 aᵢ = πᵢ / Σⱼ πⱼ  
   再得加权负载 r = Σᵢ aᵢpᵢ ，此时 E ≡ r  

   Неоднородная система: по тексту эффективность = загруженность системы  
   aᵢ = πᵢ / Σⱼ πⱼ ,  r = Σᵢ aᵢpᵢ ,  E ≡ r  

--------------------------------------------------
三、Эффективность распараллеливания (Parallelization Efficiency)  
III. Эффективность распараллеливания  
--------------------------------------------------
1. 本质：衡量“并行版本相比串行版本究竟节省了多少时间”，即 S 的大小  

   Суть: насколько параллельная версия сокращает время по сравнению с последовательной  

2. 制约因素：  
   - 负载不均衡 → 部分 pᵢ ≪ 1  
   - 通信/同步开销 → 额外时间拉长 Tₛ  
   - 设备峰值差异 → πᵢ 越小越“拖后腿”  

   Факторы-ограничители:  
   - неравномерная нагрузка → низкие pᵢ  
   - накладные расходы на обмен/синхронизацию  
   - различия πᵢ , малые значения уменьшают r  

3. 调优方向：  
   - 任务划分均衡，使所有 pᵢ → 1  
   - 减少通信量，隐藏延迟  
   - 让慢设备尽可能满负荷或把关键路径放到最快 πₛ 上  

   Направления оптимизации:  
   - сбалансировать задачи, стремиться к pᵢ → 1  
   - сократить объём сообщений и скрывать задержки  
   - загружать медленные устройства полностью или переместить критический путь на быстрое πₛ


13 Компьютеры с общей и распредёленной памятью. Две задачи параллельных вычислений.
--------------------------------------------------
一、计算机按内存组织方式的两大类别  
I. Два класса компьютеров по организации памяти  
--------------------------------------------------
1. 共享内存系统（Shared-Memory, SMP/ccNUMA）  
   ‑ 所有 CPU 通过总线/交叉开关访问同一条物理地址空间  
   ‑ 通信 = 普通 load/store，编程简单，调试快  
   ‑ 瓶颈：总线带宽 & 缓存一致性 → CPU 数量≈数十颗  

   Системы с общей памятью (SMP/ccNUMA)  
   ‑ Все процессоры обращаются к единому физическому адресному пространству  
   ‑ Обмен данными через обычные операции чтения/записи; разработка и отладка проще  
   ‑ Ограничение: пропускная способность шины и когерентность кэшей → десятки ядер  

2. 分布式内存系统（Distributed-Memory, MPP/Cluster）  
   ‑ 每个节点 = CPU + 本地内存；节点间用高速网络或以太网互联  
   ‑ 远程数据只能显式收发消息（MPI/PVM）  
   ‑ 优点：可扩展至成千上万核；缺点：通信延迟高，编程复杂  

   Системы с распределённой памятью (MPP/кластер)  
   ‑ Узел = процессор + локальная память; соединение через высокоскоростную сеть  
   ‑ Доступ к чужим данным только через сообщения (MPI/PVM)  
   ‑ Плюс: линейный масштаб до тысяч ядер; минус: высокая задержка и сложная разработка  

--------------------------------------------------
二、并行计算永恒面对的“两大任务”  
II. Две основные задачи параллельных вычислений  
--------------------------------------------------
任务 1 · 极限性能 – “堆”出最高浮点能力  
├─ 手段：横向扩展（加节点）、提高网络带宽、优化拓扑  
├─ 代表：TOP500 上榜系统、云计算集群、甚至互联网本身  
└─ 关键瓶颈：节点间通信开销 → 需隐藏延迟、提升带宽  

Задача 1 · Максимальная производительность  
├─ Путь: горизонтальное масштабирование, увеличение пропускной способности сети  
├─ Примеры: системы TOP500, облачные кластеры, «Интернет как суперкомпьютер»  
└─ Главное препятствие: накладные расходы на обмен сообщениями → необходимо скрывать задержки  

任务 2 · 易用编程 – 让开发者轻松写出高效并行代码  
├─ 共享内存：OpenMP / Pthreads，逻辑简单，调试快，但 CPU 数量受限  
├─ 分布式：MPI/PVM，可扩展，却需手工分数据、管通信  
└─ 现代折中：节点内 OpenMP + 节点间 MPI，或 ccNUMA“逻辑共享、物理分布”  

Задача 2 · Удобное программирование  
├─ Shared-memory: OpenMP/Pthreads — проще отладка, но ограничено число ядер  
├─ Distributed: MPI/PVM — масштабно, но нужно вручную разбивать данные  
└─ Современный гибрид: внутри узла OpenMP, между узлами MPI; либо ccNUMA  

--------------------------------------------------
速记口诀 / Краткая формула  
--------------------------------------------------
“共享”易编程，难扩展；  
“分布”可扩展，难编程。  
两大任务：①堆性能 ②降开发难度。  

«Shared» — проще код, сложнее масштаб;  
«Distributed» — легко масштаб, сложен код.  
Две задачи: ① максимум FLOPS ② минимум усилий разработчика.




14 UMA, NUMA и ccNUMA архитектуры. Компьютеры Cm*, BBN Butterfly  
--------------------------------------------------
一、三种“内存访问距离”逐渐拉长的体系结构  
I. Три архитектуры с возрастающим «расстоянием» до памяти  
--------------------------------------------------
1. UMA（Uniform Memory Access）  
   ‑ 所有 CPU 通过单一总线或交叉开关访问“等距”的共享内存  
   ‑ 延迟一致，编程简单；瓶颈在总线带宽，规模≈几十核  

   UMA (однородный доступ к памяти)  
   ‑ Все процессоры через общую шину обращаются к памяти с одинаковой задержкой  
   ‑ Простота программирования; узкое место — шина, масштаб ограничен десятками ядер  

2. NUMA（Non-Uniform Memory Access）  
   ‑ 系统 = 多簇“CPU+本地内存”，簇间用高速互连；本地访问远快于远程  
   ‑ 地址空间统一，但速度“不均匀”；规模可扩展到上百 CPU  

   NUMA (неоднородный доступ к памяти)  
   ‑ Система состоит из кластеров «процессор + локальная память», связанных межкластерной шиной  
   ‑ Общее адресное пространство, но разная скорость доступа; масштаб до сотен процессоров  

3. ccNUMA（cache-coherent NUMA）  
   ‑ 在 NUMA 基础上由硬件协议自动保证各 CPU 缓存一致性  
   ‑ 程序员仍视其为“单一大内存”，内核数可扩至 256–1024，且无需改写 SMP 代码  

   ccNUMA (когерентная NUMA)  
   ‑ Аппаратно решается проблема когерентности кэшей; для программиста видна как единое пространство  
   ‑ Позволяет масштабироваться до 256–1024 ядер без изменения SMP-программ  




## 15. Общая структура ccNUMA компьютера на примере Hewlett-Packard Superdome  
--------------------------------------------------  
一、ccNUMA 架构的核心特征  
I. Основные характеристики архитектуры ccNUMA  
--------------------------------------------------  
1. 统一地址空间与非均匀内存访问  
   ‑ 所有 CPU 共享统一的物理地址空间，但访问延迟因内存位置不同而异  
   ‑ 访问本地内存延迟最低，访问其他 cell 的内存延迟较高，跨交换机延迟最高  
   ‑ 硬件自动解决缓存一致性问题，简化编程模型  

   Единое адресное пространство и неравномерный доступ к памяти  
   ‑ Все процессоры имеют доступ к единому физическому адресному пространству, но время доступа к памяти зависит от её местоположения  
   ‑ Минимальная задержка при доступе к локальной памяти, большая — к памяти в других ячейках, максимальная — через коммутаторы  
   ‑ Аппаратное обеспечение когерентности кэшей упрощает разработку  

2. 分层的系统架构  
   ‑ 基于 cell 的设计：每个 cell 包含 4 个处理器、本地内存和专用控制器  
   ‑ Cell 通过高速交叉开关连接，形成大规模并行系统  
   ‑ 系统可扩展到 64 个处理器，支持灵活的配置和扩展  

   Иерархическая архитектура системы  
   ‑ Архитектура на основе ячеек: каждая ячейка включает 4 процессора, локальную память и контроллер  
   ‑ Ячейки соединены высокоскоростными коммутаторами, образуя крупную параллельную систему  
   ‑ Возможность масштабирования до 64 процессоров с гибкой настройкой  

3. 高速互连与扩展性  
   ‑ 使用 8 GB/s 的全双工交叉开关连接 cell，确保高带宽和低延迟通信  
   ‑ 支持多机柜扩展，通过级联实现超过 64 个处理器的系统配置  
   ‑ 提供强大的 I/O 功能和热插拔支持，增强系统的可靠性和可用性  

   Высокоскоростное взаимосоединение и масштабируемость  
   ‑ Использование 8-ГБ/с полнодуплексных коммутаторов для соединения ячеек с низкой задержкой и высокой пропускной способностью  
   ‑ Возможность расширения за пределы одного шкафа, каскадное подключение для систем с более чем 64 процессорами  
   ‑ Поддержка мощных функций ввода/вывода и горячей замены компонентов для повышения надёжности и доступности

   
## 16 Причины уменьшения производительности компьютеров с общей памятью  
--------------------------------------------------  
一、共享内存系统性能下降的六大根源  
I. Шесть основных причин снижения производительности систем с общей памятью  
--------------------------------------------------  
1. 阿姆达尔定律——“串行天花板”  
   ‑ 即使处理器再多，程序里 20 % 的串行段把加速比硬锁在 ≤5 倍  
   ‑ “Если в программе 20 % операций строго последовательны, ускорения больше 5 не бывает”  

   Закон Амдала — «потолок последовательности»  
   ‑ Даже при бесконечном росте числа процессоров последовательная часть ограничивает ускорение ≤5×  

2. NUMA 非一致访存——“远程内存慢几倍”  
   ‑ 本地与远程访问时差可达 5–10 倍，用户必须像分布式系统一样重新排布数据  
   ‑ “Разница во времени доступа к локальной и удалённой памяти в несколько раз потребует… аккуратного программирования”  

   Неоднородность доступа к памяти — «удалённая память в несколько раз медленнее»  
   ‑ Различие в задержках заставляет программиста решать задачи, аналогичные распределению данных в кластерах  

3. 内存访问冲突——“多核撞车”  
   ‑ 多 CPU 同时命中同一内存体或缓存行，硬件串行化，带宽骤降  
   ‑ “Конфликты при обращении к памяти… характерны для многих SMP-систем”  

   Конфликты при доступе к памяти — «многие ядра сталкиваются в одном банке»  
   ‑ Одновременные обращения к одной и той же кэш-линии вызывают сериализацию и падение пропускной способности  

4. 缓存一致性开销——“ccNUMA 的 cc 就是这样来的”  
   ‑ 每颗 CPU 私有缓存必须持续侦听/广播一致性消息，占用互联带宽  
   ‑ “Необходимость обеспечения согласованности содержимого кэш-памяти… первые две буквы в аббревиатуре ccNUMA”  

   Поддержание когерентности кэшей — «отсюда появились первые две буквы ccNUMA»  
   ‑ Чем чаще аппаратура вмешивается, тем выше накладные расходы на протоколы согласования  

5. 负载不均衡——“有人闲、有人累”  
   ‑ 线程任务量差异大，总时间被最慢线程拖长；所幸 SMP 处理器同构，策略简单  
   ‑ “Сбалансированность нагрузки… в случае общей памяти системы почти всегда однородны”  

   Сбалансированность нагрузки — «одинаковые процессоры упрощают стратегию распределения»  
   ‑ Хотя распределение работы проще, неравномерная загрузка всё равно оставляет часть ядер в простое  

6. 单核实际性能落差——“峰值与现实的鸿沟”  
   ‑ 现代 CPU 峰值与实测性能可差十倍；若代码吃不满流水线、向量化单元，整机吞吐量随之下滑  
   ‑ “Реальная производительность отдельного процессора может отличаться… в десятки раз”  

   Реальная производительность ядра — «пиковая и фактическая могут различаться в десятки раз»  
   ‑ Чем полнее используются возможности каждого процессора, тем выше суммарная мощность всей системы



## 17. Коммуникационные топологии. Длина критического пути, связность, сложность.
--------------------------------------------------  
一、 Коммуникационные топологии.
I.  Коммуникационные топологии.
--------------------------------------------------  
在分布式内存计算机中，节点间的互连拓扑结构对通信延迟和算法性能至关重要。主要拓扑结构及其关键指标如下：
В компьютерах с распределённой памятью топология соединения вычислительных узлов критически важна для задержек обмена данными и производительности алгоритмов. Основные топологии и их ключевые метрики:

线性 (Линейка): 所有节点连成一条链。复杂度（链路数）为n-1，平均路径长度约为n/3，连通度为1（移除一条链路即导致网络分裂）。效率低。
Линейка: Все узлы соединены в цепочку. Сложность (число связей) равна n-1, средняя длина пути ~n/3, связность равна 1 (удаление одной связи разрывает сеть). Неэффективна.

环 (Кольцо): 线性拓扑首尾相连形成环。复杂度为n，平均路径长度约为n/6（优于线性）。连通度为2（存在两个独立方向，容错性更高）。传输通常沿最短路径进行，但单点故障时仍可通过反向路径通信。
Кольцо: Линейка, замкнутая в кольцо. Сложность равна n, средняя длина пути ~n/6 (лучше линейки). Связность равна 2 (есть два независимых направления, отказоустойчивее). Передача идёт по кратчайшему пути, но при нарушении одной связи возможна передача в противоположном направлении.

星型 (Звезда): 所有节点连接至一个中心节点（如交换机）。复杂度为n，平均路径长度约为2（外围节点间通信需经中心）。连通度为1（中心节点为单点故障点）。非常适合主从（master/slaves）计算模式。
Звезда: Все узлы соединены с центральным узлом (коммутатором). Сложность равна n, средняя длина пути ~2 (между периферийными узлами через центр). Связность равна 1 (выход из строя центрального узла катастрофичен). Хорошо соответствует схеме мастер/рабочие (master/slaves).

二维网格 (Двумерная решетка): 节点排列为矩形网格，每个节点与上下左右四个近邻相连（边界节点除外）。复杂度约为2n，平均路径长度为O(√n)，连通度为2。曾用于Intel Paragon等系统。
Двумерная решетка: Узлы расположены в прямоугольной сетке, каждый соединён с ближайшими соседями по четырём направлениям (кроме граничных). Сложность ~2n, средняя длина пути O(√n), связность равна 2. Использовалась, например, в Intel Paragon.

二维环面 (Двумерный тор): 网格拓扑的改进，其相对边界环形连接，形成环面。复杂度约为2n，平均路径长度优于网格但仍为O(√n)，连通度增至4。具有更好的对称性和容错性。用于SCI网络（如MSU集群）等。
Двумерный тор: Решётка, у которой противоположные грани соединены, образуя тор. Сложность ~2n, средняя длина пути O(√n) (но меньше, чем у решётки), связность равна 4. Более симметрична и отказоустойчива. Используется, например, в сетях SCI (кластеры НИВЦ МГУ).

二进制超立方体 (Двоичный гиперкуб): 对于N=2^d个节点，每个节点对应d维单位超立方体的一个顶点，并与d个邻居（坐标仅一位不同）相连。复杂度为(N·log₂N)/2，平均路径长度为O(log₂N)，连通度为d=log₂N。它是对数路径长度与线性对数复杂度的优秀折衷，高度对称，且完美匹配许多算法（如折叠法）。实例：Cosmic Cube。
Двоичный гиперкуб: Для N=2^d узлов каждый узел соответствует вершине d-мерного единичного куба и соединён с d соседями (отличающимися в одном бите координаты). Сложность (N·log₂N)/2, средняя длина пути O(log₂N), связность равна d=log₂N. Отличный компромисс: логарифмическая длина пути при росте сложности как N log N. Очень симметричен, хорошо соответствует многим алгоритмам (например, схеме сдваивания). Пример: Cosmic Cube.

--------------------------------------------------  
二、 Длина критического пути, связность, сложность.
I. Длина критического пути, связность, сложность.
--------------------------------------------------  
关键指标定义：
长度 (Диаметр/Длина критического пути): 网络中任意两个最远节点间最短路径所需经过的最小链路数（跳数）。它决定了小消息传输的最坏情况延迟。
连通度 (Связность): 使网络分裂为两个不连通部分所需移除的最小链路数。它衡量了网络的容错能力。
复杂度 (Сложность): 网络中物理链路的总数。它直接关系到硬件实现的成本和复杂性。

Определения ключевых метрик:
Длина критического пути (Диаметр): Минимальное количество элементарных связей (хопов), которые нужно пройти между двумя самыми удалёнными узлами сети. Определяет наихудшую задержку передачи небольшого сообщения.
Связность: Минимальное количество элементарных связей, которое нужно удалить, чтобы сеть распалась на две несвязные части. Показатель отказоустойчивости сети.
Сложность: Общее количество необходимых элементарных связей в сети. Определяет стоимость и сложность реализации аппаратуры.

拓扑选择始终是在追求低延迟/高带宽（小直径、高连通度）与可控成本（低复杂度）之间的权衡。
Выбор топологии — это всегда компромисс между низкой задержкой/высокой пропускной способностью (малый диаметр, высокая связность) и приемлемой стоимостью (невысокая сложность).

