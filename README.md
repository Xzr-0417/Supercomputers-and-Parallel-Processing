- [1. Виды параллельной обработки данных, их особенности.](#1-виды-параллельной-обработки-данных-их-особенности)
- [2. Вычислительно сложные задачи. Примеры оценки вычислительной сложности школьных, научных и промышленных задач.](#2-вычислительно-сложные-задачи-примеры-оценки-вычислительной-сложности-школьных-научных-и-промышленных-задач)
- [3. Современные технологии и парадигмы решения задач с использованием суперкомпьютеров.](#3-современные-технологии-и-парадигмы-решения-задач-с-использованием-суперкомпьютеров)
- [4. Микроэлектроника и архитектура: оценка вклада в увеличение производительности компьютеров.](#4-микроэлектроника-и-архитектура-оценка-вклада-в-увеличение-производительности-компьютеров)
- [5. Архитектура и параметры суперкомпьютерных систем – лидеров списка Top500 (примеры): производительность, эффективность, энергопотребление, энергоэффективность, степень параллельности.](#5-архитектура-и-параметры-суперкомпьютерных-систем--лидеров-списка-top500-примеры-производительность-эффективность-энергопотребление-энергоэффективность-степень-параллельности)
- [6. Этапы решения задач на параллельных вычислительных системах. Пиковая и реальная производительность компьютеров. Понятие суперкомпьютерного кодизайна.](#6-этапы-решения-задач-на-параллельных-вычислительных-системах-пиковая-и-реальная-производительность-компьютеров-понятие-суперкомпьютерного-кодизайна)
- [7. Список Top500: принципы формирования, структура, параметры, рост производительности суперкомпьютерных систем, значения N и N1/2.](#7-список-top500-принципы-формирования-структура-параметры-рост-производительности-суперкомпьютерных-систем-значения-n-и-n12)
- [8. Иерархия памяти, локальность вычислений, локальность использования данных.](#8-иерархия-памяти-локальность-вычислений-локальность-использования-данных)
- [9. Закон Амдала, его следствия, суперлинейное ускорение.](#9-закон-амдала-его-следствия-суперлинейное-ускорение)
- [10. Показатели качества параллельных программ: ускорение, эффективность реализации, эффективность распараллеливания, масштабируемость.](#10-показатели-качества-параллельных-программ-ускорение-эффективность-реализации-эффективность-распараллеливания-масштабируемость)
- [11. Сильная масштабируемость, масштабируемость вширь, слабая масштабируемость. Функция изоэффективности.](#11-сильная-масштабируемость-масштабируемость-вширь-слабая-масштабируемость-функция-изоэффективности)
- [12. Классификация Флинна архитектур вычислительных систем.](#12-классификация-флинна-архитектур-вычислительных-систем)
- [13. Компьютеры с общей и распредёленной памятью. Две задачи параллельных вычислений.](#13-компьютеры-с-общей-и-распредёленной-памятью-две-задачи-параллельных-вычислений)
- [14. UMA, NUMA и ccNUMA архитектуры. Компьютеры Cm*, BBN Butterfly.](#14-uma-numa-и-ccnuma-архитектуры-компьютеры-cm-bbn-butterfly)
- [15. Общая структура ccNUMA компьютера на примере Hewlett-Packard Superdome.](#15-общая-структура-ccnuma-компьютера-на-примере-hewlett-packard-superdome)
- [16. Причины уменьшения производительности компьютеров с общей памятью.](#16-причины-уменьшения-производительности-компьютеров-с-общей-памятью)
- [17. Коммуникационные топологии. Длина критического пути, связность, сложность.](#17-коммуникационные-топологии-длина-критического-пути-связность-сложность)
- [18. Особенности компьютеров семейства CRAY XT: вычислительные узлы, процессорные элементы, коммуникационная сеть.](#18-особенности-компьютеров-семейства-cray-xt-вычислительные-узлы-процессорные-элементы-коммуникационная-сеть)
- [19. Особенности компьютеров семейства CRAY XT: аппаратная поддержка синхронизации параллельных процессов.](#19-особенности-компьютеров-семейства-cray-xt-аппаратная-поддержка-синхронизации-параллельных-процессов)
- [20. Вычислительные кластеры: узлы, коммуникационная сеть (латентность, пропускная способность), способы построения.](#20-вычислительные-кластеры-узлы-коммуникационная-сеть-латентность-пропускная-способность-способы-построения)
- [21. Архитектура суперкомпьютеров СКИФ МГУ «Чебышев», «Ломоносов» и «Ломоносов-2».](#21-архитектура-суперкомпьютеров-скиф-мгу-чебышев-ломоносов-и-ломоносов-2)
- [22. Топология коммуникационной сети «толстое дерево» (fat tree) на примере реализации в суперкомпьютерах СКИФ МГУ «Чебышёв» или «Ломоносов».](#22-топология-коммуникационной-сети-толстое-дерево-fat-tree-на-примере-реализации-в-суперкомпьютерах-скиф-мгу-чебышёв-или-ломоносов)
- [23. Причины уменьшения производительности компьютеров с распределённой памятью.](#23-причины-уменьшения-производительности-компьютеров-с-распределённой-памятью)
- [24. Соотношение между понятиями: функциональное устройство, команда (операция), компьютер и их характеристиками: скалярный, векторный, конвейерный.](#24-соотношение-между-понятиями-функциональное-устройство-команда-операция-компьютер-и-их-характеристиками-скалярный-векторный-конвейерный)
- [25. Векторизация программ, необходимые условия векторизации, препятствия для векторизации.](#25-векторизация-программ-необходимые-условия-векторизации-препятствия-для-векторизации)
- [26. Общая структура векторно-конвейерного компьютера на примере CRAY C90. Параллелизм в архитектуре компьютера CRAY C90.](#26-общая-структура-векторно-конвейерного-компьютера-на-примере-cray-c90-параллелизм-в-архитектуре-компьютера-cray-c90)
- [27. Суперкомпьютеры NEC SX-Aurora TSUBASA.](#27-суперкомпьютеры-nec-sx-aurora-tsubasa)
- [28. Элементы векторной обработки в современных компьютерах. Наборы инструкций MMX, SSE, AVX, AVX2, AVX-512, AltiVec, ARM SVE.](#28-элементы-векторной-обработки-в-современных-компьютерах-наборы-инструкций-mmx-sse-avx-avx2-avx-512-altivec-arm-sve)
- [29. Причины уменьшения производительности векторно-конвейерных компьютеров.](#29-причины-уменьшения-производительности-векторно-конвейерных-компьютеров)
- [30. Метакомпьютер и метакомпьютинг. Отличительные свойства распределенных вычислительных сред.](#30-метакомпьютер-и-метакомпьютинг-отличительные-свойства-распределенных-вычислительных-сред)
- [31. Параллелизм на уровне машинных команд. Суперскалярность, VLIW, EPIC.](#31-параллелизм-на-уровне-машинных-команд-суперскалярность-vliw-epic)
- [32. Производительность вычислительных систем, методы оценки и измерения.](#32-производительность-вычислительных-систем-методы-оценки-и-измерения)
- [33. Технологии параллельного программирования: способы и подходы создания параллельных программ.](#33-технологии-параллельного-программирования-способы-и-подходы-создания-параллельных-программ)
- [34. MPI: параллельная программа, сообщение, понятия групп и коммуникаторов.](#34-mpi-параллельная-программа-сообщение-понятия-групп-и-коммуникаторов)
- [35. MPI: синхронное взаимодействие процессов, виды операторов Send (Bsend, Ssend, Rsend). Тупиковые ситуации.](#35-mpi-синхронное-взаимодействие-процессов-виды-операторов-send-bsend-ssend-rsend-тупиковые-ситуации)
- [36. MPI: асинхронное взаимодействие процессов.](#36-mpi-асинхронное-взаимодействие-процессов)
- [37. MPI: коллективные операции.](#37-mpi-коллективные-операции)
- [38. MPI: пересылка разнотипных данных, пересылка упакованных данных.](#38-mpi-пересылка-разнотипных-данных-пересылка-упакованных-данных)
- [39. OpenMP: параллельная программа, нити, конструкции для организации параллельных и последовательных секций.](#39-openmp-параллельная-программа-нити-конструкции-для-организации-параллельных-и-последовательных-секций)
- [40. OpenMP: основные конструкции для распределения работы между нитями.](#40-openmp-основные-конструкции-для-распределения-работы-между-нитями)
- [41. OpenMP: основные конструкции для синхронизации нитей и работы с общими и локальными данными.](#41-openmp-основные-конструкции-для-синхронизации-нитей-и-работы-с-общими-и-локальными-данными)
- [42. Графовые модели программ, их взаимосвязь.](#42-графовые-модели-программ-их-взаимосвязь)
- [43. Понятия информационной зависимости и информационной независимости: критерий эквивалентности преобразования программ, ресурс параллелизма программ и алгоритмов.](#43-понятия-информационной-зависимости-и-информационной-независимости-критерий-эквивалентности-преобразования-программ-ресурс-параллелизма-программ-и-алгоритмов)
- [44. Граф алгоритма. Взаимосвязь графа алгоритма и графовых моделей программ.](#44-граф-алгоритма-взаимосвязь-графа-алгоритма-и-графовых-моделей-программ)
- [45. Виды параллелизма: конечный, массовый, координатный, скошенный.](#45-виды-параллелизма-конечный-массовый-координатный-скошенный)
- [46. Ярусно-параллельная форма графа алгоритма, высота, ширина. Каноническая ЯПФ. Высота ЯПФ и длина критического пути графа алгоритма.](#46-ярусно-параллельная-форма-графа-алгоритма-высота-ширина-каноническая-япф-высота-япф-и-длина-критического-пути-графа-алгоритма)
- [47. Зависимость степени параллелизма от формы записи алгоритма (на примере реализации метода Гаусса).](#47-зависимость-степени-параллелизма-от-формы-записи-алгоритма-на-примере-реализации-метода-гаусса)

1 Виды параллельной обработки данных, их особенности  
--------------------------------------------------  
一、并行数据处理的两种“范式”  
I. Два вида параллельной обработки данных  
--------------------------------------------------  
1. 并行（Параллелизм / Parallelism）  
   ‑ 把 100 对数同时丢给 N 台“完整加法器”，每台一次算一对，5 拍完成  
   ‑ 时间 = 500 / N 拍；理想加速比 = N  
   ‑ 生活映射：超市 N 台收银机、N 个油枪、N 名土地挖掘工——“人多力量大”  

   Параллелизм  
   ‑ 100 пар чисел одновременно поступают в N одинаковых устройств-сумматоров  
   ‑ Время вычислений = 500 / N тактов; ускорение ≈ N  
   ‑ Аналог из жизни: N касс в магазине, N бензоколонок, N землекопов — «больше рук — больше дела»  

2. 流水线（Конвейерность / Pipelining）  
   ‑ 把一次加法拆成 5 个微操作（比阶、对阶、加尾数、规格化…），每微操占 1 拍  
   ‑ 单条数据仍需 5 拍，但连续 n 条只要 5 + n – 1 拍 → 加速 ≈ 5 倍  
   ‑ 生活映射：一条收银链“扫码→计价→刷卡→找零”，四顾客同时处在不同阶  

   Конвейерность  
   ‑ Операция сложения разбита на 5 микро-ступеней, каждая — 1 такт  
   ‑ Одна операция всё ещё 5 тактов, но серия из n операций требует l + n – 1 тактов → ускорение ≈ l  
   ‑ Аналог: одна касса, где 4 покупателя одновременно на разных этапах обслуживания  

--------------------------------------------------  
二、二者的关键差异与适用场景  
II. Ключевые различия и области применения  
--------------------------------------------------  
差异 1 · 硬件代价  
并行：需 N 套“全功能”单元，面积/功耗线性上升  
流水线：仅把一套硬件切成 l 级，面积增加有限  

Различие 1 · Аппаратные затраты  
Параллелизм: нужно N полных блоков → рост площади и энергии линейный  
Конвейер: один блок, разделённый на l ступеней → рост площади ограничен  

差异 2 · 加速条件  
并行：只有当任务可完全分割成独立子任务时才有效  
流水线：只要运算能拆成固定顺序的子步骤即可持续加速  

Различие 2 · Условия ускорения  
Параллелизм: работает только при полной независимости подзадач  
Конвейер: достаточно фиксированной последовательности микро-шагов  

差异 3 · 瓶颈所在  
并行：最慢的那台单元 + 数据分发/收集开销  
流水线：最慢的那级 ступень 决定整条线速度  

Различие 3 · Узкие места  
Параллелизм: самое медленное устройство + издержки на раздачу/сбор данных  
Конвейер: самая медленная ступень задаёт общий тактовый ритм  

## 2 Вычислительно сложные задачи. Примеры оценки вычислительной сложности школьных, научных и промышленных задач.
--------------------------------------------------
中文  
“计算密集型任务”指那些主要受限于处理器运算速度、而非输入/输出或网络延迟的问题。其特点是：  
1. 需要大量浮点或整数运算；  
2. 运算量随问题规模呈超线性（甚至指数）增长；  
3. 内存带宽与延迟相对不成为瓶颈。  
评价这类任务时，通常用大 O 记号估算计算复杂度，即运算次数与输入规模 n 的关系。   
«Вычислительно сложные задачи» — это задачи, производительность которых ограничена прежде всего скоростью процессора, а не вводом-выводом или задержками сети. Их характерные признаки:  
1. требуется большое количество операций с плавающей или целочисленной точностью;  
2. объём вычислений растёт сверхлинейно (до экспоненциально) с ростом размера задачи;  
3. пропускная способность и задержки памяти не являются узким местом.  
Для оценки таких задач используют асимптотическую сложность в нотации O(f(n)), показывающую число арифметических операций в зависимости от размера входных данных n.  
  
【中小学例子】  
任务：用暴力法求 1…n 中所有数的两两最大公约数之和。  
复杂度：需检查 C(n,2)=n(n−1)/2 对，每对调用欧几里得算法平均 O(log n) 次除法，总复杂度 O(n² log n)。当 n=10⁴ 时运算约 1.5×10⁸ 次，普通笔记本需数秒；n=10⁵ 时已需数百秒，明显属于计算密集型。  
【Школьный пример】  
Задача: найти сумму НОД всех пар чисел от 1 до n «в лоб».  
Сложность: необходимо просмотреть C(n,2)=n(n−1)/2 пар; каждый НОД требует в среднем O(log n) делений. Общая сложность O(n² log n). При n=10⁴ выполняется ≈1.5×10⁸ операций, что занимает несколько секунд на обычном ноутбуке; при n=10⁵ время возрастает до сотен секунд — задача явно вычислительно-ёмкая.  
  
【科学研究例子】  
任务：用直接数值模拟（DNS）计算 3-D 湍流，网格规模 2048³。  
复杂度：每一步时间积分需对每网格点做 ≈1000 次浮点运算，总计 2048³×10³≈8.6×10¹² 次。若需 10⁴ 步，则总运算量 10¹⁷。按 1 PFLOPS（10¹⁵ 次/秒）超级计算机估算，纯 CPU 时间约 10⁵ 秒（≈27 小时），是典型的计算密集型问题。  
【Научный пример】  
Задача: прямое численное моделирование (DNS) 3-D турбулентности на сетке 2048³.  
Сложность: каждый временной шаг требует ≈1000 операций на ячейку, итого 2048³×10³≈8.6×10¹² операций. При 10⁴ шагах общий объём 10¹⁷ FLOP. Суперкомпьютер производительностью 1 PFLOPS (10¹⁵ FLOP/с) потратит ≈10⁵ с (≈27 ч) только на вычисления — классическая вычислительно-ёмкая задача.  
 
【工业例子】  
任务：用有限元方法对整车模型做碰撞显式动力学仿真，单元数 5×10⁶，时间步 1 µs，总时长 0.15 s（150 000 步）。  
复杂度：每个单元每步约 2000 次浮点运算，总运算量 5×10⁶×1.5×10⁵×2×10³=1.5×10¹⁵。现代 100 TFLOPS 集群需约 15 秒纯 CPU 时间；若规模再翻倍（单元+步长减半），运算量增 8 倍，明显受限于计算能力而非 I/O。  
【Промышленный пример】  
Задача: явное динамическое FEM-моделирование лобового удара автомобиля, 5×10⁶ элементов, шаг 1 мкс, общее время 0.15 с (150 000 шагов).  
Сложность: на элемент в шаг требуется ≈2000 FLOP, суммарно 5×10⁶×1.5×10⁵×2×10³=1.5×10¹⁵ операций. Кластер 100 TFLOPS выполнит чистые вычисления за ≈15 с; при удвоении сетки и уполовинивании шага объём вырастает в 8 раз — узкое место именно в вычислениях, а не во вводе-выводе.

## 3 Современные технологии и парадигмы решения задач с использованием суперкомпьютеров.  
--------------------------------------------------  
一、从 CDC 6600 到 E 级系统：并行思想的“硬件载体”演进  
I. От CDC 6600 к E-классу: эволюция носителя параллелизма  
--------------------------------------------------  
1. 功能部件并行 → 众核+异构加速器  
   ‑ 1964 年 CDC 6600 的 10 个“独立功能单元”今天已演化为 CPU 内的多发射流水线 + GPU 内的数千 CUDA-core  
   ‑ 思想不变：让“不同运算类”同时跑起来，用空间换时间  

   Функциональный параллелизм → многозадачные + гетерогенные ускорители  
   ‑ 10 независимых устройств CDC 6600 стали современными multi-issue конвейерами и тысячами ядер GPU  
   ‑ Идея та же: одновременно выполнять разные классы операций  

2. 流水线深度 + 两级存储 → 芯片内 3D 堆叠 + HBM  
   ‑ CDC 7600 把周期缩到 27.5 ns 并引入“计算内存/主存”两级，今天变成 7 nm 制程 + 3D 堆叠高带宽内存 (HBM3)  
   ‑ 目的相同：让数据“更近、更快、更冷”  

   Углубление конвейера + двухуровневая память → 3D-stacked HBM  
   ‑ 27.5 нс CDC 7600 стали 7-нм техпроцессом, а «вычислительная/основная» память — HBM3 в стеке  

3. 阵列并行 → 机柜级“魔方”拓扑  
   ‑ ILLIAC IV 计划 256 PE、实际 64 PE，今天 Top10 超算用 10^6–10^7 核，但“矩阵-网格”思想保留：Dragonfly + Torus 只是更大号“魔方”  

   Матричный параллелизм → кластерные топологии Dragonfly/Torus  
   ‑ 256 ПЭ ILLIAC IV выросли до миллионов ядер, но сетевые топологии всё ещё «квадранты» большого куба  

--------------------------------------------------  
二、现代范式 1：MPI+X —— “节点间消息 + 节点内共享”  
II. Парадигма 1: MPI+X — «сообщения между узлами, разделяемая память внутри»  
--------------------------------------------------  
- 节点外：沿用 1990-s MPI，显式 send/recv 或 RDMA，隐藏延迟靠 Overlap  
- 节点内：OpenMP/CUDA/SYCL，把“功能部件并行”交给编译器与运行时  
- 结果：同一套代码可在 10^3–10^5 节点、10^6–10^7 核上线性扩展  

   ‑ Вне узла: MPI, RDMA, overlap задержек  
   ‑ Внутри узла: OpenMP/CUDA/SYCL, компилятор распределяет «функциональные устройства»  
   ‑ Итог: один и тот же код масштабируется до миллионов ядер  

--------------------------------------------------  
三、现代范式 2：AI-for-Science —— “用神经网络取代子网格”  
III. Парадигма 2: AI-for-Science — «нейросеть вместо подсеточной модели»  
--------------------------------------------------  
- 传统 CFD/气候模型需要 10^8 网格、10^5 核·年；用 CNN/GNN 学习“小尺度-大尺度”映射，可把计算量压到 1 %  
- 训练阶段吃 GPU，推理阶段只需 1–2 节点，实现“用 AI 隐藏浮点墙”  
- 软件栈：PyTorch ⇄ PETSc/Trilinos 耦合，oneAPI Deep Neural Network Library 直接调 MPI  

   ‑ Классические задачи CFD/климат требуют 10^5 ядеро-лет; CNN/GNN сжимают вычисления до 1 %  
   ‑ Обучение на GPU, инференс на 1–2 узлах — «ИИ прячет стену FLOP»  
   ‑ Стек: PyTorch ↔ PETSc/Trilinos, oneAPI-DNN поверх MPI  

--------------------------------------------------  
四、现代范式 3：协同设计 —— “从算法到液冷一起优化”  
IV. Парадигма 3: Co-design — «совместная оптимизация алгоритма и железа»  
--------------------------------------------------  
- 目标：30 MW 以内实现 1 EFLOP/s → 必须 30 GFlops/W  
- 手段：  
  ① 低精度/混合精度迭代 (FP16→FP32→FP64)  
  ② 稀疏矩阵算子 + 结构化网格“剪枝”  
  ③ 3D 封装 + 75 °C 温水液冷，PUE < 1.1  
- 结果：算法重写让“功能部件”利用率 > 90 %，同预算可多买 30 % 节点  

   ‑ Цель: 1 EFLOP/s при 30 МВт → 30 Гфлопс/Вт  
   ‑ Инструменты: mixed-precision, sparse-операторы, 3D-упаковка, жидкостное охлаждение 75 °C  
   ‑ Итог: > 90 % загрузка «функциональных устройств», +30 % узлов в рамках бюджета  

--------------------------------------------------  
五、失败教训：ILLIAC IV 给今天的提醒  
V. Урок ILLIAC IV для сегодняшнего дня  
--------------------------------------------------  
- “太超前”= 风险：256 PE 缩到 64 PE，成本×4，性能÷5  
- 提醒：技术成熟度、软件生态、应用需求必须同步，否则“第一个”也会进博物馆  
- 对策：先用小规模验证 AI/量子/光互联，再扩到全机  

   ‑ «Слишком впереди» = риск: 256→64 PE, цена ×4, производительность ÷5  
   ‑ Вывод: технологии, софт и спрос должны идти в ногу  
   ‑ Метод: пилот-конфигурации → масштабирование только после зрелости  

--------------------------------------------------  
六、小结：思想未变，载体升级  
VI. Итог: идеи те же, носители — новые  
--------------------------------------------------  
CDC 6600 用“10 条独立功能单元”告诉我们：  
“让不同运算同时跑”永远是提速第一性原理。  

今天只是把“功能单元”换成 GPU-core、Tensor-core、量子-qubit，  
把“27.5 ns 周期”换成 7 nm、1.2 GHz、HBM3，  
把“64 个阵列 PE”换成 10^7 核 + Dragonfly，  
但并行计算的终极任务依旧是：  
① 把墙后的延迟藏好；② 让科学家像写串行代码一样写并行世界。  

   ‑ CDC 6600 показал: «одновременно разные операции» — первичный принцип ускорения  
   ‑ Сегодня «устройства» = GPU/TPU/qubit, «27.5 нс» = 7 нм + 1.2 ГГц + HBM3  
   ‑ Задачи те же: скрыть задержки и дать учёным привычный интерфейс для параллельного мира

## 4 Микроэлектроника и архитектура: оценка вклада в увеличение производительности компьютеров  
--------------------------------------------------
一、微电子学：把“单个操作时间”压到极限  
I. Микроэлектроника: сжимаем время одной операции до предела  
--------------------------------------------------
1. 工艺缩小 → 晶体管更快更密  
   ‑ 28 nm → 3 nm，栅延迟下降 5×，单位面积晶体管数增 30×  
   ‑ 直接效果：每次浮点运算所需皮秒级时间缩短，任务1的 10^17 次运算从“月”缩到“小时”  

   Уменьшение техпроцесса → транзисторы быстрее и плотнее  
   ‑ 28 нм → 3 нм, задержка затвора ↓5×, плотность ↑30×  
   ‑ Прямой эффект: сокращение пикосекунд на одну Flop, 10^17 операций задачи 1 сокращаются с «месяцев» до «часов»  

2. 3D 集成与低功耗互连  
   ‑ TSV 硅通孔把内存堆到计算芯粒旁，任务2的 10^6 网格×5 变量数据移动能耗降一个量级  
   ‑ 片上光互连将片间延迟从 100 ns 压到 5 ns，使“每 10 分钟输出全球大气状态”成为实时流  

   3D-интеграция и низкоэнергетические линии связи  
   ‑ TSV объединяет память и вычисления в одном корпусе, энергия пересылки данных задачи 2 ↓10×  
   ‑ Оптические волноводы на кристалле снижают межкристалльную задержку с 100 нс до 5 нс, превращая «снимок атмосферы каждые 10 мин» в потоковую задачу  

--------------------------------------------------
二、体系结构：让“每秒并发操作数”爆炸增长  
II. Архитектура: взрывное увеличение числа параллельных операций в секунду  
--------------------------------------------------
任务 1 · 气候模型：把 10^12 Flop/s 的机器“踩”到 10^14  
├─ 向量流水线+SIMD 宽度 512 bit → 单核 IPC ×8  
├─ 众核扩展：单芯片 80 核，节点 8 路，整机 10^4 核 → 峰值 10^14 Flop/s  
└─ 结果：100 年 2.6×10^7 变量×5.3×10^6 步 = 1.4×10^14 中间量，2 小时跑完  

Задача 1 · Климатическая модель: со 10^12 до 10^14 Flop/s  
├─ Векторные конвейеры и SIMD-512 → IPC↑8×  
├─ Многоядерность: 80 ядер на чипе, 8 сокетов, 10^4 ядер в кластере → пик 10^14 Flop/s  
└─ Итог: 10^14 промежуточных значений за 2 часа вместо суток  

任务 2 · 飞行器绕流：从 10^9 到 3×10^12 Flop/s 有效值  
├─ GPU-like 加速核，每核 10^3 Flop/цикл，1 GHz×10^4 核 = 10^13 理论值  
├─ 数据局部性调度 + 片上光网络，把有效利用率提到 30 % → 3×10^12 有用 Flop/s  
└─ 10^15–10^16 次运算 10^3 s 级完成，实时气动设计成为可能  

Задача 2 · Обтекание ЛА: эффективные 3×10^12 Flop/s  
├─ GPU-подобные ускорители: 10^3 Flop/такт, 1 ГГц×10^4 ядер = 10^13 теоретик  
├─ Локальность данных и оптическая сеть → полезное использование 30 % → 3×10^12 Flop/s  
└─ 10^15–10^16 операций заканчиваются за тысячи секунд, реальный временной масштаб конструкторского цикла  

任务 3 · 通用 100³ 网格：规模每十年 10×，靠“架构-微电子”协同兜底  
├─ 工艺：3 nm 带来 5× 能效，核心数再翻 4×  
├─ 架构：数据流芯片+AI 加速，Flop 利用率 30 % → 80 %  
└─ 同样 10^14 次运算，2025 年能耗与机时均降至 2020 年的 1/20  

Задача 3 · Универсальная 100³-сетка: рост 10×/10 лет компенсируется синергией  
├─ Техпроцесс: 3 нм = 5× энергоэффективности, +4× количество ядер  
├─ Архитектура: dataflow-ускорители + ИИ-блоки, полезное использование Flop 30 % → 80 %  
└─ Те же 10^14 операций в 2025 г. требуют в 20 раз меньше энергии и машинного времени, чем в 2020 г.
以下内容是对您提问的逐条中文翻译与解释，并保留关键数据与实例（仍以2024年11月Top500/Green500榜单为基准）。为方便阅读，先给出一张"速查表"，随后逐条展开说明。

---

5 Архитектура и параметры суперкомпьютерных систем – лидеров списка Top500 (примеры): производительность, эффективность, энергопотребление, энергоэффективность, степень параллельности. 
--------------------------------------------------  
一、从EDSAC到百亿亿次：时钟只快了1 500倍，性能却多出20亿倍  
I. От EDSAC до эксафлопса: тактовая частота выросла лишь в 1 500 раз, а производительность — в 2 млрд  
--------------------------------------------------  
1. 原文回顾  
   “время такта с 2 мкс до 1,3 нс … составляет лишь около 1500 раз … Откуда же взялось остальное? … использование новых решений в архитектуре … параллельной обработки данных”  
   → 性能爆炸的主引擎不是工艺，而是“架构+并行度”。  

   Процитировано: «ускорение тактового времени … всего ~1500×, всё остальное — за счёт архитектурных решений и параллелизма».  

2. 今天Top500冠军把“1500×”进一步压到仅数十倍，却把并行度放大到百万核级，从而再抬3–4个数量级。  

   Современные лидеры Top500 уменьшили тактовый выигрыш до десятков раз, но масштабировали параллелизм до миллионов ядер, добавив ещё 3–4 порядка производительности.  

--------------------------------------------------  
二、Top500“四连击”指标：算得快、耗得少、扩得大、好编程  
II. Четверка ключевых метрик: скорость, масштаб, энергия, удобство  
--------------------------------------------------  
1. 持续性能 Rmax（PFlops/EFlops）  
   ‑ 反映真实应用LINPACK，决定榜单排名  
   Постоянная производительность Rmax — «валюта» списка Top500  

2. 峰值效率 η = Rmax / Rpeak  
   ‑ 看“跑满”程度；>70 % → 网络/平衡优秀  
   Пиковая эффективность η показывает, насколько хорошо «раскачана» система  

3. 总功耗与能效 GFlops/W  
   ‑ Green500同榜比拼；液冷、芯片工艺、低电压直接决定电费  
   Потребляемая мощность и энергоэффективность — фактор эксплуатационных расходов  

4. 并行规模（节点·核·加速器核）  
   ‑ 节点数=网络直径，核数=同时任务，加速器=AI/FP64 boost  
   Степень параллельности = число узлов × ядра × ускорители  

--------------------------------------------------  
三、实例解剖：Frontier、Fugaku、神威·太湖之光  
III. Разбор примеров: Frontier, Fugaku, Sunway TaihuLight  
--------------------------------------------------  
1. Frontier（2024 №1，1.19 EFlops）  
   ‑ 架构：CPU-GPU异构，9 408水冷节点，1×EPYC 7A53 + 4×MI250X  
   ‑ 并行：8.7 M核算力核心，Slingshot-11 100 G fat-tree  
   ‑ 能耗：22.7 MW；能效52.6 GFlops/W → Green500冠军  
   ‑ 经验：把“1500倍时钟”换成“百万倍并行+液冷+功率门控”  

   Frontier: гетерогенные узлы, 8,7 млн ядер, энергоэффективность 52,6 Гфлопс/Вт — пример замены «1500× такт» на «миллионы параллельных потоков + жидкостное охлаждение».  

2. Fugaku（2020-2022 №1，442 PFlops）  
   ‑ 架构：纯CPU同构，158 k节点，A64FX 48+4核+SVE 512-bit  
   ‑ 并行：7.6 M核，6-D torus TofuD，带宽>100 G，延迟<1 µs  
   ‑ 能耗：29.9 MW；能效14.8 GFlops/W  
   ‑ 经验：用“宽向量+高并行网络”弥补无GPU的峰值差距  

   Fugaku: однородные широковекторные CPU + 6-D сеть; показывает, что и без GPU можно выйти на сотни Пфлопс за счёт масштаба и сети.  

3. Sunway TaihuLight（2016 №1，93 PFlops）  
   ‑ 架构：国产申威26010，每芯片+4从核，完全共享内存片上  
   ‑ 并行：10.6 M核，自定义PCIe级互连，胖树+环面混合  
   ‑ 能耗：15.4 MW；能效6 GFlops/W  
   ‑ 经验：把“共享内存”做到芯片级，节点外走消息传递→节点内免MPI  

   Sunway: «shared-memory внутри чипа, message-passing между узлами» — пример гибридного подхода к параллелизму.  

--------------------------------------------------  
四、小结：冠军公式 = 先进工艺 × 新架构 × 百万并行 × 绿色冷却  
IV. Формула лидера: новый техпроцесс × архитектура × 10⁶ ядер × энергоэффективность  
--------------------------------------------------  
1. 时钟红利已近极限，未来每10年工艺只给≈2-3倍；主要增量靠“核-加速器-网络”并行。  
   Тактовый «дефицит» заставляет брать прирост в ядрах, ускорителях и сетях.  

2. 能效成为硬门槛：>30 GFlops/W是进入前十的“门票”。  
   Энергоэффективность >30 Гфлопс/Вт становится пропуском в ТОП-10.  

3. 节点内共享内存+节点间分布式仍是主流混合模型；OpenMP/MPI+X（CUDA/HIP/SYCL）成为事实标准。  
   Гибрид «shared inside — distributed outside» и стек OpenMP/MPI+X остаются доминирующими.

6 Этапы решения задач на параллельных вычислительных системах. Пиковая и реальная производительность компьютеров. Понятие суперкомпьютерного кодизайна.
--------------------------------------------------
一、解题六步法：从公式到可执行代码  
I. Этапы решения задач на параллельных вычислительных системах  
--------------------------------------------------
阶段 1. 明确问题  
   ‑ 把物理/工程现象提炼成“可计算”的目标函数或方程组  
   Этап 1. Формулировка задачи  

阶段 2. 建立数学模型  
   ‑ 决定变量、边界条件、守恒律，写出 PDE/代数/概率模型  
   Этап 2. Построение математической модели объекта исследования  

阶段 3. 选数值方法  
   ‑ 有限差分、有限元、谱方法、蒙特卡洛……  
   Этап 3. Выбор численного (или аналитического) метода решения  

阶段 4. 设计“天生可并行”的算法  
   ‑ 先想好数据切块、通信模式、同步点；再写伪代码  
   Этап 4. Разработка алгоритма, изначально предполагающего распараллеливание  

阶段 5. 选并行编程技术  
   ‑ 节点内线程：OpenMP / Pthreads  
   ‑ 节点间消息：MPI / PVM  
   ‑ 加速器：CUDA / HIP / OpenCL  
   Этап 5. Выбор технологии и модели параллельного программирования (MPI, OpenMP, CUDA, …)  

阶段 6. 编码→调试→上机→性能分析  
   ‑ 用 profiler 看负载均衡、通信瓶颈、效率；必要时回滚到阶段 4  
   Этап 6. Написание и отладка программы, а затем запуск на параллельной ВС и анализ результатов  

--------------------------------------------------
二、峰值性能 vs. 实际性能：为什么“跑不满”？  
II. Пиковая и реальная производительность компьютеров  
--------------------------------------------------
峰值性能（Peak）  
├─ 公式：核心数 × 主频 × 每周期浮点操作数  
├─ 单位：TFLOPS/PFLOPS；TOP500 榜单用的就是这一栏  
└─ 纯粹理论天花板，不考虑任何延迟/带宽/同步  

Пиковая (theoretical peak)  
├─ Считается как «ядра × частота × операций за такт»  
├─ Измеряется в PFLOPS/EFLOPS  
└─ Это максимально возможное число арифметических операций в секунду  

实际持续性能（Sustained）  
├─ 同一程序长时间运行能稳住的 FLOPS  
├─ 受限于：负载不均、通信同步、缓存未命中、内存带宽、I/O  
└─ 效率 = 实际 ÷ 峰值；常见 5 %–60 %，甚至更低  

Реальная (sustained)  
├─ Фактически достигнутый уровень при выполнении конкретного кода  
├─ Причины падения: неидеальное распараллеливание, синхронизации, ожидания данных  
└─ Отношение реальной к пиковой редко превышает 60-70 % и часто падает до 5-10 %  

--------------------------------------------------
三、超算协同设计：让“应用-算法-系统-硬件”同盘迭代  
III. Понятие суперкомпьютерного кодизайна  
--------------------------------------------------
传统套路  
硬件先造好 → 软件凑合 → 性能不足再抱怨  

Классический подход  
Железо готово → ПО подгоняют → Потом удивляются низкой эффективности  

协同设计（Co-design）  
├─ 把“应用需求、算法特征、系统软件、硬件架构”四条线放在一张图里同步迭代  
├─ 目标：让“实际性能”尽可能贴近“峰值性能”  
├─ 手段：  
│  – 一起分析计算热点、通信模式、数据局部性  
│  – 按应用特点增减核数、内存带宽、网络拓扑，甚至设计定制加速单元  
│  – 反复循环：硬件→软件→应用反馈→再改硬件/软件  
└─ 结果：效率提升 3–10 倍，典型案例如 GROMACS、QCD、气候模式  

Суперкомпьютерный кодизайн  
├─ Совместная разработка прикладной задачи, алгоритма, системного ПО и аппаратуры  
├─ Цель – минимизировать разрыв между пиковой и реальной производительностью  
├─ Включает выбор декомпозиции задачи, топологии сети, языков и библиотек  
└─ Благодаря итеративным циклам удаётся получать на реальных приложениях в 3-10 раз большую эффективность

7 Список Top500: принципы формирования, структура, параметры, рост производительности суперкомпьютерных систем, значения N и N1/2. 
--------------------------------------------------  
一、Top500 榜单的“游戏规则”  
I. Принципы формирования списка TOP500  
--------------------------------------------------  
1. 唯一标尺——Linpack HPL 实测峰值 Rmax  
   ‑ 只认“解稠密线性方程组”的实测速度，单位 PFlop/s  
   ‑ 成绩由用户中心自己提交，必须能在真机或“加速模式”上复现  
   ‑ 只有被组委会确认并符合文档要求的测试成绩才会被收录  

   Единый критерий — максимально зафиксированная производительность Rmax при решении плотной системы линейных уравнений (Linpack HPL), измеренная в PFlop/s или TFlop/s.  
   Заявки подаются самими центрами; измерения выполняются либо на уже установленной машине, либо на «бустерном» режиме.  
   Система попадает в список, только если результат подтверждён организаторами и соответствует требованиям к документации.  

--------------------------------------------------  
二、榜单长什么样，机器长什么样  
II. Структура списка и архитектура систем  
--------------------------------------------------  
1. 表格结构——每行一台机器  
   ‑ 字段：排名、系统名、安装地、国家、年份、CPU/加速器、总核数、Rmax、Rpeak、能效、功耗、应用领域  
   ‑ 80–90 % 机器 = 集群（Cluster）：标准服务器 + InfiniBand/Slingshot/以太网  
   ‑ 前十里既有集群，也有专用 MPP；节点内常见 CPU+GPU 异构或纯 CPU 同构  

   В таблице публикуются: место, название, сайт, страна, год установки, процессоры+ускорители, кол-во ядер, Rmax, Rpeak, энергоэффективность, мощность, сегмент применения.  
   Подавляющее большинство систем строится по схеме кластер: коммутатор соединяет стандартные серверные узлы.  
   В «десятке» присутствуют как кластерные, так и MPP-машины с распределённой памятью и специализированной сетью.  

--------------------------------------------------  
三、官方给出的“体检报告”  
III. Параметры каждой системы  
--------------------------------------------------  
Rmax — фактически измеренная производительность (HPL)  
Rpeak — пиковая теоретическая производительность  
Энергоэффективность (GFlop/s per Watt) и общее энергопотребление  
Число процессоров/ядер и тип стека (x86, ARM, Power, SPARC64, SW)  
Сетевой интерконнект (InfiniBand NDR/EDR, Slingshot, Gig-E и др.)  
Область применения: промышленность, исследования, академия, гос-учреждения, вендорские стенды  

--------------------------------------------------  
四、性能曲线——指数级爬坡  
IV. Рост производительности суперкомпьютерных систем  
--------------------------------------------------  
- 15 年历史：  
  – 全部 500 台总算力 ≈ 14 个月翻一番  
  – 榜首系统 ≈ 13 个月翻一番  
  – 第 500 名“门槛”同样 ≈ 13 个月翻一番  
- 2025 年：前 4 台已跨过 1 Exaflop/s 实测大关  
- 核心推手：堆核 + 加速器（CPU+GPU 异构）  

   За 15-летнюю историю наблюдается экспоненциальный рост:  
   суммарная мощность всех 500 машин удваивается примерно каждые 14 мес.;  
   лидер списка — каждые ≈ 13 мес.;  
   500-е место («входной барьер») — чуть быстрее 13 мес.  
   Основные драйверы — увеличение числа ядер в системе и рост процессорной производительности.  
   В 2025 г. первые четыре машины уже преодолели порог 1 Exaflop/s (Rmax).  

--------------------------------------------------  
五、Linpack 的“隐藏彩蛋”——N 与 N½  
V. Значения N и N1/2 в тесте Linpack  
--------------------------------------------------  
N — 能让机器跑出 Rmax 的矩阵阶数（内存越大，N 越大，成绩越高）  
N½ — 成绩降到 Rmax 一半时的矩阵阶数，越小说明系统越均衡  
榜单不直接刊登这两个数，但所有 Rmax 都是在最优 N 下测得  

   N — размер матрицы, при котором достигается максимальная фиксируемая производительность Rmax.  
   N1/2 — «половинный» размер матрицы, при котором производительность составляет ½ от Rmax.  
   Величина N1/2 характеризует, насколько хорошо машина масштабируется при уменьшенной задаче.  
   В публикациях TOP500 сами значения N и N1/2 обычно не табулируются, но именно при оптимальном N измеряется Rmax, который идёт в список.

8 Иерархия памяти, локальность вычислений, локальность использования данных  
--------------------------------------------------
一、内存层次结构 —— “速度-成本-容量”金字塔  
I. Иерархия памяти — пирамида «скорость-цена-объём»  
--------------------------------------------------
1. 构造原则（引用原文）  
   - “层次结构中的级别越高，处理数据的速度就越快，成本就越高……以后每个级别的体积都越来越小。”
   ‑ 寄存器 → L1/L2/L3-кэш → ОЗУ → диск → лента/архив  

   Принцип построения (цитата из исходного текста)  
   ‑ «Чем выше уровень в иерархии, тем выше скорость работы с данными, тем дороже (в пересчёте на слово или байт) обходится память, поэтому объём каждого последующего уровня становится всё меньше и меньше».  
   ‑ Именно поэтому регистры процессора занимают считанные килобайты, кэш-память — единицы мегабайт, основная память — гигабайты, а дисковые и ленточные накопители — терабайты.  

2. 生活类比（引用原文）  
   ‑ 工作台=寄存器，抽屉=缓存，工具柜=主存，仓库=磁盘，外厂订单=磁带  
   ‑ 目的：让“手边”永远放着下一步最可能用的指令和数据  

   Бытовая аналогия (цитата дословно)  
   ‑ «Всё самое необходимое мастер всегда держит под рукой на рабочем столе (регистры), часто используемые предметы хранятся здесь же в ящиках стола (кэш-память), основной набор инструментов лежит в шкафу недалеко от стола (основная память), за чем-то приходится иногда спускаться на склад (дисковая память), а что-то время от времени приходится заказывать даже из другой мастерской (архив на магнитной ленте)».  
   ‑ Эта картина показывает, почему компьютер автоматически «подтягивает» горячие данные ближе к процессору, а холодные — отправляет на медленные, но ёмкие носители.  

--------------------------------------------------
二、计算局部性 —— 时间上的“反复执行同一段代码”  
II. Локальность вычислений — временное повторение одного кода  
--------------------------------------------------
1. 定义与典型场景（引用原文）  
   ‑ “Идеальный пример фрагмента программы с высокой локальностью вычислений — это цикл с телом из одного оператора и большим числом итераций.”  
   ‑ 一旦进入循环，CPU 将无数次取同一条指令 → 适合锁进缓存或预取  

   Определение и пример (цитата)  
   ‑ «Идеальный пример фрагмента программы с высокой локальностью вычислений — это цикл с телом из одного оператора и большим числом итераций.»  
   ‑ Такой цикл позволяет процессору снова и снова обращаться к уже загруженным в кэш инструкциям, минимизируя обращения к медленной основной памяти.  

2. 破坏因素  
   ‑ 频繁过程调用、条件跳转、间接分支 → 指令流“跳远”，局部性下降  

   Факторы, ослабляющие локальность (из текста)  
   ‑ «Вызовы подпрограмм и функций, … использование разного рода условных операторов — это лишь небольшой список причин, по которым свойства локальности в реальных программах могут значительно ослабевать.»  
   ‑ Каждый переход на новый адрес заставляет процессор тратить циклы на выборку новых блоков команд, снижая эффективность кэш-памяти.  

--------------------------------------------------
三、数据局部性 —— 时间+空间上的“反复访问同一数据”  
III. Локальность использования данных — временная и пространственная  
--------------------------------------------------
1. 时间局部性（引用原文）  
   ‑ “Всё то, что используется часто, лучше хранить на регистрах, у которых времена чтения/записи всегда согласованы со скоростью работы процессора.”  
   ‑ 循环计数器、累加变量被反复读写 → 留在寄存器最划算  

   Временная локальность (цитата)  
   ‑ «Всё то, что используется часто, лучше хранить на регистрах, у которых времена чтения/записи всегда согласованы со скоростью работы процессора.»  
   ‑ Компилятор стремится разместить счётчики циклов и промежуточные переменные именно в регистрах, чтобы избежать даже обращений к L1-кэшу.  

2. 空间局部性（引用原文）  
   ‑ “Следующий необходимый для работы программы объект … расположен в оперативной памяти ‘недалеко’ от предыдущего.”  
   ‑ 顺序遍历数组、结构体字段相邻 → 一次缓存行加载可复用多次  

   Пространственная локальность (цитата)  
   ‑ «Следующий необходимый для работы программы объект (команда или операнд) расположен в оперативной памяти “недалеко” от предыдущего.»  
   ‑ При последовательном проходе по массиву процессор предварительно загружает в кэш целую строку (обычно 64 Б), и последующие элементы оказываются «под рукой» без дополнительных промахов.

 9 Закон Амдала, его следствия, суперлинейное ускорение  
--------------------------------------------------
一、阿姆达尔定律（Закон Амдала）  
I. Закон Амдала  
--------------------------------------------------
1. 定律本身  
   ‑ 若程序中必须串行执行的部分占 f，则在 p 个处理器上可获得的最大加速比  
     S ≤ 1 / [f + (1–f)/p]  
   ‑ “9/10 代码并行、1/10 串行 ⇒ 无论如何也超不过 10 倍”  

   Сам закон  
   ‑ Если доля последовательных операций равна f, то максимальное ускорение на p процессорах  
     S ≤ 1 / [f + (1–f)/p]  
   ‑ «9/10 программы параллельно, 1/10 последовательно ⇒ ускорение >10 раз невозможно»  

--------------------------------------------------
二、三大推论（Следствия）  
II. Следствия закона Амдала  
--------------------------------------------------
推论 1 · 性能天花板由最慢环节决定  
├─ “系统最大性能 r_max = s·min π_i” ⇒ 最慢设备拖死全局  
├─ 若串行部分 f>0，则无论 p→∞，S 上限 =1/f  
└─ 先找出瓶颈，再盲目加核  

Следствие 1 · Потолок задан самым медленным звеном  
├─ «r_max = s·min π_i» — самое непроизводительное устройство ограничивает всю систему  
├─ При f>0 предел ускорения =1/f, сколь угодно большое p не поможет  
└─ Сначала ищем узкое место, потом добавляем ядра  

推论 2 · 想整体快 q 倍，得把 (1–1/q) 部分无限加速  
├─ 100× 提速 ⇒ ≥99 % 代码要“瞬间完成”  
├─ 实践中几乎等于重写主要算法  
└─ 指导性能优化优先级：先削串行，再扩并行  

Следствие 2 · Чтобы ускорить в q раз, нужно бесконечно ускорить (1–1/q) часть  
├─ Ускорение в 100× требует ≥99 % «мгновенного» кода  
├─ На практике — почти полная переработка алгоритма  
└─ Приоритет оптимизации: сначала уменьшаем последовательную часть, потом масштабируем параллельную  

推论 3 · 均匀硬件 ⇒ 最大加速 = 设备数 × 最低负载  
├─ 若所有单元 π 相同且完全加载，则 R = s·p_min  
├─ 负载均衡+消除串行=逼近理论极限  
└─ 现代系统常采用“同构核+等长任务片”实现  

Следствие 3 · Однородное железо ⇒ максимум = число устройств × минимальная загруженность  
├─ При π_i≡π и полной загрузке R = s·p_min  
├─ Балансировка нагрузки + устранение серийных участков → предел  
└─ Современные системы: «одинаковые ядра + равные пачки задач»  

--------------------------------------------------
三、超线性加速（Суперлинейное ускорение）  
III. Суперлинейное ускорение  
--------------------------------------------------
现象 · 处理器翻倍，时间不到一半  
├─ 原因：子问题完全落入各核私有缓存，不再访问慢速主存  
├─ 例：256→512 CPU 时，任务由“内存带宽瓶颈”转为“缓存命中”  
└─ 条件：数据量、访问模式、缓存容量恰好匹配——罕见但真实  

Феномен · При удвоении процессоров время падает больше чем в 2 раза  
├─ Причина: подзадачи целиком помещаются в кэш ядер, исчезает обращение к медленной ОЗУ  
├─ Пример: переход от 256 к 512 CPU убирает «узкое место пропускной способности памяти»  
└─ Условие: объём данных, паттерн доступа и ёмкость кэша совпадают — редко, но бывает

## 10. Показатели качества параллельных программ: ускорение, эффективность реализации, эффективность распараллеливания, масштабируемость.  
--------------------------------------------------
一、Ускорение (Speed-up)  
I. Ускорение  
--------------------------------------------------
1. 定义：把同一算法在单处理器上的运行时间 T₁ 与在 s 个设备上并行运行的时间 Tₛ 之比  
   S = T₁ / Tₛ （经典定义）  
   原文通用定义：系统实际总性能 r 与最快设备峰值 πₛ 之比  
   R = r / πₛ ，其中 r 按“Утверждение 2.2”为  
   r = Σᵢ pᵢπᵢ ，0 ≤ pᵢ ≤ 1  

   Определение: отношение времени на одном процессоре T₁ ко времени на s устройствах Tₛ  
   S = T₁ / Tₛ (классика)  
   Общее определение текста: R = r / πₛ ,  
   r = Σᵢ pᵢπᵢ по формуле (2.1)  

2. 上限：R ≤ s，且仅当所有 πᵢ 相同且完全满载 (pᵢ = 1) 时可达 s  

   Верхняя граница: R ≤ s; достигается только при равных πᵢ и полной загрузке  

--------------------------------------------------
二、Эффективность реализации (Implementation Efficiency)  
II. Эффективность реализации  
--------------------------------------------------
1. 同构系统：E = S / s ，表示“每颗处理器平均贡献的加速”  
   0 < E ≤ 1；越接近 1，资源利用率越高  

   Однородная система: E = S / s — доля ускорения на один процессор; 0 < E ≤ 1  

2. 异构系统：按原文定义，系统“负载”即为效率  
   先算权重 aᵢ = πᵢ / Σⱼ πⱼ  
   再得加权负载 r = Σᵢ aᵢpᵢ ，此时 E ≡ r  

   Неоднородная система: по тексту эффективность = загруженность системы  
   aᵢ = πᵢ / Σⱼ πⱼ ,  r = Σᵢ aᵢpᵢ ,  E ≡ r  

--------------------------------------------------
三、Эффективность распараллеливания (Parallelization Efficiency)  
III. Эффективность распараллеливания  
--------------------------------------------------
1. 本质：衡量“并行版本相比串行版本究竟节省了多少时间”，即 S 的大小  

   Суть: насколько параллельная версия сокращает время по сравнению с последовательной  

2. 制约因素：  
   - 负载不均衡 → 部分 pᵢ ≪ 1  
   - 通信/同步开销 → 额外时间拉长 Tₛ  
   - 设备峰值差异 → πᵢ 越小越“拖后腿”  

   Факторы-ограничители:  
   - неравномерная нагрузка → низкие pᵢ  
   - накладные расходы на обмен/синхронизацию  
   - различия πᵢ , малые значения уменьшают r  

3. 调优方向：  
   - 任务划分均衡，使所有 pᵢ → 1  
   - 减少通信量，隐藏延迟  
   - 让慢设备尽可能满负荷或把关键路径放到最快 πₛ 上  

   Направления оптимизации:  
   - сбалансировать задачи, стремиться к pᵢ → 1  
   - сократить объём сообщений и скрывать задержки  
   - загружать медленные устройства полностью или переместить критический путь на быстрое πₛ

## 11. Сильная масштабируемость, масштабируемость вширь, слабая масштабируемость. Функция изоэффективности.
--------------------------------------------------
一、强可扩展性（Сильная масштабируемость）
--------------------------------------------------
定义：当问题的计算复杂度 W 固定不变时，系统性能 R 随处理器数量 p 增加而提升的能力。  
衡量方式：性能增速 ≈ 处理器增速 ⇒ 理想斜率 1。  
原文引用：  
“Сильная масштабируемость — зависимость производительности R от количества процессоров p при фиксированной вычислительной сложности задачи (W = const)。”  
关键指标：强扩展曲线越贴近线性，并行效率损失越小；一旦出现明显下弯，即进入“通信/同步主导”区。  

Определение: способность увеличивать R при росте p без изменения общего объёма работы W.  
Источник: «Сильная масштабируемость… при W = const».  
Ключевой показатель: чем ближе прирост R к пропорциональному, тем выше сильная масштабируемость системы.  

--------------------------------------------------
二、宽度可扩展性（Масштабируемость вширь）
--------------------------------------------------
定义：在处理器数量 p 固定的情况下，性能 R 随问题规模（计算复杂度 W）增大而提升的能力。  
原文引用：  
“Масштабируемость вширь – зависимость производительности R от вычислительной сложности задачи W при фиксированном числе процессоров (p = const)。”  
应用场景：单节点内存/算力受限时，通过“让问题变大”来充分发挥现有资源，常用于科学计算弱扩展实验的“横向切片”。  

Определение: рост R при увеличении W без добавления процессоров.  
Источник: «Масштабируемость вширь … при p = const».  
Применение: позволяет оценить, насколько увеличение данных помогает загрузить фиксированный набор ядер.  

--------------------------------------------------
三、弱可扩展性（Слабая масштабируемость）
--------------------------------------------------
定义：当“每处理器工作量”保持恒定（W/p = const）时，性能 R 随处理器数量 p 增加而提升的能力。  
原文引用：  
“Слабая масштабируемость — зависимость производительности R от количества процессоров p при фиксированной вычислительной сложности задачи в пересчёте на один процессор (W/p = const)。”  
理想结果：R 与 p 成线性 ⇒ 并行效率 E 几乎不变；常用于验证算法在“数据与 CPU 同步放大”时是否仍保持恒定效率。  

Определение: сохранение постоянной работы на ядро при увеличении p.  
Источник: «Слабая масштабируемость … при W/p = const».  
Цель: проверить, способна ли система удерживать эффективность при одновременном росте задачи и ресурсов.  

--------------------------------------------------
四、等效率函数（Функция изоэффективности）
--------------------------------------------------
定义：为维持恒定并行效率 E，问题的计算复杂度 W 必须随处理器数 p 按何种函数增长。  
原文引用：  
“Определим, в какой степени должна увеличиваться вычислительная сложность задачи W в зависимости от числа процессоров p, чтобы эффективность распараллеливания E оставалась постоянной。”  
公式骨架：W = K·T₀(p)，其中 K=E/(1–E)，T₀ 为并行额外开销；函数 W(p) 的增长越慢，系统越易扩展。  
用途：定量比较不同算法/机器的可扩展性——“等效率曲线越平缓，规模上限越高”。  

Определение: зависимость W(p), обеспечивающая неизменное E.  
Источник: «…функция изоэффективности (isoefficiency function)».  
Применение: чем медленнее растёт W при росте p, тем лучше масштабируемость конкретной вычислительной системы.

## 12. Классификация Флинна архитектур вычислительных систем  
--------------------------------------------------
一、弗林分类法：按“指令流”和“数据流”的四种组合  
I. Классификация Флинна: четыре комбинации «потоков команд и данных»  
--------------------------------------------------
1. SISD（单指令单数据）  
   ‑ 单核CPU的“经典”顺序执行：每条时钟周期只处理一组数据  
   ‑ 文中场景：若找不到可并行计算的分支，则多处理器也无意义  

   SISD (Single Instruction — Single Data)  
   ‑ Классическое последовательное ядро: за такт — одна команда над одними данными  
   ‑ Из текста: «Если не решить первую задачу, то бессмысленно использовать многопроцессорные конфигурации»  

2. SIMD（单指令多数据）  
   ‑ 同一指令同时作用在多个数据元素上——GPU、向量指令集SSE/AVX  
   ‑ 适合规则数据并行；文中暗示：物理、化学家无需深研并行即可调用  

   SIMD (Single Instruction — Multiple Data)  
   ‑ Одна и та же команда одновременно над множеством данных — GPU, SSE/AVX  
   ‑ Упомянуто: «физик, химик ... не захочет осваивать новую специальность», но может использовать готовые SIMD-библиотеки  

3. MISD（多指令单数据）  
   ‑ 多条指令对同一数据流进行处理——纯体系结构罕见，多用于容错冗余  
   ‑ 文中未直接出现，但归入“иногда интересны своей идеей”  

   MISD (Multiple Instructions — Single Data)  
   ‑ Разные команды обрабатывают один поток данных; чистый вид почти не применяется  
   ‑ В статье: «другие интересны своей идеей» — как раз про такие экзотические схемы  

4. MIMD（多指令多数据）  
   ‑ 各核心独立取指、独立数据——现代多核/集群/超级计算机  
   ‑ 正是文中“三大任务”针对的对象：找并行、分数据、协调通信  

   MIMD (Multiple Instructions — Multiple Data)  
   ‑ Ядра исполняют разные команды над разными данными — кластеры, TOP500  
   ‑ Именно здесь «нужно решить три основные задачи: найти параллелизм, распределить данные, согласовать обмен»  

--------------------------------------------------
二、弗林分类与“效率-便携-开发速度”权衡  
II. Таксономия Флинна и компромисс «эффективность-переносимость-время разработки»  
--------------------------------------------------
- SIMD/MIMD 都能“快速求解”，但技术选型决定能否“充分利用潜力”  
  «...если технология не позволяет использовать весь потенциал, нужно ли её осваивать?»  

- 高可移植性往往牺牲极致效率  
  «...вы будете вынуждены пойти на компромисс между временем разработки, эффективностью и переносимостью»  

- 每一代新MIMD平台都迫使程序重写  
  «...программы переписываются, и так по кругу в течение многих лет»  

- 结论：先按弗林框定架构类型，再在同一类型内权衡“开发快”还是“跑得快”  
  «...если выбор будет правильным, проблем будет меньше»

13 Компьютеры с общей и распредёленной памятью. Две задачи параллельных вычислений.
--------------------------------------------------
一、计算机按内存组织方式的两大类别  
I. Два класса компьютеров по организации памяти  
--------------------------------------------------
1. 共享内存系统（Shared-Memory, SMP/ccNUMA）  
   ‑ 所有 CPU 通过总线/交叉开关访问同一条物理地址空间  
   ‑ 通信 = 普通 load/store，编程简单，调试快  
   ‑ 瓶颈：总线带宽 & 缓存一致性 → CPU 数量≈数十颗  

   Системы с общей памятью (SMP/ccNUMA)  
   ‑ Все процессоры обращаются к единому физическому адресному пространству  
   ‑ Обмен данными через обычные операции чтения/записи; разработка и отладка проще  
   ‑ Ограничение: пропускная способность шины и когерентность кэшей → десятки ядер  

2. 分布式内存系统（Distributed-Memory, MPP/Cluster）  
   ‑ 每个节点 = CPU + 本地内存；节点间用高速网络或以太网互联  
   ‑ 远程数据只能显式收发消息（MPI/PVM）  
   ‑ 优点：可扩展至成千上万核；缺点：通信延迟高，编程复杂  

   Системы с распределённой памятью (MPP/кластер)  
   ‑ Узел = процессор + локальная память; соединение через высокоскоростную сеть  
   ‑ Доступ к чужим данным только через сообщения (MPI/PVM)  
   ‑ Плюс: линейный масштаб до тысяч ядер; минус: высокая задержка и сложная разработка  

--------------------------------------------------
二、并行计算永恒面对的“两大任务”  
II. Две основные задачи параллельных вычислений  
--------------------------------------------------
任务 1 · 极限性能 – “堆”出最高浮点能力  
├─ 手段：横向扩展（加节点）、提高网络带宽、优化拓扑  
├─ 代表：TOP500 上榜系统、云计算集群、甚至互联网本身  
└─ 关键瓶颈：节点间通信开销 → 需隐藏延迟、提升带宽  

Задача 1 · Максимальная производительность  
├─ Путь: горизонтальное масштабирование, увеличение пропускной способности сети  
├─ Примеры: системы TOP500, облачные кластеры, «Интернет как суперкомпьютер»  
└─ Главное препятствие: накладные расходы на обмен сообщениями → необходимо скрывать задержки  

任务 2 · 易用编程 – 让开发者轻松写出高效并行代码  
├─ 共享内存：OpenMP / Pthreads，逻辑简单，调试快，但 CPU 数量受限  
├─ 分布式：MPI/PVM，可扩展，却需手工分数据、管通信  
└─ 现代折中：节点内 OpenMP + 节点间 MPI，或 ccNUMA“逻辑共享、物理分布”  

Задача 2 · Удобное программирование  
├─ Shared-memory: OpenMP/Pthreads — проще отладка, но ограничено число ядер  
├─ Distributed: MPI/PVM — масштабно, но нужно вручную разбивать данные  
└─ Современный гибрид: внутри узла OpenMP, между узлами MPI; либо ccNUMA  

--------------------------------------------------
速记口诀 / Краткая формула  
--------------------------------------------------
“共享”易编程，难扩展；  
“分布”可扩展，难编程。  
两大任务：①堆性能 ②降开发难度。  

«Shared» — проще код, сложнее масштаб;  
«Distributed» — легко масштаб, сложен код.  
Две задачи: ① максимум FLOPS ② минимум усилий разработчика.




14 UMA, NUMA и ccNUMA архитектуры. Компьютеры Cm*, BBN Butterfly  
--------------------------------------------------
一、三种“内存访问距离”逐渐拉长的体系结构  
I. Три архитектуры с возрастающим «расстоянием» до памяти  
--------------------------------------------------
1. UMA（Uniform Memory Access）  
   ‑ 所有 CPU 通过单一总线或交叉开关访问“等距”的共享内存  
   ‑ 延迟一致，编程简单；瓶颈在总线带宽，规模≈几十核  

   UMA (однородный доступ к памяти)  
   ‑ Все процессоры через общую шину обращаются к памяти с одинаковой задержкой  
   ‑ Простота программирования; узкое место — шина, масштаб ограничен десятками ядер  

2. NUMA（Non-Uniform Memory Access）  
   ‑ 系统 = 多簇“CPU+本地内存”，簇间用高速互连；本地访问远快于远程  
   ‑ 地址空间统一，但速度“不均匀”；规模可扩展到上百 CPU  

   NUMA (неоднородный доступ к памяти)  
   ‑ Система состоит из кластеров «процессор + локальная память», связанных межкластерной шиной  
   ‑ Общее адресное пространство, но разная скорость доступа; масштаб до сотен процессоров  

3. ccNUMA（cache-coherent NUMA）  
   ‑ 在 NUMA 基础上由硬件协议自动保证各 CPU 缓存一致性  
   ‑ 程序员仍视其为“单一大内存”，内核数可扩至 256–1024，且无需改写 SMP 代码  

   ccNUMA (когерентная NUMA)  
   ‑ Аппаратно решается проблема когерентности кэшей; для программиста видна как единое пространство  
   ‑ Позволяет масштабироваться до 256–1024 ядер без изменения SMP-программ  




## 15. Общая структура ccNUMA компьютера на примере Hewlett-Packard Superdome  
--------------------------------------------------  
一、ccNUMA 架构的核心特征  
I. Основные характеристики архитектуры ccNUMA  
--------------------------------------------------  
1. 统一地址空间与非均匀内存访问  
   ‑ 所有 CPU 共享统一的物理地址空间，但访问延迟因内存位置不同而异  
   ‑ 访问本地内存延迟最低，访问其他 cell 的内存延迟较高，跨交换机延迟最高  
   ‑ 硬件自动解决缓存一致性问题，简化编程模型  

   Единое адресное пространство и неравномерный доступ к памяти  
   ‑ Все процессоры имеют доступ к единому физическому адресному пространству, но время доступа к памяти зависит от её местоположения  
   ‑ Минимальная задержка при доступе к локальной памяти, большая — к памяти в других ячейках, максимальная — через коммутаторы  
   ‑ Аппаратное обеспечение когерентности кэшей упрощает разработку  

2. 分层的系统架构  
   ‑ 基于 cell 的设计：每个 cell 包含 4 个处理器、本地内存和专用控制器  
   ‑ Cell 通过高速交叉开关连接，形成大规模并行系统  
   ‑ 系统可扩展到 64 个处理器，支持灵活的配置和扩展  

   Иерархическая архитектура системы  
   ‑ Архитектура на основе ячеек: каждая ячейка включает 4 процессора, локальную память и контроллер  
   ‑ Ячейки соединены высокоскоростными коммутаторами, образуя крупную параллельную систему  
   ‑ Возможность масштабирования до 64 процессоров с гибкой настройкой  

3. 高速互连与扩展性  
   ‑ 使用 8 GB/s 的全双工交叉开关连接 cell，确保高带宽和低延迟通信  
   ‑ 支持多机柜扩展，通过级联实现超过 64 个处理器的系统配置  
   ‑ 提供强大的 I/O 功能和热插拔支持，增强系统的可靠性和可用性  

   Высокоскоростное взаимосоединение и масштабируемость  
   ‑ Использование 8-ГБ/с полнодуплексных коммутаторов для соединения ячеек с низкой задержкой и высокой пропускной способностью  
   ‑ Возможность расширения за пределы одного шкафа, каскадное подключение для систем с более чем 64 процессорами  
   ‑ Поддержка мощных функций ввода/вывода и горячей замены компонентов для повышения надёжности и доступности

   
## 16 Причины уменьшения производительности компьютеров с общей памятью  
--------------------------------------------------  
一、共享内存系统性能下降的六大根源  
I. Шесть основных причин снижения производительности систем с общей памятью  
--------------------------------------------------  
1. 阿姆达尔定律——“串行天花板”  
   ‑ 即使处理器再多，程序里 20 % 的串行段把加速比硬锁在 ≤5 倍  
   ‑ “Если в программе 20 % операций строго последовательны, ускорения больше 5 не бывает”  

   Закон Амдала — «потолок последовательности»  
   ‑ Даже при бесконечном росте числа процессоров последовательная часть ограничивает ускорение ≤5×  

2. NUMA 非一致访存——“远程内存慢几倍”  
   ‑ 本地与远程访问时差可达 5–10 倍，用户必须像分布式系统一样重新排布数据  
   ‑ “Разница во времени доступа к локальной и удалённой памяти в несколько раз потребует… аккуратного программирования”  

   Неоднородность доступа к памяти — «удалённая память в несколько раз медленнее»  
   ‑ Различие в задержках заставляет программиста решать задачи, аналогичные распределению данных в кластерах  

3. 内存访问冲突——“多核撞车”  
   ‑ 多 CPU 同时命中同一内存体或缓存行，硬件串行化，带宽骤降  
   ‑ “Конфликты при обращении к памяти… характерны для многих SMP-систем”  

   Конфликты при доступе к памяти — «многие ядра сталкиваются в одном банке»  
   ‑ Одновременные обращения к одной и той же кэш-линии вызывают сериализацию и падение пропускной способности  

4. 缓存一致性开销——“ccNUMA 的 cc 就是这样来的”  
   ‑ 每颗 CPU 私有缓存必须持续侦听/广播一致性消息，占用互联带宽  
   ‑ “Необходимость обеспечения согласованности содержимого кэш-памяти… первые две буквы в аббревиатуре ccNUMA”  

   Поддержание когерентности кэшей — «отсюда появились первые две буквы ccNUMA»  
   ‑ Чем чаще аппаратура вмешивается, тем выше накладные расходы на протоколы согласования  

5. 负载不均衡——“有人闲、有人累”  
   ‑ 线程任务量差异大，总时间被最慢线程拖长；所幸 SMP 处理器同构，策略简单  
   ‑ “Сбалансированность нагрузки… в случае общей памяти системы почти всегда однородны”  

   Сбалансированность нагрузки — «одинаковые процессоры упрощают стратегию распределения»  
   ‑ Хотя распределение работы проще, неравномерная загрузка всё равно оставляет часть ядер в простое  

6. 单核实际性能落差——“峰值与现实的鸿沟”  
   ‑ 现代 CPU 峰值与实测性能可差十倍；若代码吃不满流水线、向量化单元，整机吞吐量随之下滑  
   ‑ “Реальная производительность отдельного процессора может отличаться… в десятки раз”  

   Реальная производительность ядра — «пиковая и фактическая могут различаться в десятки раз»  
   ‑ Чем полнее используются возможности каждого процессора, тем выше суммарная мощность всей системы



## 17. Коммуникационные топологии. Длина критического пути, связность, сложность.

--------------------------------------------------
一、主要拓扑结构及其关键指标  
I. Основные топологии и их ключевые метрики  
--------------------------------------------------
1. **线性 (Линейка)**  
   ‑ 所有节点连成一条链  
   ‑ 复杂度（链路数）：n-1  
   ‑ 平均路径长度：≈n/3  
   ‑ 连通度：1（移除一条链路即导致网络分裂）  
   ‑ 效率低  

   **Линейка**  
   ‑ Все узлы соединены в цепочку  
   ‑ Сложность (число связей): n-1  
   ‑ Средняя длина пути: ~n/3  
   ‑ Связность: 1 (удаление одной связи разрывает сеть)  
   ‑ Неэффективна  

2. **环 (Кольцо)**  
   ‑ 线性拓扑首尾相连形成环  
   ‑ 复杂度：n  
   ‑ 平均路径长度：≈n/6（优于线性）  
   ‑ 连通度：2（存在两个独立方向，容错性更高）  
   ‑ 传输通常沿最短路径，单点故障时可反向通信  

   **Кольцо**  
   ‑ Линейка, замкнутая в кольцо  
   ‑ Сложность: n  
   ‑ Средняя длина пути: ~n/6 (лучше линейки)  
   ‑ Связность: 2 (есть два независимых направления, отказоустойчивее)  
   ‑ Передача идёт по кратчайшему пути, но при нарушении одной связи возможна передача в противоположном направлении  

3. **星型 (Звезда)**  
   ‑ 所有节点连接至一个中心节点（如交换机）  
   ‑ 复杂度：n  
   ‑ 平均路径长度：≈2（外围节点间通信需经中心）  
   ‑ 连通度：1（中心节点为单点故障点）  
   ‑ 非常适合主从（master/slaves）计算模式  

   **Звезда**  
   ‑ Все узлы соединены с центральным узлом (коммутатором)  
   ‑ Сложность: n  
   ‑ Средняя длина пути: ~2 (между периферийными узлами через центр)  
   ‑ Связность: 1 (выход из строя центрального узла катастрофичен)  
   ‑ Хорошо соответствует схеме мастер/рабочие (master/slaves)  

4. **二维网格 (Двумерная решетка)**  
   ‑ 节点排列为矩形网格，每个节点与四个近邻相连（边界节点除外）  
   ‑ 复杂度：≈2n  
   ‑ 平均路径长度：O(√n)  
   ‑ 连通度：2  
   ‑ 曾用于Intel Paragon等系统  

   **Двумерная решетка**  
   ‑ Узлы расположены в прямоугольной сетке, каждый соединён с ближайшими соседями по четырём направлениям (кроме граничных)  
   ‑ Сложность: ~2n  
   ‑ Средняя длина пути: O(√n)  
   ‑ Связность: 2  
   ‑ Использовалась, например, в Intel Paragon  

5. **二维环面 (Двумерный тор)**  
   ‑ 网格拓扑的改进，相对边界环形连接，形成环面  
   ‑ 复杂度：≈2n  
   ‑ 平均路径长度：O(√n)（优于网格）  
   ‑ 连通度：4  
   ‑ 具有更好的对称性和容错性，用于SCI网络等  

   **Двумерный тор**  
   ‑ Решётка, у которой противоположные грани соединены, образуя тор  
   ‑ Сложность: ~2n  
   ‑ Средняя длина пути: O(√n) (но меньше, чем у решётки)  
   ‑ Связность: 4  
   ‑ Более симметрична и отказоустойчива, используется, например, в сетях SCI  

6. **二进制超立方体 (Двоичный гиперкуб)**  
   ‑ 对于N=2^d个节点，每个节点对应d维单位超立方体的一个顶点  
   ‑ 每个节点与d个邻居（坐标仅一位不同）相连  
   ‑ 复杂度：(N·log₂N)/2  
   ‑ 平均路径长度：O(log₂N)  
   ‑ 连通度：d=log₂N  
   ‑ 对数路径长度与线性对数复杂度的优秀折衷，高度对称，完美匹配许多算法（如折叠法）  

   **Двоичный гиперкуб**  
   ‑ Для N=2^d узлов каждый узел соответствует вершине d-мерного единичного куба  
   ‑ Каждый узел соединён с d соседями (отличающимися в одном бите координаты)  
   ‑ Сложность: (N·log₂N)/2  
   ‑ Средняя длина пути: O(log₂N)  
   ‑ Связность: d=log₂N  
   ‑ Отличный компромисс: логарифмическая длина пути при росте сложности как N log N, очень симметричен, хорошо соответствует многим алгоритмам (например, схеме сдваивания)  

--------------------------------------------------
二、关键指标定义  
II. Определения ключевых метрик  
--------------------------------------------------
1. **长度 (Диаметр/Длина критического пути)**  
   ‑ 网络中任意两个最远节点间最短路径所需经过的最小链路数（跳数）  
   ‑ 决定了小消息传输的最坏情况延迟  

   **Длина критического пути (Диаметр)**  
   ‑ Минимальное количество элементарных связей (хопов), которые нужно пройти между двумя самыми удалёнными узлами сети  
   ‑ Определяет наихудшую задержку передачи небольшого сообщения  

2. **连通度 (Связность)**  
   ‑ 使网络分裂为两个不连通部分所需移除的最小链路数  
   ‑ 衡量了网络的容错能力  

   **Связность**  
   ‑ Минимальное количество элементарных связей, которое нужно удалить, чтобы сеть распалась на две несвязные части  
   ‑ Показатель отказоустойчивости сети  

3. **复杂度 (Сложность)**  
   ‑ 网络中物理链路的总数  
   ‑ 直接关系到硬件实现的成本和复杂性  

   **Сложность**  
   ‑ Общее количество необходимых элементарных связей в сети  
   ‑ Определяет стоимость и сложность реализации аппаратуры  

--------------------------------------------------
**核心总结 / Ключевой вывод**  
--------------------------------------------------
拓扑选择是在低延迟/高带宽（小直径、高连通度）与可控成本（低复杂度）之间的权衡。  

Выбор топологии — это всегда компромисс между низкой задержкой/высокой пропускной способностью (малый диаметр, высокая связность) и приемлемой стоимостью (невысокая сложность).


## 18. Особенности компьютеров семейства CRAY XT: вычислительные узлы, процессорные элементы, коммуникационная сеть.
--------------------------------------------------
一、 Вычислительные узлы (计算节点)
I. Вычислительные узлы
--------------------------------------------------
-  **组成与架构**: 每个计算节点包含两个独立的处理器元素(ПЭ)、一个网络接口和一个块传输控制器(DMA)。节点作为资源分配的基本单位。
    -  **Состав и архитектура**: Каждый вычислительный узел содержит два независимых процессорных элемента (ПЭ), сетевой интерфейс и контроллер блочных передач (DMA). Узел — базовая единица выделения ресурсов.

-  **节点分类与功能**:
    -  **管理节点 (Управляющие узлы)**: 运行多用户环境，处理单进程程序和脚本。
    -  **系统节点 (Узлы ОС)**: 运行操作系统服务，如文件系统，用户无法直接访问。
    -  **计算节点 (Вычислительные узлы)**: 以独占模式执行用户并行程序，程序运行时节点被锁定。
    -  **Классификация и функции узлов**:
        -  **Управляющие узлы**: Многопользовательский режим, выполнение однопроцессорных задач и скриптов.
        -  **Узлы ОС**: Системные сервисы (напр., файловая система), недоступны пользователям напрямую.
        -  **Вычислительные узлы**: Монопольное выполнение параллельных программ пользователя; узлы закрепляются за программой до её завершения.

--------------------------------------------------
二、 Процессорные элементы (处理器元素)
II. Процессорные элементы
--------------------------------------------------
-  **核心组件**: 每个ПЭ包含一个DEC Alpha 64位RISC微处理器(150 MHz)、本地内存(8M字)和支持电路。
    -  **Основные компоненты**: Каждый ПЭ включает 64-разрядный RISC-микропроцессор DEC Alpha (150 МГц), локальную память (8 Мслов) и вспомогательные схемы.

-  **内存模型**: 物理上分布式，逻辑上共享。每个ПЭ可直接访问任意其他ПЭ的内存，远程访问延迟约为本地访问的6倍。
    -  **Модель памяти**: Физически распределённая, но логически разделяемая память. Любой ПЭ может обращаться к памяти любого другого ПЭ; удалённый доступ ~ в 6 раз медленнее локального.

-  **辅助硬件**: 块传输控制器(DMA)支持异步数据传输，允许在ПЭ间移动数据而不中断其计算。
    -  **Вспомогательная аппаратура**: Контроллер блочных передач (DMA) поддерживает асинхронный обмен данными между ПЭ без прерывания их работы.

--------------------------------------------------
三、 Коммуникационная сеть (通信网络)
III. Коммуникационная сеть
--------------------------------------------------
-  **拓扑结构**: 双向三维环面。每个节点通过6个链路连接邻居，边界节点通过环绕连接，形成对称拓扑。
    -  **Топология**: Двунаправленный трёхмерный тор. Каждый узел соединён с 6 соседями; граничные узлы связаны «наоборот», образуя симметричную структуру.

-  **关键特性**:
    -  **高性能**: 最大链路带宽140 MB/s。
    -  **短径与容错**: 最大网络距离短（例如128 ПЭ时为6跳），支持通过替代路径绕过故障链路。
    -  **维度顺序路由**: 数据包路由顺序固定：先调整X坐标，再Y，最后Z，以优化路径。
    -  **Ключевые характеристики**:
        -  **Высокая производительность**: Максимальная пропускная способность канала — 140 МБ/с.
        -  **Короткие пути и отказоустойчивость**: Малая максимальная дистанция в сети (напр., 6 для 128 ПЭ); возможность обхода повреждённых связей.
        -  **Детерминированная маршрутизация**: Порядок следования пакета: сначала по размерности X, затем Y, наконец Z для оптимизации пути.

--------------------------------------------------
**核心理念总结 / Ключевая концепция**
--------------------------------------------------
CRAY XT (T3D) 是典型的分布式内存MPP系统，其核心设计通过**物理分布但逻辑共享的内存模型**、基于**三维环面的高效容错网络**以及**分层的节点架构**，在提供高可扩展性的同时，简化了并行编程的数据访问模型。
CRAY XT (T3D) — типичная MPP-система с распределённой памятью. Её ядро — **модель памяти, физически распределённой, но логически общей**, **эффективная отказоустойчивая сеть на основе 3D-тора** и **многоуровневая архитектура узлов**. Это обеспечивает высокую масштабируемость, упрощая модель доступа к данным для параллельного программирования.



## 19. Особенности компьютеров семейства CRAY XT: аппаратная поддержка синхронизации параллельных процессов.
--------------------------------------------------
一、 Аппаратная реализация барьеров синхронизации (屏障同步的硬件实现)
I. Аппаратная реализация барьеров синхронизации
--------------------------------------------------
- **目的与定义**: 硬件直接支持开销较大的同步操作——屏障。屏障是程序中的一个点，所有进程必须在此等待，直到所有进程都到达后，才能继续执行。
  - **Цель и определение**: Аппаратная поддержка «тяжёлого» вида синхронизации — барьеров. Барьер — точка в программе, где каждый процессор ждет, пока остальные не достигнут её, после чего все продолжают работу.

- **硬件机制**:
    1.  **专用寄存器**: 每个处理器元素(ПЭ)有两个8位寄存器，每位对应一条独立的屏障电路（共16条独立电路）。
    2.  **电路逻辑**: 每条电路基于AND门和复制电路(1-2)。到达屏障前，所有ПЭ的相应位清零；ПЭ到达屏障后，将其位置1。AND门输出1仅当所有ПЭ的对应位都为1，标志着屏障解除。
    - **Аппаратный механизм**:
        1.  **Специализированные регистры**: Каждый ПЭ имеет два 8-разрядных регистра, каждый разряд подключён к своей независимой цепи барьера (всего 16 цепей).
        2.  **Логика цепи**: Цепь построена на основе схем AND и дублирования (1-2). До барьера разряды обнуляются; ПЭ, достигший барьера, устанавливает свой разряд в 1. Выход AND становится 1 только когда все ПЭ выставили 1, что сигнализирует о преодолении барьера.

--------------------------------------------------
二、 Механизм "эврика" (Eureka/广播发现机制)
II. Механизм "эврика"
--------------------------------------------------
- **原理**: 将屏障电路中的AND门替换为OR门，即构成“尤里卡”电路。只要有一个ПЭ将其位置1，该信号立即广播给所有ПЭ。
  - **Принцип**: Замена схем AND на OR в цепи барьера создаёт механизм "эврика". Как только один ПЭ устанавливает свой разряд в 1, этот сигнал немедленно распространяется всем ПЭ.

- **应用**: 用于通知全局事件（如搜索任务中找到解），可立即停止所有进程或触发统一行动。
  - **Применение**: Используется для оповещения о глобальном событии (напр., найденное решение в задаче поиска), позволяя мгновенно остановить все процессы или инициировать общее действие.

--------------------------------------------------
**核心价值 / Ключевая ценность**
--------------------------------------------------
CRAY XT 通过硬件同步原语（屏障和“尤ри卡”）显著降低了分布式内存系统中同步操作的开销，提升了并行程序的协调效率和性能。
CRAY XT значительно снижает накладные расходы на синхронизацию в системах с распределённой памятью за счёт аппаратных примитивов (барьер и "эврика"), повышая эффективность координации и производительность параллельных программ.




## 20. Вычислительные кластеры: узлы, коммуникационная сеть (латентность, пропускная способность), способы построения.
--------------------------------------------------
一、 计算集群的定义与节点  
I. Определение и узлы вычислительного кластера  
--------------------------------------------------
- 计算集群是由计算机网络连接、为解决同一任务而协同工作的计算机集合。  
  ‑ Вычислительный кластер — совокупность компьютеров, объединенных сетью для решения одной задачи.
- 节点通常使用市售的计算机或SMP服务器（单/双/四路CPU），每个节点运行自己的操作系统副本（如Linux, Windows）。  
  ‑ В качестве узлов используются доступные на рынке компьютеры или SMP-серверы; каждый узел работает под управлением своей копии ОС.
- 集群节点可以是异构的，其组成和性能在同一个集群内也可以不同。  
  ‑ Состав и мощность узлов могут меняться даже в рамках одного кластера, что позволяет создавать неоднородные системы.

--------------------------------------------------
二、 通信网络的关键性能与构建方式  
II. Ключевые характеристики и способы построения коммуникационной сети  
--------------------------------------------------
1. 关键性能指标  
  1. Ключевые характеристики производительности  
  - **延迟**：发送消息的初始延迟时间，由软件和硬件开销构成。短消息性能受其严重影响。  
    ‑ **Латентность**: время начальной задержки при посылке сообщений. Сильно влияет на работу с короткими сообщениями.
  - **带宽**：单位时间内通过信道传输的数据量（字节/秒）。分为单向带宽和双向带宽。长消息传输性能主要受其影响。  
    ‑ **Пропускная способность**: количество информации, передаваемой между узлами в единицу времени. Бывает однонаправленная и двунаправленная.

2. 网络技术与构建方式  
  2. Сетевые технологии и способы построения  
  - 构建方式多样，从通过10兆以太网连接的两台PC，到使用高速专用网络（如Myrinet）连接上千工作站的大型系统（如Sandia的Cplant项目）。  
    ‑ Способы варьируются от пары ПК в Ethernet до систем из тысяч рабочих станций, объединенных высокоскоростной сетью.
  - 网络技术选择取决于任务类别、成本、性能和可扩展性。常见技术包括：Fast/Gigabit Ethernet, SCI, Myrinet, cLAN, ServerNet等。  
    ‑ Выбор сетевой технологии определяется классом задач, стоимостью, производительностью и масштабируемостью.
  - 低成本解决方案（如Fast Ethernet）通用性有限；对通用性要求高的集群需要转向更高性能的网络技术。  
    ‑ Низкая стоимость Fast Ethernet имеет ограниченную универсальность; для большей универсальности нужны более производительные сети.


    
## 21. Архитектура суперкомпьютеров СКИФ МГУ «Чебышев», «Ломоносов» и «Ломоносов-2».
--------------------------------------------------
一、 Суперкомпьютер СКИФ МГУ «Чебышёв» (2008)  
I. Суперкомпьютер СКИФ МГУ «Чебышёв» (2008)
--------------------------------------------------
- **性能与排名**: 峰值性能60 TFlop/s，Linpack测试47.32 TFlop/s (效率79%)。曾位列Top500第36位，Top50 CIS第1位。
    - **Производительность и рейтинг**: Пиковая производительность 60 TFlop/s, Linpack — 47.32 TFlop/s (эффективность 79%). Занимал 36 место в Top500 и 1 место в Top50 СНГ.

- **计算架构**:
    - **节点与处理器**: 625个计算节点，1250颗Intel Xeon E5472 (Harpertown) 处理器，总计5000核。
    - **内存**: 总容量约5 TB，采用混合配置 (8/16/32 GB 模块)。
    - **Компьютерная архитектура**:
        - **Узлы и процессоры**: 625 вычислительных узлов, 1250 процессоров Intel Xeon E5472 (Harpertown), всего 5000 ядер.
        - **Оперативная память**: Общий объём ~5 ТБ, смешанная конфигурация (модули по 8/16/32 ГБ).

- **网络与存储**:
    - **高速网络**: DDR InfiniBand (FatTree拓扑)，延迟1.3-1.95 μs，带宽1.7 GB/s。
    - **辅助网络**: Gigabit Ethernet (管理网络)。
    - **存储系统**: 60 TB分布式网络存储 (T-Platforms ReadyStorage) + 15 TB本地磁盘 + 磁带库。
    - **Сеть и хранение данных**:
        - **Высокоскоростная сеть**: DDR InfiniBand (топология FatTree), латентность 1.3-1.95 мкс, пропускная способность 1.7 ГБ/с.
        - **Вспомогательная сеть**: Gigabit Ethernet (управляющая сеть).
        - **Система хранения**: 60 ТБ распределённое сетевое хранилище (T-Platforms ReadyStorage) + 15 ТБ локальных дисков + ленточное хранилище.

- **基础设施**:
    - **冷却**: 精密空调 (N+2冗余)，采用“热通道”封闭设计以提高效率。
    - **供电**: 不间断电源 (UPS)，10分钟备用，N+1冗余。
    - **防火**: 自动惰性气体灭火系统。
    - **Инфраструктура**:
        - **Охлаждение**: Прецизионные кондиционеры (резервирование N+2), конструкция «горячий коридор» для повышения эффективности.
        - **Электропитание**: ИБП (10 минут автономной работы), резервирование N+1.
        - **Пожаротушение**: Автоматическая система газового пожаротушения.

--------------------------------------------------
二、 Суперкомпьютер «Ломоносов» (более поздняя конфигурация)  
II. Суперкомпьютер «Ломоносов» (более поздняя конфигурация)
--------------------------------------------------
- **性能规模**: 峰值性能1.7 PFlop/s，Linpack测试901.9 TFlop/s (效率53%)，是规模更大的系统。
    - **Масштаб производительности**: Пиковая производительность 1.7 PFlop/s, Linpack — 901.9 TFlop/s (эффективность 53%), система значительно большего масштаба.

- **混合计算架构**:
    - **异构节点**: 总计约6,200个节点，包括：
        - 5,104个基于Intel Xeon 5570/5670的通用计算节点 (12,346个x86核)。
        - 1,065个带NVIDIA Tesla X2070的GPU加速节点 (2,130个GPU核)。
        - 30个基于PowerXCell的节点。
    - **内存**: 总容量约92 TB。
    - **Гибридная компьютерная архитектура**:
        - **Разнородные узлы**: Всего ~6200 узлов, включая:
            - 5104 универсальных узла на Intel Xeon 5570/5670 (12 346 ядер x86).
            - 1065 узлов с ускорителями NVIDIA Tesla X2070 (2130 ядер ГПУ).
            - 30 узлов на PowerXCell.
        - **Память**: Общий объём ~92 ТБ.

- **网络与存储**:
    - **高速网络**: QDR InfiniBand 和 10 Gigabit Ethernet。
    - **海量存储**: 1.75 PB 并行文件系统 (Lustre, NFS)。
    - **Сеть и хранение данных**:
        - **Высокоскоростная сеть**: QDR InfiniBand и 10 Gigabit Ethernet.
        - **Массовое хранилище**: 1.75 ПБ параллельной файловой системы (Lustre, NFS).

- **大规模基础设施**:
    - **占地面积**: 计算部分252 平方米。
    - **能耗**: 计算部分2.8 兆瓦。
    - **冷却**: 复杂液冷系统 (10吨乙二醇 + 40吨水)。
    - **规模指标**: 电缆总长 >80 公里，设备总重 149 吨。
    - **Крупномасштабная инфраструктура**:
        - **Занимаемая площадь**: Вычислительная часть — 252 м².
        - **Энергопотребление**: Вычислительная часть — 2.8 МВт.
        - **Охлаждение**: Сложная жидкостная система охлаждения (10 т гликоля + 40 т воды).
        - **Показатели масштаба**: Общая длина кабелей >80 км, общий вес оборудования 149 т.

--------------------------------------------------
**架构演进概要 / Резюме об эволюции архитектуры**
--------------------------------------------------
从“切比雪夫”到“罗蒙诺索夫”，展现了俄罗斯超级计算机从以CPU为中心的集群，向**大规模、混合架构（CPU+GPU）** 的演进。两者均高度重视**高性能InfiniBand网络**和**企业级基础设施**（冷却、供电），但“罗蒙诺索夫”在规模、异构计算能力和存储容量上实现了数量级提升。  
От «Чебышёва» к «Ломоносову» прослеживается эволюция российских суперкомпьютеров от CPU-центричных кластеров к **крупномасштабным гибридным системам (CPU+ГПУ)**. Оба делали упор на **высокопроизводительную сеть InfiniBand** и **промышленную инфраструктуру** (охлаждение, питание), но «Ломоносов» совершил скачок на порядок в масштабе, разнородности вычислений и объёме хранения данных.



## 22. Топология коммуникационной сети «толстое дерево» (fat tree) на примере реализации в суперкомпьютерах СКИФ МГУ «Чебышёв» или «Ломоносов».




## 23. Причины уменьшения производительности компьютеров с распределённой памятью.
--------------------------------------------------
一、 与并行程序组织相关的限制  
I. Ограничения, связанные с организацией параллельной программы  
--------------------------------------------------
- **阿姆达尔定律**：程序中必然存在的初始化、I/O和纯串行部分限制了最大加速比。几乎整个程序都必须并行执行，这需要对程序进行彻底分析。  
  ‑ **Закон Амдала**: присутствующие в программе инициализация, ввод/вывод и сугубо последовательные действия ограничивают максимальное ускорение. Практически вся программа должна исполняться параллельно, что требует анализа всей программы.
- **计算负载均衡**：为实现高效并行处理，必须保证所有处理器负载均匀。负载不均会导致部分处理器空闲，等待其他处理器。  
  ‑ **Балансировка вычислительной нагрузки**: для эффективной параллельной обработки необходима равномерная загрузка всех процессоров. Неравномерность приводит к простоям.
- **异步计算与通信的可能性**：为减少处理器等待数据的时间，应尽早发送所需数据，并将不依赖该数据的工作推迟；接收方则应在等待消息前完成尽可能多的不相关计算。  
  ‑ **Возможность асинхронного счета и передачи данных**: чтобы минимизировать время ожидания, данные следует отправлять как можно раньше, а получатель должен выполнить максимум независимой работы перед приемом.

--------------------------------------------------
二、 与硬件和通信网络相关的限制  
II. Ограничения, связанные с аппаратным обеспечением и коммуникационной сетью  
--------------------------------------------------
1. **通信网络特性**  
  1. **Характеристики коммуникационной сети**
  - **延迟**：消息发送的初始化时间。短消息性能受其严重影响。  
    ‑ **Латентность**: время инициализации посылки сообщения. Серьезно влияет на короткие сообщения.
  - **带宽**：通过网络通道的实际数据传输速率。长消息的传输时间主要受其影响，最大传输速率仅在长消息下达到。  
    ‑ **Пропускная способность**: скорость передачи данных по сети. Время передачи длинных сообщений определяется ею; максимальная скорость достигается на больших сообщениях.
  - **网络拓扑特点**：影响节点间的通信路径和效率。  
    ‑ **Особенности топологии коммуникационной сети**: влияют на пути и эффективность обмена между узлами.

2. **节点与处理器的硬件特性**  
  2. **Аппаратные особенности узлов и процессоров**
  - **SMP节点使用特点**：节点内多处理器共享内存的架构可能引入额外开销（如缓存一致性）。  
    ‑ **Особенности использования SMP-узлов**: архитектура с общей памятью внутри узла может вносить дополнительные накладные расходы.
  - **单个处理器性能**：不同微处理器具有不同的缓存层次、专用功能单元、寄存器结构和向量流水线能力，直接影响节点的计算效率。  
    ‑ **Производительность отдельных процессоров**: различные уровни кэш-памяти, специализированные устройства, векторно-конвейерная архитектура и т.п. напрямую влияют на эффективность вычислений.

--------------------------------------------------
核心要点 / Ключевые выводы  
--------------------------------------------------
分布式内存系统性能下降的主要原因：  
1.  **程序并行度限制**（串行部分、负载不均）。  
2.  **通信开销**（延迟、带宽、网络拓扑）。  
3.  **硬件差异**（节点架构、单个CPU性能）。  

Основные причины снижения производительности систем с распределенной памятью:  
1.  **Ограничения параллелизма программы** (последовательные части, несбалансированная нагрузка).  
2.  **Накладные расходы на обмен данными** (латентность, пропускная способность, топология сети).  
3.  **Аппаратные различия** (архитектура узлов, производительность отдельных CPU).



## 24. Соотношение между понятиями: функциональное устройство, команда (операция), компьютер и их характеристиками: скалярный, векторный, конвейерный.
--------------------------------------------------  
一、三大“对象”与三大“属性”  
I. Три объекта и три их характеристики  
--------------------------------------------------  
1. 功能部件（ФУ）  
   ‑ 只有两种标签：  
     - 标量型 — “必须等前一条操作完全结束才能开始下一条”（не конвейерные сумматоры или умножители）  
     - 流水型 — “把操作拆成若干微操作，各操作在不同段上重叠”（операция делится на несколько микроопераций, количество микроопераций определяет число ступеней конвейера）  

   Функциональное устройство  
   ‑ Возможны только два признака:  
     - скалярное — последующая операция не может начаться раньше завершения предыдущей  
     - конвейерное — оборудование распределяется для одновременной реализации нескольких операций  

2. 指令（команда / операция）  
   ‑ 标量指令 — 所有操作数都是单个标量（все аргументы — скаляры）  
   ‑ 向量指令 — 一次对整组数据执行同样运算（например, сложить все элементы массива x с числом b）  

   Команда  
   ‑ Скалярная — аргументы-скаляры  
   ‑ Векторная — охватывает массив данных одной операцией  

3. 计算机（компьютер）  
   ‑ 标量机 — 内部仅有标量功能部件  
   ‑ 向量机 — 拥有“只能执行向量命令”的向量功能部件（предназначены для выполнения только векторных команд）  
   ‑ 流水线机 — 大量采用“每拍推进一段”的流水线部件（каждая ступень срабатывает за один такт, при полной загрузке результат выдаётся каждый такт）  

   Компьютер  
   ‑ Может быть скалярным, векторным и конвейерным одновременно — в зависимости от набора ФУ  

--------------------------------------------------  
二、CRAY Y-MP C90 中的“活生生”对应  
II. Живая иллюстрация на примере CRAY Y-MP C90  
--------------------------------------------------  
1. 结构总览  
   “所有功能部件都是流水化的，同时被划分为四组”  
   ‑ 地址组（2 个） — 整数加/减、整数乘  
   ‑ 标量组（4 个） — 整数加/减、逻辑、移位、前导 1/0 计数  
   ‑ 向量组（5–7 个） — 整数加/减、移位、逻辑、前导 1/0、位矩阵乘（后两项 0–1 个）  
   ‑ 浮点组（3 个） — 加/减、乘、求倒数，可服务“标量或向量”指令  

   Структура CRAY Y-MP C90  
   ‑ Все ФУ конвейерные и делятся на 4 группы; векторные ФУ выполняют только векторные команды, тогда как плавающие ФУ — и скалярные, и векторные  

2. 对应关系一目了然  
   - 标量指令 → 标量组或浮点组  
   - 向量指令 → 向量组或浮点组  
   - 任何指令 → 都在流水线上“每拍出结果”  

   Таким образом, в одной системе реализованы:  
   - скалярные команды → скалярные/плавающие ФУ  
   - векторные команды → векторные/плавающие ФУ  
   - конвейерная организация → все ФУ выдают результат каждый такт при полной загрузке  

--------------------------------------------------  
三、一句话总结  
III. Итог одной фразой  
--------------------------------------------------  
功能部件决定“能不能流水”，指令决定“是不是向量”，计算机则通过“组合不同属性部件”同时获得标量、向量、流水线三大特征。  

ФУ задают «конвейерность», команда определяет «векторность», а компьютер — просто совокупность таких ФУ, совмещая все три характеристики внутри себя.



## 25. Векторизация программ, необходимые условия векторизации, препятствия для векторизации.
--------------------------------------------------
一、 Векторизация программ: понятие и цель (程序向量化：概念与目的)
I. Векторизация программ: понятие и цель
--------------------------------------------------
- **定义**: 向量是内存中按相同间隔存储的同类数据有序集合。向量化是将程序中的合适片段替换为向量指令的过程。
    - **Определение**: Вектор — упорядоченный набор однотипных данных, размещённых в памяти с одинаковым смещением. Векторизация — процесс замены подходящих фрагментов программы векторными командами.

- **优势**: 单条指令处理整个数据集，大幅提升效率。向量处理速度可比标量处理快10-15倍。
    - **Преимущество**: Обработка всего набора данных одной командой значительно повышает эффективность. Скорость векторной обработки может в 10-15 раз превышать скалярную.

- **示例与类型**: 典型的向量化对象是最内层循环（如 `C(i) = A(i) + B(i)`）。若整个循环可被替换，则为完全向量化，否则为部分向量化。
    - **Пример и типы**: Типичный кандидат — самый внутренний цикл (напр., `C(i) = A(i) + B(i)`). Если весь цикл заменяется — полная векторизация, иначе — частичная.

--------------------------------------------------
二、 Условия и препятствия векторизации (向量化的条件与障碍)
II. Условия и препятствия векторизации
--------------------------------------------------
**1. 必要条件 (Необходимые условия):**
   - **存在向量参数**: 操作对象必须是内存中连续、同类型的数据集合（向量）。
        - **Наличие векторов-аргументов**: Операнды должны быть последовательными наборами однотипных данных (векторами) в памяти.
   - **操作一致且独立**: 对向量所有元素执行相同、独立的操作，且处理器指令集中存在对应的向量指令。
        - **Одинаковые независимые операции**: Над всеми элементами векторов выполняются одинаковые, независимые операции, и в системе команд есть соответствующие векторные инструкции.

**2. 主要障碍 (Основные препятствия):**
   - **数据依赖**: 循环迭代间存在依赖关系（如 `A(i) = A(i-1) + B(i)`），阻止并行执行。
        - **Зависимость по данным**: Наличие зависимостей между итерациями цикла (напр., `A(i) = A(i-1) + B(i)`), препятствующее параллельному выполнению.
   - **硬件指令缺失**: 处理器缺乏执行特定操作所需的向量指令。
        - **Отсутствие векторных команд**: В наборе инструкций процессора отсутствует необходимая векторная команда для операции.
   - **非规则内存访问**: 数据访问模式非连续或非固定间隔（如通过函数计算的间接索引 `B(FUNC(i))`）。
        - **Нерегулярное расположение данных**: Непоследовательный или нефиксированный шаг доступа к данным (напр., косвенная адресация `B(FUNC(i))`).
   - **嵌套循环**: 当前循环内包含其他循环，通常缺乏对应的多维向量操作指令。
        - **Вложенные циклы**: Наличие внутри векторизуемого цикла другого цикла; для таких фрагментов обычно нет векторных команд.
   - **未知函数调用**: 调用编译器无法分析的外部函数或子程序，其副作用难以预测。
        - **Вызов неизвестных функций**: Вызов внешних подпрограмм, побочные эффекты которых компилятор не может проанализировать.

--------------------------------------------------
**核心原则总结 / Ключевой принцип**
--------------------------------------------------
成功的向量化取决于**数据的规整性（连续、同类型）** 和**操作的独立性**。主要障碍源于**数据依赖、不规则访问模式及硬件支持的限制**。最内层循环是主要的优化目标。
Успешная векторизация зависит от **регулярности данных (последовательность, однотипность)** и **независимости операций**. Главные препятствия — **зависимости данных, нерегулярные шаблоны доступа и ограничения аппаратной поддержки**. Самые внутренние циклы — основная цель оптимизации.



## 26. Общая структура векторно-конвейерного компьютера на примере CRAY C90. Параллелизм в архитектуре компьютера CRAY C90.
--------------------------------------------------
一、 CRAY C90 总体结构  
I. Общая структура CRAY C90  
--------------------------------------------------
- **系统概述**：CRAY C90 是一款共享内存的向量流水线计算机，最大配置为 **16个相同且平等的处理器**，共同访问共享资源（内存、I/O 部分、处理器间交互部分）。时钟周期为 **4.1 ns** (~250 MHz)。  
  ‑ **Общее описание**: CRAY C90 — векторно-конвейерный компьютер с общей памятью, объединяющий до **16 одинаковых и равноправных процессоров**, работающих над общими ресурсами. Время такта — **4.1 нс** (~250 MHz).

- **内存组织**：
  - **字长**：80位（64位数据 + 16位纠错位）。  
    ‑ **Длина слова**: 80 разрядов (64 данных + 16 для коррекции).
  - **并行访问**：内存被划分为 **1024个bank**（8个区 × 8个子区 × 16个bank），地址交错分布以实现高并发访问。顺序或奇数步长访问可避免冲突。  
    ‑ **Параллельный доступ**: память расслоена на **1024 банка**. Последовательные адреса распределены с чередованием для максимального параллелизма.
  - **处理器端口**：每个处理器通过 **4个端口** 访问内存，每个端口每周期可传输 **2个字**。一个端口专用于I/O，至少一个专用于写操作。  
    ‑ **Порты процессора**: каждый процессор имеет доступ к памяти через **4 порта** (2 слова/такт каждый). Один порт всегда связан с I/O.

- **处理器计算部件**：每个处理器包含寄存器、功能部件和通信网络，处理三种数据类型：
  1.  **地址寄存器**：A寄存器（8x32位）和缓冲B寄存器（64x32位）。  
      ‑ **Адресные регистры**: A-регистры (8x32) и буферные B-регистры (64x32).
  2.  **标量寄存器**：S寄存器（8x64位）和缓冲T寄存器（64x64位），用于标量和部分向量指令。  
      ‑ **Скалярные регистры**: S-регистры (8x64) и T-регистры (64x64).
  3.  **向量寄存器**：V寄存器（8个，每个128x64位），**仅用于向量指令**。  
      ‑ **Векторные регистры**: V-регистры (8x128 слов по 64 разряда) — **только для векторных команд**.
  4.  **功能部件**：分为**地址**（2个）、**标量**（4个）、**向量**（5-7个）、**浮点**（3个）四组。所有功能部件均为流水线，且可**同时独立工作**。向量与浮点功能部件是**双流水线的**（Pipe 0 和 Pipe 1），可同时处理向量的奇偶元素。  
      ‑ **Функциональные устройства (ФУ)**: 4 группы (адресные, скалярные, векторные, с плавающей точкой). Все ФУ конвейерные и независимы. Векторные и ФУ с плавающей точкой **продублированы** (два конвейера).

--------------------------------------------------
二、 CRAY C90 中的并行性  
II. Параллелизм в архитектуре CRAY C90  
--------------------------------------------------
1.  **流水线执行**  
    1.  **Конвейеризация выполнения**  
    - 所有核心操作（内存访问、指令处理、指令执行）均采用流水线。  
      ‑ Все основные операции являются конвейерными.

2.  **功能部件独立性**  
    2.  **Независимость функциональных устройств**  
    - 大多数功能部件独立，允许**多条操作同时执行**。  
      ‑ Большинство ФУ независимы, поэтому несколько операций могут выполняться одновременно.

3.  **向量处理**  
    3.  **Векторная обработка**  
    - **单一指令处理整个数据集（向量）**。向量模式下的执行速度比标量处理快约 **10倍**。  
      ‑ Обработка целого набора (вектора) данных **одной командой**. Скорость в векторном режиме примерно **в 10 раз выше** скалярной.

4.  **功能部件链接**  
    4.  **Зацепление функциональных устройств**  
    - 将**一个向量操作的结果寄存器直接作为下一个向量操作的输入**，形成流水线链，提高吞吐量。  
      ‑ Использование регистра результатов векторной операции в качестве входного для последующей — выход сразу подается на вход.

5.  **多处理器处理**  
    5.  **Многопроцессорная обработка**  
    - **多程序处理**：在不同处理器上执行多个独立程序。  
      ‑ **Multiprogramming**: выполнение нескольких независимых программ на различных процессорах.
    - **多任务处理**：在多个处理器上执行单个（并行）程序。  
      ‑ **Multitasking**: выполнение одной программы на нескольких процессорах.
    - **峰值性能**：利用双流水线、链接（如加法和乘法）以及所有16个处理器，理论峰值可达约 **16 GFlops**。  
      ‑ **Пиковая производительность**: использование сдвоенных конвейеров, зацепления и 16 процессоров дает до **~16 Гфлопс**.

--------------------------------------------------
核心总结 / Ключевой вывод  
--------------------------------------------------
CRAY C90 通过 **多级并行** 实现高性能：  
1.  **指令/操作级**：流水线、独立功能部件。  
2.  **数据级**：向量处理、功能部件链接。  
3.  **任务/进程级**：多达16个共享内存处理器。  

CRAY C90 достигает высокой производительности за счёт **многоуровневого параллелизма**:  
1.  **Уровень команд/операций**: конвейеризация, независимые ФУ.  
2.  **Уровень данных**: векторная обработка, зацепление ФУ.  
3.  **Уровень задач/процессов**: до 16 процессоров с общей памятью.



## 27. Суперкомпьютеры NEC SX-Aurora TSUBASA.




## 28. Элементы векторной обработки в современных компьютерах. Наборы инструкций MMX, SSE, AVX, AVX2, AVX-512, AltiVec, ARM SVE.




## 29. Причины уменьшения производительности векторно-конвейерных компьютеров.
--------------------------------------------------
一、 基础与算法限制  
I. Фундаментальные и алгоритмические ограничения  
--------------------------------------------------
1. 阿姆达尔定律 (Закон Амдала)  
   ‑ 程序加速受限于其顺序（串行）部分的比例。即使并行部分高度优化，大的顺序部分也会严重限制整体性能。编译器质量也会影响，因为它可能无法识别潜在的可向量化代码。  
   ‑ Время выполнения программы определяется её самой медленной (последовательной) частью. Даже при полной оптимизации параллельной части, большая доля последовательных операций резко ограничивает общее ускорение. Качество компилятора также влияет, так как он может не распознать векторизуемость кода.  

2. 向量分割与流水线启动开销 (Секционирование и разгон конвейера)  
   ‑ **向量分割**：长向量操作被分割为固定长度的段（例如，128个元素），这会引入循环和控制开销。  
   ‑ **流水线启动**：流水线功能设备需要初始填充时间（启动延迟）。对于非常短的循环，标量执行模式可能更高效，因为它没有这些开销。  

   ‑ **Секционирование**: Длинные векторные операции разбиваются на порции фиксированной длины (напр., 128 элементов), что вносит накладные расходы на управление циклом.  
   ‑ **Разгон конвейера**: Конвейерным ФУ требуется время на начальное заполнение. Для очень коротких циклов скалярный режим исполнения может быть эффективнее из-за отсутствия этих накладных расходов.  

--------------------------------------------------
二、 硬件与资源限制  
II. Аппаратные и ресурсные ограничения  
--------------------------------------------------
3. 内存访问冲突 (Конфликты при обращении в память)  
   ‑ 当数据访问模式（例如，步长）导致对同一内存体或子体的重复请求时，会发生冲突。例如，在CRAY Y-MP C90中，步长为64的访问会造成最严重的冲突，而任意奇数的步长则可以无冲突进行。  

   ‑ Происходят, когда шаг обращения к данным приводит к повторяющимся запросам к одному и тому же банку или подразделу памяти. Например, на CRAY Y-MP C90 выборка с шагом 64 вызывает максимальные конфликты, а с любым нечетным шагом — проходит без конфликтов.  

4. 数据通道瓶颈 (Ограниченная пропускная способность каналов)  
   ‑ 数据总线/通道的数量有限，限制了每个周期可加载/存储的操作数数量。例如，CRAY Y-MP只有两个读取通道和一个写入通道，因此需要三个操作数的链式操作（如 A = B * C + D）会导致通道争用和空闲周期。  

   ‑ Ограниченное число шин/каналов передачи данных ограничивает количество операндов, которые можно загрузить или сохранить за такт. Например, CRAY Y-MP имеет только два канала чтения и один записи, поэтому операция сцепления, требующая три аргумента, приводит к конфликтам и простоям.  

5. 功能设备使用不平衡与缺失 (Дисбаланс и отсутствие ФУ)  
   ‑ **设备不平衡**：如果算法顺序使用不同类型的功能设备（例如，先执行所有加法，再执行所有乘法），会导致一些设备闲置，而其他设备繁忙，降低了整体利用率。  
   ‑ **缺少专用设备**：缺乏硬件除法器等专用功能单元会迫使通过软件或多次操作来模拟该运算，显著降低性能。  

   ‑ **Несбалансированность**: Последовательное использование ФУ разного типа (сначала все сложения, затем все умножения) приводит к простою одних устройств и перегрузке других.  
   ‑ **Отсутствие устройств**: Отсутствие специализированного ФУ (например, для деления) требует эмуляции операции в программном обеспечении, что резко снижает производительность.  

6. 指令流中断 (Перезагрузка буферов команд)  
   ‑ 频繁的子程序调用或复杂的、包含大量分支的控制流会导致指令缓冲区频繁刷新，因为预取的下一条指令很可能不在当前缓冲区中。这会引入额外的指令获取延迟。  

   ‑ Частые вызовы подпрограмм или сложная структура управления с множеством переходов приводят к частой перезагрузке буферов команд, так как следующая нужная команда может отсутствовать в текущем буфере. Это вносит дополнительную задержку на выборку команд.  

--------------------------------------------------
综合影响 / Совокупное воздействие  
--------------------------------------------------
即使每个因素单独仅造成15%的性能损失（即保持85%的峰值性能），所有因素共同作用可能导致实际性能降至峰值性能的20%以下。  
Даже если влияние каждого отдельного фактора позволяет достичь 85% от пиковой производительности, их совместное действие может снизить реальную производительность менее чем до 20% от пика.



## 30. Метакомпьютер и метакомпьютинг. Отличительные свойства распределенных вычислительных сред.
--------------------------------------------------
一、 Понятия метакомпьютера и метакомпьютинга (元计算机与元计算的概念)
I. Понятия метакомпьютера и метакомпьютинга
--------------------------------------------------
- **元计算机 (Метакомпьютер)**: 由多台计算机组成的虚拟计算机，其资源（处理器、内存、存储）通过网络（如互联网）聚合，对用户呈现为单一的计算系统。
    - **Метакомпьютер**: Виртуальный компьютер, состоящий из множества компьютеров, чьи ресурсы (процессоры, память, хранилище) объединены через сеть (напр., Интернет) и представляются пользователю как единая вычислительная система.

- **元计算 (Метакомпьютинг)**: 在元计算机上组织和执行计算的过程。系统自动处理资源发现、任务分配、数据传输和格式转换，对用户透明。
    - **Метакомпьютинг**: Процесс организации и выполнения вычислений на метакомпьютере. Система автоматически выполняет поиск ресурсов, распределение задач, передачу и преобразование данных, обеспечивая прозрачность для пользователя.

- **核心理念**: 互联网可被视为世界上最大的元计算机，其聚合资源（算力、内存、存储）远超任何独立超级计算机。
    - **Ключевая идея**: Интернет можно рассматривать как крупнейший в мире метакомпьютер, совокупные ресурсы которого (производительность, память, дисковое пространство) превосходят любой отдельный суперкомпьютер.

--------------------------------------------------
二、 Отличительные свойства распределенных вычислительных сред (метакомпьютера) (分布式计算环境（元计算机）的特性)
II. Отличительные свойства распределенных вычислительных сред (метакомпьютера)
--------------------------------------------------
1. **资源规模巨大 (Огромные ресурсы)**
   - 聚合的处理器、内存、存储、用户和应用程序数量远超传统计算机。
   - Совокупное число процессоров, объём памяти, хранилищ, пользователей и приложений несравнимо с ресурсами обычных компьютеров.

2. **固有的分布性与高延迟 (Распределённость и высокая задержка)**
   - 组件可地理分散（相距数百/数千公里），导致网络通信延迟高，影响交互响应速度。
   - Компоненты могут быть географически удалены на сотни/тысячи км, что вызывает высокую сетевую задержку и влияет на оперативность взаимодействия.

3. **动态配置与透明性 (Динамическая конфигурация и прозрачность)**
   - 资源可随时加入或离开，系统需动态适应。对用户而言，这些变化应是透明的，系统负责持续的资源管理和任务调度。
   - Ресурсы могут подключаться и отключаться, система должна динамически адаптироваться. Для пользователя эти изменения прозрачны; система обеспечивает непрерывное управление ресурсами и планирование задач.

4. **异构性 (Неоднородность)**
   - 包含不同架构、操作系统、指令集、数据格式和网络带宽的系统。任务分配必须考虑这些差异。
   - Объединяет системы с разной архитектурой, ОС, наборами команд, форматами данных и пропускной способностью сети. Распределение задач должно учитывать эти различия.

5. **跨组织资源整合与管理复杂性 (Интеграция ресурсов различных организаций и сложность управления)**
   - 整合来自不同机构的资源，各机构有自己的访问和使用策略。元计算机没有单一所有者，其管理策略需高度标准化以协调众多组件。
   - Объединяет ресурсы разных организаций, каждая со своей политикой доступа. Метакомпьютер не имеет единственного владельца, его администрирование требует высокой стандартизации для согласованной работы всех компонентов.

--------------------------------------------------
**本质总结 / Суть явления**
--------------------------------------------------
元计算机不仅是硬件集合，更是**实现大规模、动态、异构资源协调管理的软件基础设施**。其核心挑战在于如何使数百万设备为成千上万用户的任务**长期、协调、高效、透明地工作**。
Метакомпьютер — это не просто набор аппаратного обеспечения, а **программно-инфраструктурное решение для координации масштабных, динамических, разнородных ресурсов**. Ключевая проблема — обеспечить **долговременную, согласованную, эффективную и прозрачную работу миллионов устройств** над задачами тысяч пользователей.



## 31. Параллелизм на уровне машинных команд. Суперскалярность, VLIW, EPIC.
--------------------------------------------------
一、 指令级并行性概念与核心原理  
I. Понятие и основной принцип параллелизма на уровне команд  
--------------------------------------------------
- **定义**：指令级并行（ILP）是**对用户透明**的并行性。用户无需进行专门的并行编程，移植性问题保持在串行机程序的通用移植性层面。  
  ‑ **Определение**: Параллелизм на уровне машинных команд (ILP) — это **скрытый от пользователя** параллелизм. Пользователь не нуждается в специальном параллельном программировании.
- **硬件基础**：两种主要架构都假设处理器包含**多个可以独立工作的功能部件**（FU）。部件可以相同或不同。  
  ‑ **Аппаратная основа**: Оба подхода предполагают, что процессор содержит **несколько функциональных устройств (ФУ)**, которые могут работать независимо.

--------------------------------------------------
二、 实现指令级并行的三种主要架构  
II. Три основные архитектуры реализации ILP  
--------------------------------------------------
1.  **超标量架构**  
    1.  **Суперскалярная архитектура**
    - **核心原理**：**硬件**在运行时负责检测机器码中的并行性，并动态构建指令执行顺序。硬件开销大。  
      ‑ **Принцип**: **Аппаратура** во время выполнения обнаруживает параллелизм в машинном коде и строит последовательность исполнения команд. Требует много ресурсов.
    - **代码特性**：程序代码本身不包含并行性信息，不反映底层硬件细节或精确的执行时序。代表：IBM STRETCH，现代多数微处理器。  
      ‑ **Характер кода**: Код не содержит информации о параллелизме, не отражает аппаратное обеспечение или точный порядок выполнения. Примеры: IBM STRETCH, многие современные микропроцессоры.

2.  **超长指令字架构**  
    2.  **Архитектура VLIW**
    - **核心原理**：**编译器**在编译时找出并行性，并将**多个独立操作打包到一条超长指令**的不同字段中。每个字段控制一个功能部件。未使用的部件对应字段为空。  
      ‑ **Принцип**: **Компилятор** выявляет параллелизм и явно упаковывает **независимые операции в одно очень длинное командное слово**. Каждое поле команды отвечает за свою операцию (ФУ).
    - **代码特性**：代码包含精确的并行性信息和执行计划（何时执行、使用哪个FU、寄存器内容等）。编译器完全了解目标VLIW处理器。代表：Multiflow, Cydra。  
      ‑ **Характер кода**: Код содержит точный план выполнения программы. Компилятор имеет полное представление о целевом процессоре. Примеры: Multiflow, Cydra.
    - **主要缺点**：指令集**不向后兼容**（不同代处理器FU数量不同）；内存访问延迟不可完全预测，使静态指令调度复杂。  
      ‑ **Недостатки**: Наборы инструкций **не обратно совместимы**; задержки доступа к памяти непредсказуемы, что усложняет статическое планирование.

3.  **显式并行指令计算架构**  
    3.  **Архитектура EPIC**
    - **核心原理**：作为VLIW的**增强版**，核心思想仍是**编译时显式指定并行性**（编译器标记独立指令）。由Intel和HP联合开发（1997），代表：Intel Itanium。  
      ‑ **Принцип**: Усовершенствованный вариант **VLIW**. Параллелизм в машинном коде **явный**, поиск зависимостей осуществляет компилятор. Разработка Intel и HP (1997). Пример: Intel Itanium.
    - **关键增强特性**：
      - **谓词执行**：为条件分支的不同路径指令添加谓词（条件）字段，**并行执行分支**，然后根据条件选择结果。  
        ‑ **Предикация**: команды из разных ветвей условия снабжаются полями предикатов и запускаются параллельно.
      - **预取**：提前从慢速主内存加载数据。  
        ‑ **Предварительная загрузка**: данные из основной памяти загружаются заранее.
      - **大量寄存器** & **架构可扩展至大量功能块**。  
        ‑ **Большое количество регистров** & **Масштабируемость до большого количества функциональных блоков**.

--------------------------------------------------
核心对比与总结 / Ключевое сравнение и вывод  
--------------------------------------------------
- **根本区别**：**超标量 – 硬件管理并行**（动态，灵活，兼容性好）；**VLIW/EPIC – 软件（编译器）管理并行**（静态，高效，硬件简单，但兼容性/灵活性挑战）。  
  ‑ **Коренное отличие**: **Суперскалярность – аппаратное управление параллелизмом** (динамическое, гибкое, совместимое); **VLIW/EPIC – программное (компилятор) управление** (статическое, эффективное, аппаратура проще, но проблемы совместимости/гибкости).
- **趋势**：两者思想相互影响。编译时规划对超标量系统也很重要；而运行时动态机制能解决编译时无法确定的问题。  
  ‑ **Тенденция**: Идеи взаимно влияют. Создание плана во время компиляции важно и для суперскалярных систем; динамические механизмы во время выполнения разрешают неоднозначности.



## 32. Производительность вычислительных систем, методы оценки и измерения.
--------------------------------------------------
一、 性能指标与峰值性能  
I. Показатели и пиковая производительность  
--------------------------------------------------
1. 峰值性能 (Пиковая производительность, Rpeak)  
   ‑ 定义：计算机在理想条件下（无资源冲突、全负载运行）所能达到的最大理论性能。  
   ‑ 计算方式：基于硬件参数（如处理器数量、每个处理器的峰值浮点运算能力）明确计算得出。  
   ‑ 特点：实际程序性能永远无法达到，仅作为理论上限。不同任务能达到的百分比（2%-90%）差异巨大。  

   Пиковая производительность (Rpeak)  
   ‑ Определение: Максимальная теоретическая производительность компьютера в идеальных условиях (отсутствие конфликтов, полная загрузка устройств).  
   ‑ Расчет: Однозначно вычисляется на основе аппаратных параметров (число процессоров, пиковая производительность каждого).  
   ‑ Характеристика: Фактическая производительность реальных программ никогда её не достигает. Доля от пика варьируется от 2% до 90% в зависимости от задачи.  

2. 传统评估指标 (Традиционные способы оценки)  
   ‑ **MIPS (百万条指令/秒)**：衡量每秒执行的指令数。缺点：不同指令集和程序指令密度不同，难以跨平台比较。  
   ‑ **FLOPS (浮点运算次数/秒)**：衡量每秒执行的浮点运算数。优点：与程序的计算复杂度直接相关，用户可据此预估程序运行时间下限。  

   Традиционные показатели  
   ‑ **MIPS**: Измеряет число выполняемых команд в секунду. Недостаток: сложно сравнивать разные архитектуры из-за разного набора инструкций.  
   ‑ **FLOPS**: Измеряет число операций с плавающей запятой в секунду. Преимущество: напрямую связано со сложностью алгоритма, позволяет оценить нижнюю границу времени выполнения.  

--------------------------------------------------
二、 基准测试程序 (Benchmarks)  
II. Тестовые пакеты (Бенчмарки)  
--------------------------------------------------
1. 综合测试与真实测试 (Синтетические и реальные тесты)  
   ‑ **综合测试**：人为构造，用于对特定子系统（如内存、CPU）施加压力，不反映真实应用性能。  
   ‑ **真实测试**：使用真实应用和数据进行测试，更能反映实际工作负载下的性能。  

   Синтетические и реальные тесты  
   ‑ **Синтетические**: Искусственные, создают стрессовую нагрузку на отдельные подсистемы, не отражают реальную производительность.  
   ‑ **Реальные**: Выполняют реальные задачи на реальных данных, лучше отражают практическую эффективность.  

2. 著名基准测试套件 (Известные наборы тестов)  
   ‑ **LINPACK**: 解稠密线性方程组的测试。是TOP500排名的基础。提供三个变体（固定小矩阵100x100、可优化的大矩阵1000x1000、任意大矩阵Nmax）。Rmax（LINPACK最佳性能）通常是Rpeak的50-70%。  
   ‑ **STREAM**: 评估处理器与内存带宽的平衡性，使用长向量操作，数据不放入缓存。  
   ‑ **Livermore Fortran Kernels (LFK)**: 24个来自实际科学计算的循环内核，代表典型计算模式。  
   ‑ **PERFECT Club Benchmarks**: 13个真实应用程序（计算流体力学、天气预报等），总计超过5万行Fortran-77代码。  
   ‑ **NAS Parallel Benchmarks (NPB)**: 包含计算流体力学中的典型内核和模型应用，分为不同规模等级（A, B, C等）。  
   ‑ **SPEC**: 涵盖计算、Web服务器、图形等多个领域的测试套件，组成经常更新。SPEC OMPM2001专门用于评估共享内存并行系统（4-32个处理器）。  

   Известные тестовые пакеты  
   ‑ **LINPACK**: Решение СЛАУ с плотной матрицей. Основа рейтинга TOP500. Три варианта: 100x100 (фиксированный), 1000x1000 (с оптимизацией), Nmax (произвольный размер). Rmax (лучший результат LINPACK) составляет 50-70% от Rpeak.  
   ‑ **STREAM**: Оценка сбалансированности процессора и памяти, работа с длинными векторами вне кэша.  
   ‑ **Livermore Fortran Kernels (LFK)**: 24 вычислительных ядра из реальных научных программ.  
   ‑ **PERFECT Club Benchmarks**: 13 реальных приложений (вычислительная гидродинамика, прогноз погоды и др.), >50k строк на Fortran-77.  
   ‑ **NAS Parallel Benchmarks (NPB)**: Типичные ядра и модельные приложения из вычислительной гидродинамики, классы A, B, C.  
   ‑ **SPEC**: Тесты для вычислений, Web-серверов, графики и др. Состав обновляется. SPEC OMPM2001 — для систем с общей памятью (4-32 процессора).  

--------------------------------------------------
三、 性能测试的层次与要求  
III. Уровни и требования к тестированию производительности  
--------------------------------------------------
1. 对基准测试的主要要求 (Основные требования к тестам)  
   ‑ 结果一致且易懂、易于使用、可扩展、可移植、具有代表性、测试及其源代码可公开获取、结果可复现。  

   Основные требования к тестам производительности  
   ‑ Непротиворечивость и понятность результатов, лёгкость в использовании, масштабируемость, переносимость, репрезентативность, доступность теста и исходного кода, воспроизводимость.  

2. 系统性能测试的层次 (Уровни тестирования производительности системы)  
   ‑ **基础软件层**：操作系统、编译器、编程系统的效率。  
   ‑ **基础硬件层**：基本操作速度、内存层次间的传输速度与容量。  
   ‑ **I/O操作层**：与外设的读写效率、文件操作速度、异步I/O的合理性。  
   ‑ **基础通信层**：并行进程交互环境参数、基本通信与同步原语的效率。  
   ‑ **应用通信层**：逻辑进程拓扑到通信环境的映射效率、典型并行程序的通信特征分析。  
   ‑ **模型应用层**：执行不同结构的简单程序时的系统特性。  
   ‑ **实际应用层**：执行真实应用程序时的系统综合性能检验。  

   Уровни тестирования производительности системы  
   ‑ **Базовый уровень ПО**: Эффективность ОС, компиляторов, систем программирования.  
   ‑ **Базовый уровень аппаратуры**: Скорость элементарных операций, обмена между уровнями памяти, объёмы памяти.  
   ‑ **Уровень операций ввода/вывода**: Эффективность чтения/записи, работы с файлами, асинхронного ввода/вывода.  
   ‑ **Базовый коммуникационный уровень**: Параметры среды взаимодействия процессов, эффективность коммуникационных процедур и синхронизации.  
   ‑ **Коммуникационный уровень приложений**: Эффективность отображения топологий процессов, анализ коммуникационных профилей программ.  
   ‑ **Уровень модельных приложений**: Характеристики системы на простых программах разной структуры.  
   ‑ **Уровень реальных приложений**: Комплексная проверка характеристик на реальных программах.  

--------------------------------------------------
核心结论 / Ключевой вывод  
--------------------------------------------------
没有任何单一数字或一组数字能够全面衡量计算机性能。需要进行涵盖软硬件多个层次的综合测试，并结合代表性基准测试套件进行评估。  
Никакое одно число или даже набор чисел не являются универсальной характеристикой производительности компьютера. Требуется комплексное тестирование программно-аппаратной среды на различных уровнях с использованием репрезентативных наборов тестов.



33 Технологии параллельного программирования: способы и подходы создания параллельных программ.
--------------------------------------------------
一、并行编程的“四大分工模型”  
I. Четыре базовые модели распараллеливания  
--------------------------------------------------
1. 数据并行（Data Parallel）  
   ‑ 同一份代码，不同数据块，每人跑一块  
   ‑ 通信少，扩展易；最怕负载不均或数据相关  
   ‑ 典型：CUDA 的 warp、OpenMP `parallel for`  

   Данный параллелизм  
   ‑ Один код — разные блоки данных; каждый поток обрабатывает свой кусок  
   ‑ Минимум обменов, просто масштабировать; проблема — неравномерная нагрузка  
   ‑ Примеры: CUDA-warp, директива OpenMP `parallel for`  

2. 任务并行（Task Parallel）  
   ‑ 功能拆分，多阶段流水线，每人干一道工序  
   ‑ 需要显式传递中间结果，调度复杂  
   ‑ 典型：TBB `task_arena`, Go channel, MPI 流水线 Send/Recv  

   Задачный параллелизм  
   ‑ Разделение по этапам вычислений; каждый поток выполняет свою стадию  
   ‑ Нужно передавать промежуточные данные; сложнее планировать  
   ‑ Примеры: TBB-task, Go-channel, MPI-конвейер  

3. 分治并行（Divide-and-Conquer）  
   ‑ 大问题对半劈，递归再劈，最后归并结果  
   ‑ 天然树形调度，适合任务窃取  
   ‑ 典型：Cilk `cilk_spawn`, TBB `parallel_reduce`, 归并排序  

   Параллельное деление-и-властвование  
   ‑ Рекурсивное дробление задачи и слияние результатов  
   ‑ Дерево задач позволяет «красть» свободным потокам  
   ‑ Примеры: Cilk-spawn, TBB-reduce, сортировка слиянием  

4. 流水线并行（Pipelined Parallel）  
   ‑ 时间切片，数据流像传送带，各站同时工作  
   ‑ 延迟隐藏好，吞吐高；启动与排空有损耗  
   ‑ 典型：FFmpeg 滤镜链、GPU 计算+拷贝双缓冲、MPI 双缓冲 Send/Recv  

   Конвейерный параллелизм  
   ‑ Данные движутся по стадиям, каждая выполняется одновременно  
   ‑ Высокая пропускная способность; потери на заполнение/опорожнение  
   ‑ Примеры: FFmpeg-фильтры, GPU double-buffer, MPI-пайплайн  

--------------------------------------------------
二、语言/库“三层金字塔”  
II. Трёхуровневая стека языков и библиотек  
--------------------------------------------------
1. 语言级原生并发  
   ‑ C++20 `std::jthread`, Rust `tokio`, Go `goroutine`  
   ‑ 语法轻，调度器在用户态或运行时  

   Нативные средства языка  
   ‑ `std::jthread`, Rust tokio, Go-goroutine  
   ‑ Лёгкий синтаксис, шедулер в пользовательском режиме  

2. 编译指导式（Directive）  
   ‑ 在串行代码里插一行 pragma，编译器自动生成线程  
   ‑ OpenMP、OpenACC；学习曲线最平滑  

   Директивы компилятора  
   ‑ Одна строка `#pragma omp parallel` — и цикл распараллеливается автоматически  
   ‑ OpenMP/OpenACC — самый плавный вход в параллелизм  

3. 显式库/运行时  
   ‑ MPI 进程级，跨节点；CUDA/HIP 控制 GPU 网格；Pthreads 最底层  
   ‑ 可控性最高，代码量最大  

   Явные библиотеки и runtime  
   ‑ MPI — межузловой, CUDA/HIP — GPU, Pthreads — низкий уровень  
   ‑ Максимум контроля и деталей  

--------------------------------------------------
三、算法“六板斧”  
III. Шесть алгоритмических приёмов  
--------------------------------------------------
1. 分块（Blocking） — 让数据留在 Cache  
2. SIMD/向量化 — 一次算 8-16 个数  
3. 任务窃取 — 空闲线程动态“抢”任务  
4. 双缓冲 — 计算与传输重叠  
5. 归约树 — O(log n) 完成求和/最大值  
6. 集体通信 — MPI_Allreduce 代替点对点风暴  

--------------------------------------------------
四、调试与调优“四大坑”  
IV. Четыре «колодца» отладки и оптимизации  
--------------------------------------------------
1. 数据竞争 (race) → 加锁/原子/私有化  
2. 伪共享 (false sharing) → 64 B 对齐填充  
3. 负载不均 → 动态调度 / 任务窃取  
4. 通信延迟 → 异步+双缓冲+集体原语



## 34. MPI: параллельная программа, сообщение, понятия групп и коммуникаторов.
--------------------------------------------------
一、 Общие сведения о MPI и базовая структура программы (MPI概览与程序基础结构)
I. Общие сведения о MPI и базовая структура программы
--------------------------------------------------
- **MPI 简介**: MPI (Message Passing Interface) 是基于消息传递模型的标准化并行编程接口。采用 SPMD (单程序多数据) 模型，提供 C 和 Fortran 语言绑定。
    - **Введение в MPI**: MPI (Message Passing Interface) — стандартизированный интерфейс для параллельного программирования по модели передачи сообщений. Использует модель SPMD (одна программа, множество данных), предоставляет привязки для языков C и Fortran.

- **程序生命周期**:
    1.  **初始化**: `MPI_Init(&argc, &argv)` — 必须在所有其他 MPI 调用之前执行一次，启动并行环境。
        - **Инициализация**: `MPI_Init(&argc, &argv)` — должна быть вызвана один раз до всех других вызовов MPI, запускает параллельное окружение.
    2.  **获取信息**: `MPI_Comm_size(comm, &size)` 获取通信域内进程总数；`MPI_Comm_rank(comm, &rank)` 获取当前进程在通信域中的编号 (0 到 size-1)。
        - **Получение информации**: `MPI_Comm_size(comm, &size)` возвращает общее количество процессов в коммуникаторе; `MPI_Comm_rank(comm, &rank)` возвращает номер (ранг) текущего процесса в коммуникаторе (от 0 до size-1).
    3.  **终止**: `MPI_Finalize()` — 结束 MPI 环境，之后不能再调用 MPI 例程（除 `MPI_Finalized`）。
        - **Завершение**: `MPI_Finalize()` — завершает работу с MPI, после неё нельзя вызывать процедуры MPI (кроме `MPI_Finalized`).

--------------------------------------------------
二、 Ключевые абстракции MPI: группы, коммуникаторы и сообщения (MPI核心抽象：组、通信域与消息)
II. Ключевые абстракции MPI: группы, коммуникаторы и сообщения
--------------------------------------------------
**1. Группа и коммуникатор (组与通信域):**
   - **Группа (группа)**: 进程的有序集合，是通信域的组成部分。
        - **Группа (группа)**: Упорядоченное множество процессов, часть коммуникатора.
   - **Коммуникатор (коммуникатор)**: 通信上下文，包含一个进程组和用于消息传递的独立上下文。所有通信操作都基于通信域进行。
        - **Коммуникатор (коммуникатор)**: Контекст обмена, включающий группу процессов и независимый контекст для передачи сообщений. Все операции обмена используют коммуникаторы.
   - **预定义通信域**:
        - `MPI_COMM_WORLD`: 包含应用程序所有进程的通信域。
        - `MPI_COMM_SELF`: 仅包含当前进程自身的通信域。
        - `MPI_COMM_NULL`: 空通信域，不包含任何进程。
        - **Предопределённые коммуникаторы**:
            - `MPI_COMM_WORLD`: Коммуникатор, включающий все процессы приложения.
            - `MPI_COMM_SELF`: Коммуникатор, содержащий только текущий процесс.
            - `MPI_COMM_NULL`: Пустой коммуникатор (не содержит процессов).

**2. Сообщение и его атрибуты (消息及其属性):**
   - **Сообщение (сообщение)**: 存储在连续内存中的同类型数据数组。
        - **Сообщение (сообщение)**: Массив однотипных данных, расположенных в последовательных ячейках памяти.
   - **关键属性**:
        - **源进程 (отправитель)**: 发送方进程编号（在通信域内）。
        - **目标进程 (получатель)**: 接收方进程编号（在通信域内）。
        - **消息标签 (идентификатор/тег)**: 整数标识符 (0 到 `MPI_TAG_UB`，通常至少 32767)，用于区分不同类型消息。
        - **通信域 (коммуникатор)**: 定义通信上下文。
        - **Ключевые атрибуты**:
            - **Отправитель**: Ранг процесса-отправителя (в рамках коммуникатора).
            - **Получатель**: Ранг процесса-получателя (в рамках коммуникатора).
            - **Тег сообщения**: Целочисленный идентификатор (от 0 до `MPI_TAG_UB`, обычно не менее 32767) для различения типов сообщений.
            - **Коммуникатор**: Определяет контекст обмена.

**3. Создание и управление коммуникаторами (通信域的创建与管理):**
   - **Дублирование (дублирование)**: `MPI_Comm_dup(comm, &newcomm)` 复制现有通信域，创建一个包含相同进程组但具有全新上下文的新通信域。
        - **Дублирование**: `MPI_Comm_dup(comm, &newcomm)` дублирует существующий коммуникатор, создавая новый с той же группой, но новым контекстом.
   - **Создание из группы (从组创建)**: `MPI_Comm_create(comm, group, &newcomm)` 基于现有通信域 `comm` 和一个子进程组 `group` 创建新的通信域。
        - **Создание из группы**: `MPI_Comm_create(comm, group, &newcomm)` создает новый коммуникатор на основе существующего `comm` и подгруппы `group`.
   - **Освобождение (释放)**: `MPI_Comm_free(&comm)` 释放通信域资源，将其句柄置为 `MPI_COMM_NULL`。
        - **Освобождение**: `MPI_Comm_free(&comm)` уничтожает коммуникатор, устанавливая его дескриптор в `MPI_COMM_NULL`.

--------------------------------------------------
**核心范式总结 / Резюме ключевой парадигмы**
--------------------------------------------------
MPI 程序的核心是**通过通信域组织起来的进程组之间显式的消息交换**。每个进程通过其在通信域内的**编号（rank）** 进行标识。**通信域（communicator）** 提供了隔离的通信上下文，是管理复杂并行交互和构建可扩展应用程序的基础。
Ядро программы MPI — **явный обмен сообщениями между группами процессов, организованными в коммуникаторы**. Каждый процесс идентифицируется своим **номером (рангом)** в коммуникаторе. **Коммуникатор** предоставляет изолированный контекст общения и является основой для управления сложными параллельными взаимодействиями и построения масштабируемых приложений.



## 35. MPI: синхронное взаимодействие процессов, виды операторов Send (Bsend, Ssend, Rsend). Тупиковые ситуации.
--------------------------------------------------
一、 Точка-точка взаимодействие в MPI: блокирующие и неблокирующие операции (MPI中的点对点交互：阻塞与非阻塞操作)
I. Точка-точка взаимодействие в MPI: блокирующие и неблокирующие операции
--------------------------------------------------
- **点对点操作**: 涉及两个进程（一个发送者，一个接收者）的通信。发送方调用发送例程指定接收方编号，接收方调用接收例程（可能不知道发送方编号）。
    - **Индивидуальные операции (точка-точка)**: Взаимодействие двух процессов (отправитель и получатель). Отправитель вызывает процедуру отправки, указывая ранг получателя; получатель вызывает процедуру приема (возможно, без указания отправителя).

- **阻塞与非阻塞**:
    - **Блокирующие (синхронные) операции**: 例程会挂起进程，直到满足特定条件（如发送缓冲区可重用或消息被接收）后才返回。
        - **Блокирующие (синхронные) операции**: Процедура приостанавливает работу процесса до выполнения условия (напр., повторного использования буфера отправки или получения сообщения) перед возвратом.
    - **Неблокирующие (асинхронные) операции**: 例程在初始化通信操作后立即返回，允许进程在后台传输数据时继续计算。
        - **Неблокирующие (асинхронные) операции**: Процедура возвращается немедленно после инициализации операции, позволяя процессу продолжать вычисления во время передачи данных.

--------------------------------------------------
二、 Виды блокирующих операторов Send (阻塞发送操作符的类型)
II. Виды блокирующих операторов Send
--------------------------------------------------
**1. `MPI_Bsend` (буферизированная отправка / 缓冲发送):**
   - **机制**: 消息被复制到用户提供的缓冲区后，发送例程立即返回，不等待接收方启动接收。发送与接收操作完全解耦。
        - **Механизм**: Сообщение копируется в предоставленный пользователем буфер, процедура возвращается немедленно, не дожидаясь инициализации приема получателем. Отправка и прием полностью разделены.
   - **风险**: 若缓冲区空间不足，则返回错误。需要用户预先分配缓冲区（通过 `MPI_Buffer_attach`）。
        - **Риск**: Возвращает ошибку, если в буфере недостаточно места. Требует предварительного выделения буфера пользователем (через `MPI_Buffer_attach`).

**2. `MPI_Ssend` (синхронная отправка / 同步发送):**
   - **机制**: 发送方会阻塞，直到接收方**已启动**对应的接收操作（即双方“握手”）。这保证了接收方已到达接收点，且发送缓冲区可安全重用。
        - **Механизм**: Отправитель блокируется до тех пор, пока получатель **не инициирует** соответствующий прием («рукопожатие»). Гарантирует, что получатель достиг точки приема, и буфер отправки можно безопасно повторно использовать.
   - **影响**: 速度可能较慢，但避免了系统中堆积大量未接收的缓冲消息，提供了更强的同步性。
        - **Влияние**: Может быть медленнее, но предотвращает накопление непринятых буферизированных сообщений, обеспечивает более строгую синхронизацию.

**3. `MPI_Rsend` (отправка по готовности / 就绪发送):**
   - **机制**: **前提是接收方已发布接收操作**。发送方假设接收已就绪，直接开始传输。若接收未就绪，则行为未定义（可能导致错误）。
        - **Механизм**: **Требует, чтобы получатель уже опубликовал операцию приема**. Отправитель предполагает готовность получателя и начинает передачу сразу. Если прием не инициирован, поведение не определено (может вызвать ошибку).
   - **优化**: 在许多实现中可减少协议开销，提高性能，但必须通过其他同步机制（如 `MPI_Barrier`）确保接收就绪。
        - **Оптимизация**: Во многих реализациях сокращает накладные расходы протокола, повышая производительность, но требует гарантии готовности приема через другие механизмы синхронизации (напр., `MPI_Barrier`).

--------------------------------------------------
三、 Потенциальные тупиковые ситуации (死锁风险)
III. Потенциальные тупиковые ситуации
--------------------------------------------------
- **死锁风险**: 当两个或多个进程相互等待对方完成某个操作时，程序会永久挂起。在使用阻塞通信时尤其常见。
    - **Риск взаимной блокировки**: Программа зависает навсегда, когда два или более процесса ждут друг друга для завершения операции. Особенно характерно при использовании блокирующей связи.

- **典型场景示例**:
    1.  **顺序不匹配**: 进程A向进程B发送消息并等待完成，同时进程B向进程A发送消息并等待完成。若两者都使用 `MPI_Ssend` 或标准 `MPI_Send`（可能依赖缓冲区），且未提供足够缓冲区，则可能死锁。
        - **Несоответствие порядка**: Процесс A отправляет сообщение процессу B и ждет, в то время как процесс B отправляет сообщение процессу A и ждет. Если оба используют `MPI_Ssend` или стандартный `MPI_Send` (который может зависеть от буферизации) и буферов недостаточно, может возникнуть тупик.
    2.  **缺少匹配的接收**: 使用 `MPI_Rsend` 时，若接收方未提前发布接收，发送方可能无限期等待或导致错误。
        - **Отсутствие соответствующего приема**: При использовании `MPI_Rsend`, если получатель не опубликовал прием заранее, отправитель может ждать бесконечно или вызвать ошибку.
    3.  **循环依赖**: 多个进程形成环形发送-等待链，每个进程都在发送消息给下一个进程并等待接收前一个进程的消息。
        - **Циклическая зависимость**: Несколько процессов образуют кольцо отправки-ожидания, где каждый отправляет сообщение следующему и ждет сообщения от предыдущего.

- **预防措施**:
    - 仔细设计通信顺序，避免循环等待。
    - 使用非阻塞操作（`MPI_Isend`, `MPI_Irecv`）与 `MPI_Wait` 或 `MPI_Test` 结合。
    - 使用 `MPI_Ssend` 或 `MPI_Bsend` 时确保有足够的缓冲区或同步。
    - 对于 `MPI_Rsend`，确保在发送前接收操作已发布（例如通过显式同步）。
    - **Меры предосторожности**:
        - Тщательно проектировать порядок обмена, избегать циклического ожидания.
        - Использовать неблокирующие операции (`MPI_Isend`, `MPI_Irecv`) в сочетании с `MPI_Wait` или `MPI_Test`.
        - При использовании `MPI_Ssend` или `MPI_Bsend` обеспечивать достаточную буферизацию или синхронизацию.
        - Для `MPI_Rsend` гарантировать, что операция приема уже опубликована перед отправкой (напр., через явную синхронизацию).

--------------------------------------------------
**核心要点总结 / Резюме ключевых моментов**
--------------------------------------------------
MPI的阻塞发送操作提供了不同级别的同步和性能保证：**`MPI_Bsend`（缓冲）** 解耦发送与接收，但需管理缓冲区；**`MPI_Ssend`（同步）** 确保接收方已就绪，但可能更慢；**`MPI_Rsend`（就绪）** 性能最高，但要求接收方已发布接收，否则行为未定义。使用这些操作时必须注意通信顺序和同步，以避免**死锁**。
Блокирующие операции отправки MPI предоставляют различные уровни синхронизации и гарантий производительности: **`MPI_Bsend` (буферизированная)** развязывает отправку и прием, но требует управления буфером; **`MPI_Ssend` (синхронная)** гарантирует готовность получателя, но может быть медленнее; **`MPI_Rsend` (по готовности)** наиболее производительна, но требует, чтобы прием был уже опубликован, иначе поведение не определено. При использовании этих операций необходимо внимательно относиться к порядку обмена и синхронизации, чтобы избежать **взаимных блокировок (тупиков)**.



36 MPI: асинхронное взаимодействие процессов. 
--------------------------------------------------  
一、异步通信的本质与位置  
I. Суть и место асинхронного обмена  
--------------------------------------------------  
1. 异步 = “后台快递”  
   ‑ 调用立即返回，进程继续计算；数据搬运由 MPI 运行时悄悄完成  
   ‑ 完成与否通过 Request 句柄后续“查票”确认  

   Асинхрон = «фоновая доставка»  
   ‑ Вызов возвращается мгновенно, расчёты продолжаются; данные таскает MPI  

2. 与阻塞通信的互补定位  
   ‑ 阻塞：逻辑简单，易读易调试；CPU 空等  
   ‑ 异步：隐藏延迟、重叠计算/通信；代码复杂度 ↑  

   Дополняет блокирующие операции  
   ‑ Блокирующие — проще, но ядро простаивает  
   ‑ Асинхронные — скрываем задержку, усложняем логику  

--------------------------------------------------  
二、异步三件套 API  
II. Три базовые асинхронные процедуры  
--------------------------------------------------  
1. MPI_Isend — 非阻塞发送  
   ‑ 立即获得 Request；消息可能仍在用户缓冲区  
   ‑ 禁止提前改写缓冲区 → 竞态 = 未定义行为  

   Нелокирующая отправка  
   ‑ Запрос в возвращаемом Request; буфер ещё жив  

2. MPI_Irecv — 非阻塞接收  
   ‑ 提交“空邮箱”；完成后 MPI 把数据灌入  
   ‑ 提前读邮箱 = 垃圾数据  

   Нелокирующий приём  
   ‑ Постим ящик; трогать раньше Wait — мусор  

3. MPI_Wait / Test 家族 — 完成探测器  
   ‑ Wait：阻塞到完成；Test：立即给 flag  
   ‑ Waitall/Testany 等：批量管理多 Request  

   Семейство Wait/Test  
   ‑ Ждём или мгновенно проверяем готовность  

--------------------------------------------------  
三、典型使用范式  
III. Классические шаблоны применения  
--------------------------------------------------  
1. 计算-通信重叠  
   ├─ Isend/Irecv → 做大段与缓冲区无关的计算 → Wait  
   └─ 常用双缓冲/环缓冲，流水线推进  

   Перекрытие вычислений и коммуникаций  
   ├─ Двойной буфер, пока один летит — считаем в другом  

2. 软实时“心跳”  
   ├─ 每 N 毫秒 Test 所有 Request → 有结果就处理  
   └─ 避免阻塞事件循环  

   «Сердцебиение» в soft-real-time  
   ├─ Цикл событий не засыпает  

3. 通信隐藏策略  
   ├─ 小消息 eager 模式 → Isend 几乎零开销  
   └─ 大消息 rendezvous → 握手在后台，Wait 时才暴露延迟  

   Скрытие задержек  
   ├─ Мелкие пакеты уходят сразу  
   └─ Крупные — рукопожатие в фоне  

--------------------------------------------------  
四、性能与正确性陷阱  
IV. Ловушки производительности и корректности  
--------------------------------------------------  
1. 早 touching — 数据竞态  
   ‑ 用户缓冲区 трогать до Wait = undefined  

2. 忘记 Wait — 资源泄漏  
   ‑ Request не освободится → память + дескрипторы растут  

3. 系统 eager 限额  
   ‑ 消息 >  eager 阈值 → MPI_Isend 内部 всё равно заблокируется  

4. 海量 Request  
   ‑ >256 未完结 — внутренний массив MPI растёт, задержки ↑  

--------------------------------------------------  
五、快速调优备忘  
V. Чек-лист быстрой настройки  
--------------------------------------------------  
- Сообщения <8 КиБ — почти всегда eager, Isend=free  
- Используйте MPI_Waitall пачками, чтобы снизить системные вызовы  
- Для крупных сообщений — буферизация MPI_Buffer_attach + MPI_Ibsend  
- Проверка каждый цикл: MPI_Testany + MPI_Wtick = экономия CPU  

--------------------------------------------------  
一句话速记  
Асинхронный девиз：«Отправил — забыл, но не совсем: Request жив — буфер чужой, Wait не вызвал — утечка свой!»



## 37. MPI: коллективные операции.
--------------------------------------------------
一、 集体操作概述与特性  
I. Общие сведения и свойства коллективных операций  
--------------------------------------------------
- **参与范围**：集体操作涉及**通信器中的所有进程**。  
  ‑ **Участие**: В операциях коллективного взаимодействия участвуют **все процессы коммуникатора**.
- **缓冲区和同步**：操作返回后，可安全访问发送/接收缓冲区。集体操作消息**不与其他消息交叉**。  
  ‑ **Буферы и синхронизация**: После возврата разрешён свободный доступ к буферу. Сообщения от коллективных операций **не пересекаются** с другими.
- **非同步性**：一般而言，**不能依赖集体操作进行进程同步**（除了`MPI_BARRIER`）。一个进程完成其参与部分，不意味着其他进程已开始或已完成该操作。  
  ‑ **Несинхронность**: **Нельзя рассчитывать на синхронизацию** процессами (кроме `MPI_BARRIER`). Завершение участия одним процессом не означает завершения операции другими.
- **其他规则**：集体操作**不使用消息标签**，且**严格按在程序文本中出现的顺序执行**。  
  ‑ **Другие правила**: В коллективных операциях **не используются теги**, и они **строго упорядочены** по появлению в тексте программы.

--------------------------------------------------
二、 主要集体操作分类与功能  
II. Классификация и функции основных коллективных операций  
--------------------------------------------------
1.  **同步与数据分发**  
    1.  **Синхронизация и распространение данных**
    - `MPI_BARRIER(comm)`: **路障同步**。阻塞调用进程，直到通信器 `comm` 中所有进程都调用此函数。  
      ‑ `MPI_BARRIER(comm)`: **Барьерная синхронизация**. Блокирует процесс до вызова этой процедуры всеми процессами коммуникатора.
    - `MPI_BCAST(buf, count, type, root, comm)`: **广播**。从根进程 `root` 向通信器 `comm` 中所有进程（包括自身）发送 `count` 个类型为 `type` 的数据。  
      ‑ `MPI_BCAST(...)`: **Рассылка (broadcast)**. Рассылка данных от процесса `root` всем процессам коммуникатора.

2.  **数据收集与散播**  
    2.  **Сбор и раздача данных**
    - `MPI_GATHER(sbuf, scount, stype, rbuf, rcount, rtype, root, comm)`: **收集**。从所有进程收集数据到根进程 `root` 的接收缓冲区，**按进程号顺序存储**。  
      ‑ `MPI_GATHER(...)`: **Сборка**. Сбор данных со всех процессов в буфер процесса `root` **в порядке возрастания номеров процессов**.
    - `MPI_SCATTERV(sbuf, scounts, displs, stype, rbuf, rcount, rtype, root, comm)`: **可变散播**。从根进程的发送缓冲区向各进程发送**不同数量**的数据，偏移由数组 `displs` 指定。  
      ‑ `MPI_SCATTERV(...)`: **Рассылка различного количества данных**. Рассылка порций разного размера, начало задаётся массивом `displs`.

3.  **全局数据交换**  
    3.  **Глобальный обмен данными**
    - `MPI_ALLGATHER(sbuf, scount, stype, rbuf, rcount, rtype, comm)`: **全局收集**。所有进程都收集到来自所有进程的数据（类似 `MPI_GATHER`，但结果在所有进程）。  
      ‑ `MPI_ALLGATHER(...)`: **Сборка на всех процессах**. Каждый процесс получает данные от всех.
    - `MPI_ALLTOALL(sbuf, scount, stype, rbuf, rcount, rtype, comm)`: **全交换**。每个进程向所有其他进程发送不同的数据块。进程 `i` 的发送缓冲区第 `j` 块发给进程 `j` 的接收缓冲区第 `i` 块。  
      ‑ `MPI_ALLTOALL(...)`: **Рассылка всем от всех**. j-й блок процесса i попадает в i-й блок процесса j.

4.  **归约操作**  
    4.  **Редукционные операции**
    - `MPI_REDUCE(sbuf, rbuf, count, type, op, root, comm)`: **归约**。对来自所有进程的 `count` 个数据元素按操作 `op` 进行全局计算（如求和、求最大值），结果存放在根进程 `root` 的 `rbuf` 中。  
      ‑ `MPI_REDUCE(...)`: **Глобальная операция редукции**. Выполнение операции `op` над элементами массивов `sbuf` всех процессов, результат в процессе `root`.
    - `MPI_ALLREDUCE(...)`: **全局归约**。结果在所有进程的 `rbuf` 中。  
      ‑ `MPI_ALLREDUCE(...)`: **Глобальная редукция на всех процессах**. Результат получает каждый процесс.
    - `MPI_REDUCE_SCATTER(sbuf, rbuf, rcounts, type, op, comm)`: **归约散播**。先执行全局归约操作，然后将结果按 `rcounts` 数组指定的数量散播到各进程。  
      ‑ `MPI_REDUCE_SCATTER(...)`: **Редукция с последующей рассылкой**. Сначала глобальная операция, затем результат рассылается по процессам.
    - `MPI_SCAN(sbuf, rbuf, count, type, op, comm)`: **前缀扫描**。执行前缀归约操作。进程 `i` 的 `rbuf` 包含对进程 `0` 到 `i` 的 `sbuf` 元素应用操作 `op` 的结果。  
      ‑ `MPI_SCAN(...)`: **Частичная (префиксная) редукция**. i-й процесс выполняет операцию над элементами процессов 0…i.

5.  **自定义操作**  
    5.  **Пользовательские операции**
    - `MPI_OP_CREATE(func, commute, op)`: **创建自定义归约操作**。`func` 为用户定义的函数。若 `commute=1`，操作应为**可交换且可结合**的。  
      ‑ `MPI_OP_CREATE(...)`: **Создание пользовательской глобальной операции**. Если `commute=1`, операция должна быть **коммутативной и ассоциативной**.
    - `MPI_OP_FREE(op)`: **释放自定义操作**。  
      ‑ `MPI_OP_FREE(op)`: **Уничтожение пользовательской операции**.

--------------------------------------------------
核心要点总结 / Ключевые выводы  
--------------------------------------------------
MPI集体操作的核心特性与分类：  
1.  **集体性**：涉及通信器内所有进程，需所有进程调用匹配的操作。  
2.  **功能多样**：包括同步(`BARRIER`)、数据移动(`BROADCAST`, `GATHER`, `SCATTER`, `ALLTOALL`)、规约计算(`REDUCE`, `SCAN`)等。  
3.  **结果一致性**：操作结果在所有进程或指定根进程上保持一致。  
4.  **可扩展性**：支持可变数量数据(`v`后缀)和自定义规约操作。  

Ключевые особенности и классификация коллективных операций MPI:  
1.  **Коллективность**: Участвуют все процессы коммуникатора, все должны вызвать соответствующую операцию.  
2.  **Функциональное разнообразие**: Включают синхронизацию(`BARRIER`), перемещение данных(`BROADCAST`, `GATHER`, `SCATTER`, `ALLTOALL`), редукционные вычисления(`REDUCE`, `SCAN`).  
3.  **Согласованность результатов**: Результаты операции одинаковы на всех процессах или на указанном корневом процессе.  
4.  **Масштабируемость**: Поддержка переменного количества данных (суффикс `v`) и пользовательских операций.



## 38. MPI: пересылка разнотипных данных, пересылка упакованных данных.
--------------------------------------------------
一、 派生数据类型 (Пересылка разнотипных данных)  
I. Производные типы данных (Derived Data Types)  
--------------------------------------------------
1. **概念与创建步骤 (Концепция и этапы создания)**  
   ‑ **目的**：发送内存中非连续或类型不同的数据集合。  
   ‑ **两步创建法**：1) **构造类型**：使用构造函数定义数据布局（元素类型、数量、偏移）。2) **提交类型**：使用 `MPI_Type_commit` 注册类型后方可用于通信。完成后需用 `MPI_Type_free` 释放。  
   ‑ **关键特征**：由（基本类型，偏移量）对序列定义。偏移量可正可负，无需有序，允许元素重复和顺序重排。  

   Концепция и этапы создания  
   ‑ **Цель**: Отправка совокупности данных разного типа или расположенных в памяти неконтигуально.  
   ‑ **Два этапа**: 1) **Конструирование типа**: Определение макета данных (типы элементов, количество, смещения). 2) **Регистрация типа**: Вызов `MPI_Type_commit` для регистрации перед использованием в обмене. Освобождение — `MPI_Type_free`.  
   ‑ **Ключевая характеристика**: Определяется последовательностью пар (базовый тип, смещение). Смещения могут быть любыми, порядок может отличаться от исходного, допускается повторение элементов.  

2. **主要类型构造函数 (Основные конструкторы типов)**  
   ‑ **`MPI_Type_contiguous`**：用于连续的、同类型的数据块（如：5个连续的整数）。  
   ‑ **`MPI_Type_vector`**：用于等间距的块（如：矩阵中的列或行片段）。参数：块数 `count`、每块元素数 `blocklen`、块间跨度（以元素计）`stride`。  
   ‑ **`MPI_Type_create_hvector`**：与 `vector` 类似，但跨度以**字节** (`MPI_Aint stride`) 为单位。  
   ‑ **`MPI_Type_indexed`** 与 **`MPI_Type_create_indexed_block`**：用于任意位移的块。`indexed` 允许每块长度不同，`create_indexed_block` 要求所有块长度相同。位移以元素数计。  
   ‑ **`MPI_Type_create_struct`**：最通用的构造函数，用于**混合不同类型**的数据（如结构体）。每个块可以有不同的基本类型 (`types[i]`) 和以**字节**为单位的位移 (`displs[i]`)。需配合 `MPI_Get_address` 获取变量的绝对地址来计算位移。  
   ‑ **`MPI_Type_create_subarray`**：用于描述多维数组的一个子区域（子数组）。  

   Основные конструкторы типов  
   ‑ **`MPI_Type_contiguous`**: Для контигуальных блоков однотипных данных (напр., 5 подряд идущих целых чисел).  
   ‑ **`MPI_Type_vector`**: Для блоков с постоянным шагом (напр., фрагменты столбцов матрицы). Параметры: число блоков `count`, элементов в блоке `blocklen`, шаг в элементах `stride`.  
   ‑ **`MPI_Type_create_hvector`**: Как `vector`, но шаг задаётся в **байтах** (`MPI_Aint stride`).  
   ‑ **`MPI_Type_indexed`** и **`MPI_Type_create_indexed_block`**: Для блоков с произвольными смещениями. `indexed` допускает разную длину блоков, `create_indexed_block` — одинаковую. Смещения в элементах.  
   ‑ **`MPI_Type_create_struct`**: Самый универсальный конструктор для **разнотипных** данных (напр., структур). Каждый блок может иметь свой базовый тип (`types[i]`) и смещение в **байтах** (`displs[i]`). Требует `MPI_Get_address` для получения абсолютных адресов переменных.  
   ‑ **`MPI_Type_create_subarray`**: Для описания подмассива многомерного массива.  

3. **辅助函数 (Вспомогательные функции)**  
   ‑ **`MPI_Get_address`**：获取变量在内存中的绝对字节地址（相对于 `MPI_BOTTOM`），用于计算结构体中的位移。  
   ‑ **`MPI_Type_size`**：获取已提交数据类型的大小（以字节为单位）。  
   ‑ **`MPI_Type_get_extent`**：获取数据类型的下界 (`lb`) 和范围 (`extent`)，用于了解类型的内存占用。  

   Вспомогательные функции  
   ‑ **`MPI_Get_address`**: Определяет абсолютный байт-адрес переменной (относительно `MPI_BOTTOM`). Используется для расчёта смещений в структурах.  
   ‑ **`MPI_Type_size`**: Определяет размер типа в байтах.  
   ‑ **`MPI_Type_get_extent`**: Определяет нижнюю границу (`lb`) и диапазон (`extent`) типа данных в байтах.  

--------------------------------------------------
二、 数据打包 (Пересылка упакованных данных)  
II. Упаковка данных (Packing Data)  
--------------------------------------------------
1. **打包与解包 (Упаковка и распаковка)**  
   ‑ **目的**：将不同类型的数据手动打包到单个连续的发送缓冲区中，作为 `MPI_PACKED` 类型发送。  
   ‑ **`MPI_Pack`**：将 `incount` 个 `datatype` 类型的元素从 `inbuf` 打包到 `outbuf` 中，从位置 `position`（字节偏移）开始。打包后 `position` 增加所写入的字节数。  
   ‑ **`MPI_Unpack`**：从 `inbuf` 中位置 `position` 开始，解包出 `outcount` 个 `datatype` 类型的元素到 `outbuf` 中。  
   ‑ **`MPI_Pack_size`**：计算打包 `incount` 个 `datatype` 类型元素所需的缓冲区大小（字节数），用于预先分配足够大的缓冲区。  

   Упаковка и распаковка  
   ‑ **Цель**: Вручную собрать разнотипные данные в единый контигуальный буфер для отправки как тип `MPI_PACKED`.  
   ‑ **`MPI_Pack`**: Упаковывает `incount` элементов типа `datatype` из `inbuf` в `outbuf`, начиная со смещения `position` (в байтах). После упаковки `position` увеличивается на число записанных байт.  
   ‑ **`MPI_Unpack`**: Распаковывает из `inbuf` (со смещения `position`) `outcount` элементов типа `datatype` в `outbuf`.  
   ‑ **`MPI_Pack_size`**: Определяет необходимый размер буфера (в байтах) для упаковки `incount` элементов типа `datatype`.  

2. **通信方式 (Организация обмена)**  
   ‑ 发送打包数据时，使用 `MPI_Send` / `MPI_Recv` 等标准通信函数，但数据类型指定为 **`MPI_PACKED`**。  
   ‑ 接收方收到 `MPI_PACKED` 类型的数据后，必须使用 `MPI_Unpack` 按照与发送方相同的顺序和类型进行解包。  

   Организация обмена  
   ‑ Для отправки упакованных данных используются стандартные функции (напр., `MPI_Send`/`MPI_Recv`), но тип данных указывается как **`MPI_PACKED`**.  
   ‑ Получив данные типа `MPI_PACKED`, получатель должен использовать `MPI_Unpack` для распаковки в том же порядке и тех же типов, что и при упаковке.  

--------------------------------------------------
方法对比 / Сравнение подходов  
--------------------------------------------------
**派生数据类型**：由MPI运行时管理，更高效、优雅，适合模式固定的复杂数据布局。  
**数据打包**：更灵活（可动态改变打包内容），但需要手动管理缓冲区，并引入额外的打包/解包开销。  

**Производные типы**: Управляются средой выполнения MPI, более эффективны и элегантны для сложных, но фиксированных структур данных.  
**Упаковка данных**: Более гибкая (можно динамически менять содержимое), но требует ручного управления буфером и добавляет накладные расходы на упаковку/распаковку.



## 39. OpenMP: параллельная программа, нити, конструкции для организации параллельных и последовательных секций.
--------------------------------------------------
一、 Основные понятия и модель выполнения (基本概念与执行模型)
I. Основные понятия и модель выполнения
--------------------------------------------------
- **技术本质**: OpenMP 是基于共享内存的并行编程技术，通过向串行程序添加编译指令、库函数和环境变量来创建并行版本。
    - **Сущность технологии**: OpenMP — технология параллельного программирования для систем с общей памятью, добавляющая параллелизм к последовательной программе через директивы компилятора, библиотечные функции и переменные окружения.

- **执行线程**:
    - **主线程 (нить-мастер)**: 程序启动时创建，负责执行所有串行区域，线程号固定为0。
        - **Главная нить (нить-мастер)**: Создается при запуске программы, исполняет все последовательные области, её номер всегда 0.
    - **工作线程**: 进入并行区域时动态创建，数量通常由 `OMP_NUM_THREADS` 控制。所有线程（包括主线程）共同执行并行区域内的代码。
        - **Рабочие нити**: Динамически создаются при входе в параллельную область, их количество обычно контролируется `OMP_NUM_THREADS`. Весь код в параллельной области исполняется всеми нитями (включая мастер).

- **区域与同步**: 程序分为串行和并行区域。退出并行区域时会发生隐式同步：主线程等待所有其他线程结束，此后仅主线程继续执行后续串行代码。
    - **Области и синхронизация**: Программа делится на последовательные и параллельные области. При выходе из параллельной области происходит неявная синхронизация: мастер ожидает завершения остальных нитей, после чего только он продолжает выполнение.

--------------------------------------------------
二、 Ключевые конструкции и управление (核心结构与控制)
II. Ключевые конструкции и управление
--------------------------------------------------
**1. 定义并行区域 (Определение параллельной области):**
   - **基础指令对**: `!$OMP PARALLEL` 和 `!$OMP END PARALLEL` 之间的代码由多个线程并行执行。
        - **Базовая пара директив**: Код между `!$OMP PARALLEL` и `!$OMP END PARALLEL` выполняется параллельно несколькими нитями.
   - **条件并行**: 可使用 `IF(условие)` 子句动态决定是否创建并行区域。若条件为假，则区域由主线程串行执行。
        - **Условный параллелизм**: Опция `IF(условие)` позволяет динамически решать, создавать ли параллельную область. Если условие ложно, область выполняется мастером последовательно.

**2. 数据共享属性 (Атрибуты совместного использования данных):**
   - **共享变量 (SHARED)**: 全局唯一实例，所有线程通过同一名称访问和修改同一内存位置。
        - **Общие переменные (SHARED)**: Один экземпляр на всю программу, все нити обращаются к одной и той же ячейке памяти под одним именем.
   - **私有变量 (PRIVATE)**: 每个线程拥有该变量的独立副本，一个线程对其副本的修改不影响其他线程。
        - **Локальные переменные (PRIVATE)**: Для каждой нити создается свой экземпляр переменной; изменения одной нити не видны другим.

**3. 线程数量与动态控制 (Управление количеством нитей и динамическое поведение):**
   - **设置线程数**: 可通过环境变量 `OMP_NUM_THREADS` 或运行时函数 `OMP_SET_NUM_THREADS()` 设置。
        - **Установка числа нитей**: Задаётся переменной окружения `OMP_NUM_THREADS` или функцией `OMP_SET_NUM_THREADS()`.
   - **动态调整**: 若 `OMP_DYNAMIC` 设为 `TRUE` (或 1)，系统可动态调整实际创建的线程数。
        - **Динамическая регулировка**: Если `OMP_DYNAMIC` установлен в `TRUE` (или 1), система может динамически изменять фактическое число создаваемых нитей.

**4. 嵌套并行区域 (Вложенные параллельные области):**
   - **默认行为**: 嵌套的并行区域默认由遇到它的单个线程执行（不创建新线程）。
        - **Поведение по умолчанию**: Вложенная параллельная область по умолчанию выполняется одной встретившей её нитью (новые нити не создаются).
   - **启用嵌套并行**: 通过设置 `OMP_NESTED` 为 `TRUE` 或调用 `OMP_SET_NESTED()` 来启用真正的嵌套并行。
        - **Включение вложенного параллелизма**: Установка `OMP_NESTED` в `TRUE` или вызов `OMP_SET_NESTED()` позволяет включить настоящий параллелизм во вложенных областях.

--------------------------------------------------
**编程模型核心 / Ядро модели программирования**
--------------------------------------------------
OpenMP 采用 **“分叉-汇合” (fork-join) 模型**：程序从单线程开始，在并行区域**分叉**为多个线程，区域结束后**汇合**回单线程。其关键在于通过简单的指令将串行逻辑**增量式地**转化为并行执行，并管理数据的共享与私有化。
OpenMP использует модель **«fork-join»**: программа начинается с одной нити, в параллельных областях происходит **ветвление (fork)** на несколько нитей, а после их завершения — **объединение (join)** обратно в одну. Ключевая идея — **инкрементальное** преобразование последовательной логики в параллельную с помощью простых директив и управление разделяемым и приватным доступом к данным.



## 40. OpenMP: основные конструкции для распределения работы между нитями.
--------------------------------------------------
一、 循环迭代的分配  
I. Распределение итераций циклов  
--------------------------------------------------
- **核心指令**：`!$OMP DO` / `!$OMP END DO` 用于将循环的**迭代分配给多个线程执行**，避免每个线程执行全部迭代。  
  ‑ **Ключевая директива**: `!$OMP DO` / `!$OMP END DO` используется для **распределения итераций цикла по нитям**, чтобы каждая нить выполняла не все итерации.
- **调度策略**：通过 `SCHEDULE` 子句指定分配方式。
  - `STATIC [,m]`: **块循环分配**。每个线程依次获得大小为 `m` 的迭代块。默认 `m=1`。  
    ‑ `STATIC [,m]`: **Блочно-циклическое распределение**. Каждая нить получает блок из `m` итераций по порядку. По умолчанию `m=1`.
  - `DYNAMIC [,m]`: **动态分配**，使用固定大小的块（`m`）。线程完成当前块后，从剩余迭代中获取下一个块。  
    ‑ `DYNAMIC [,m]`: **Динамическое распределение** с фиксированным размером блока (`m`). Нить, завершив блок, получает следующий.
  - `GUIDED [,m]`: **引导式动态分配**，块大小逐渐减小，有助于更好平衡负载。  
    ‑ `GUIDED [,m]`: **Динамическое распределение блоками уменьшающегося размера** для лучшей балансировки.
  - `RUNTIME`: 运行时根据环境变量 `OMP_SCHEDULE` 的值决定调度策略。  
    ‑ `RUNTIME`: Способ выбирается во время работы в зависимости от переменной `OMP_SCHEDULE`.
- **隐式同步与消除**：并行循环末尾存在**隐式路障同步**。使用 `END DO NOWAIT` 子句可让先到达的线程继续执行，无需等待。  
  ‑ **Неявная синхронизация и её отмена**: В конце параллельного цикла есть **неявная барьерная синхронизация**. Ключ `END DO NOWAIT` позволяет нитям продолжать без ожидания.

--------------------------------------------------
二、 非循环工作分配的构造  
II. Конструкции для распределения нецикловой работы  
--------------------------------------------------
1.  **独立代码段并行**  
    1.  **Параллелизм независимых фрагментов кода**  
    - **指令**：`!$OMP SECTIONS` / `!$OMP END SECTIONS`。  
      ‑ **Директива**: `!$OMP SECTIONS` / `!$OMP END SECTIONS`.
    - **功能**：将**逻辑上独立的代码块**（`!$OMP SECTION` 标记）分配给不同线程**并行执行**。每个块由单个线程执行。  
      ‑ **Функция**: **Информационно независимые фрагменты кода** (обозначенные `!$OMP SECTION`) выполняются **параллельно разными нитями**. Каждый фрагмент выполняется одной нитью.

2.  **单线程执行段**  
    2.  **Участок кода для однократного выполнения**  
    - **指令**：`!$OMP SINGLE` / `!$OMP END SINGLE`。  
      ‑ **Директива**: `!$OMP SINGLE` / `!$OMP END SINGLE`.
    - **功能**：封装一段**只需执行一次**的代码（例如，初始化共享变量）。由**首个到达该点的线程**执行，其他线程可能等待（除非使用 `NOWAIT`）。  
      ‑ **Функция**: Обрамляет участок кода, который должен быть **выполнен только один раз** (напр., инициализация общих переменных). Выполняется **нитью, первой дошедшей до этой точки**.

--------------------------------------------------
核心要点总结 / Ключевые выводы  
--------------------------------------------------
OpenMP 工作分配的核心构造：  
1.  **`DO` 指令**：并行化循环，通过 `SCHEDULE` 精细控制迭代分配。  
2.  **`SECTIONS` 指令**：并行执行独立的代码段。  
3.  **`SINGLE` 指令**：确保代码段仅由单个线程执行一次。  

Основные конструкции OpenMP для распределения работы:  
1.  **Директива `DO`**: Параллелизация циклов, тонкое управление через `SCHEDULE`.  
2.  **Директива `SECTIONS`**: Параллельное выполнение независимых фрагментов кода.  
3.  **Директива `SINGLE`**: Гарантирует однократное выполнение участка кода одной нитью.



## 41. OpenMP: основные конструкции для синхронизации нитей и работы с общими и локальными данными.
--------------------------------------------------
一、 数据作用域：共享与私有  
I. Область видимости данных: общие и локальные переменные  
--------------------------------------------------
1. **共享变量 (Директива `SHARED`)**  
   ‑ 在并行区域内只有一个实例，所有线程通过同一个名称访问和修改它。  
   ‑ Существует в единственном экземпляре, доступна всем нитям под одним именем.  

2. **私有变量 (Директива `PRIVATE`)**  
   ‑ 每个线程都拥有该变量的一个独立副本，线程之间互不可见。  
   ‑ В каждой нити создаётся отдельный экземпляр переменной, доступный только этой нити.  

--------------------------------------------------
二、 线程同步构造  
II. Конструкции для синхронизации нитей  
--------------------------------------------------
1. **屏障 (Директива `BARRIER`)**  
   ‑ 所有线程执行至此指令时被阻塞，直到所有线程都到达该点，然后它们才能继续执行。  
   ‑ Все нити останавливаются и ждут, пока каждая нить не достигнет этой точки, после чего работа продолжается.  

2. **主线程区块 (Директивы `MASTER` / `END MASTER`)**  
   ‑ 仅由主线程（master thread）执行该代码块，其他线程直接跳过并继续执行后续语句。  
   ‑ Участок кода выполняется только нитью-мастером, остальные нити его пропускают.  

3. **临界区 (Директивы `CRITICAL` / `END CRITICAL`)**  
   ‑ 确保同一时刻只有一个线程能执行被保护的代码块。可以命名，未命名的所有临界区视为同一个。  
   ‑ Гарантирует, что в любой момент времени внутри секции находится не более одной нити. Может быть именованной.  

4. **原子操作 (Директива `ATOMIC`)**  
   ‑ 确保紧随其后的单个赋值语句（通常是更新共享变量，如 `SUM = SUM + Expr`）被不可分割地执行。  
   ‑ Гарантирует атомарное (неразрывное) выполнение идущего сразу за ней оператора присваивания.  

5. **内存一致性 (Директива `FLUSH`)**  
   ‑ 强制实现线程间内存视图的一致性：将寄存器中的变量值写回主存，使其他线程能见到更新。可以指定变量列表以减少开销。  
   ‑ Обеспечивает согласованный образ памяти: значения переменных из регистров записываются в основную память. Можно указать список переменных.  

--------------------------------------------------
核心用途 / Ключевое назначение  
--------------------------------------------------
**共享变量**用于线程间通信与结果累积；**私有变量**用于防止数据竞争。  
**同步构造**用于控制执行顺序、保护共享数据更新 (`CRITICAL`, `ATOMIC`) 以及协调线程进度 (`BARRIER`, `MASTER`)。  

**Общие переменные** используются для обмена данными между нитями; **локальные переменные** предотвращают гонки данных.  
**Синхронизация** управляет порядком выполнения, защищает обновление общих данных (`CRITICAL`, `ATOMIC`) и координирует прогресс нитей (`BARRIER`, `MASTER`).



## 42. Графовые модели программ, их взаимосвязь.
--------------------------------------------------
一、 Основные графовые модели, не зависящие от входных данных (与输入数据无关的基本图模型)
I. Основные графовые модели, не зависящие от входных данных
--------------------------------------------------
1. **Граф управления (управляющий граф) (控制流图):**
   - **Основа (基础)**: 基于操作关系（控制依赖），反映程序语句（转换器和识别器）之间可能的执行顺序。
        - **Основа**: Основан на операционной связи (управлении), отражает возможный порядок выполнения операторов программы (преобразователей и распознавателей).
   - **Построение (构建)**: 通过分析程序文本静态构建。顶点对应程序中的每个操作符，如果文本允许一个操作符紧接另一个执行，则用从前者指向后者的弧连接。
        - **Построение**: Строится статически на основе анализа текста программы. Вершины соответствуют операторам; дуга направлена от оператора-предшественника к последователю, если текст допускает их непосредственное выполнение друг за другом.
   - **Ключевое свойство (关键属性)**: **独立于输入数据**。对于特定程序，其控制流图是唯一且固定的。
        - **Ключевое свойство**: **Не зависит от входных данных**. Для данной программы граф управления единственен и фиксирован.

2. **Информационный граф (数据依赖图/信息流图):**
   - **Основа (基础)**: 基于信息关系（数据依赖），反映转换器（如赋值语句）之间潜在的数据流。
        - **Основа**: Основан на информационной связи (зависимости по данным), отражает потенциальный поток данных между преобразователями (напр., операторами присваивания).
   - **Построение (构建)**: 通过分析程序文本静态构建。顶点仅对应转换器。如果两个操作符的执行实例之间理论上可能存在数据传递（一个产生数据，另一个使用），则用弧连接。
        - **Построение**: Строится статически. Вершины соответствуют только преобразователям. Дуга проводится, если между какими-либо срабатываниями соответствующих операторов теоретически возможна передача данных (один производит данные, другой их потребляет).
   - **Ключевое свойство (关键属性)**: **独立于输入数据**。但可能包含在特定输入下不会实现的“冗余”弧。
        - **Ключевое свойство**: **Не зависит от входных данных**. Однако может содержать «лишние» дуги, которые не реализуются при конкретных входных данных.

--------------------------------------------------
二、 Основные графовые модели, зависящие от входных данных (истории) (依赖于输入数据的图模型（历史）)
II. Основные графовые модели, зависящие от входных данных (истории)
--------------------------------------------------
1. **Операционно-логическая история (操作逻辑历史):**
   - **Основа (基础)**: 基于操作关系（控制依赖），反映程序在**特定输入数据**下的**实际**执行轨迹。
        - **Основа**: Основана на операционной связи, отражает **фактическую** последовательность срабатываний всех операторов (и преобразователей, и распознавателей) при **конкретных** входных данных.
   - **Построение (构建)**: 通过跟踪运行时每个操作符的每次执行（实例）动态构建。顶点对应操作符的**执行实例**，弧表示实例间的实际控制转移。
        - **Построение**: Строится динамически путём отслеживания каждого срабатывания каждого оператора во время выполнения. Вершины соответствуют **экземплярам срабатываний** операторов, дуги — фактическим передачам управления между ними.
   - **Ключевое свойство (关键属性)**: **严重依赖于输入数据**。对于不同输入，顶点数量、每个操作符的实例数甚至出现的操作符集合都可能不同。图本质上是从起点到终点的一条路径。
        - **Ключевое свойство**: **Сильно зависит от входных данных**. Для разных данных могут различаться общее число вершин, количество экземпляров одного оператора и даже набор присутствующих операторов. Граф по сути представляет собой единственный путь от начальной до конечной вершины.

2. **История реализации (实现历史):**
   - **Основа (基础)**: 基于信息关系（数据依赖），反映程序在**特定输入数据**下**实际**发生的数据流。
        - **Основа**: Основана на информационной связи, отражает **фактический** поток данных между преобразователями при **конкретных** входных данных.
   - **Построение (构建)**: 通过跟踪运行时每个转换器操作的每次执行（实例）动态构建。顶点对应转换器的**执行实例**，弧表示实例间实际的数据传递。
        - **Построение**: Строится динамически путём отслеживания каждого срабатывания операторов-преобразователей. Вершины соответствуют **экземплярам срабатываний** преобразователей, дуги — фактическим передачам данных между ними.
   - **Ключевое свойство (关键属性)**: **严重依赖于输入数据**。是信息流图在特定输入下的一个具体子集或实例化，去除了未实现的“冗余”弧。
        - **Ключевое свойство**: **Сильно зависит от входных данных**. Является конкретным подграфом или реализацией информационного графа для заданных данных, где удалены нереализованные «лишние» дуги.

--------------------------------------------------
**Взаимосвязь моделей (模型间的相互关系)**
--------------------------------------------------
1. **Статические vs Динамические (静态 vs 动态)**: 控制流图和信息流图是**静态模型**，直接从程序文本推导，**不依赖**输入数据。操作逻辑历史和实现历史是**动态模型**（历史），描述程序在特定输入下的**实际**执行情况，**严重依赖**输入数据。
    - **Статические vs Динамические**: Граф управления и информационный граф — **статические модели**, выводятся из текста программы и **не зависят** от входных данных. Операционно-логическая история и история реализации — **динамические модели (истории)**, описывающие **фактическое** выполнение при конкретных данных и **сильно зависят** от них.

2. **Управление vs Информация (控制 vs 数据)**: 控制流图和操作逻辑历史关注**控制流**（操作的顺序）。信息流图和实现历史关注**数据流**（操作间的数据依赖）。
    - **Управление vs Информация**: Граф управления и операционно-логическая история фокусируются на **потоке управления** (порядке операций). Информационный граф и история реализации фокусируются на **потоке данных** (зависимостях по данным).

3. **Абстракция vs Конкретизация (抽象 vs 具体化)**: 对于给定的输入，**操作逻辑历史**是**控制流图**的一个具体路径（实例化）。同样，**实现历史**是**信息流图**的一个具体子图（实例化），仅包含实际发生的数据依赖。
    - **Абстракция vs Конкретизация**: Для заданных входных данных **операционно-логическая история** является конкретным путём (экземпляром) **графа управления**. Аналогично, **история реализации** является конкретным подграфом (экземпляром) **информационного графа**, содержащим только реализованные зависимости.

--------------------------------------------------
**Практическое значение (实际意义)**
--------------------------------------------------
- **Статические модели (静态模型)**: 广泛用于编译优化、程序分析和**识别潜在并行性**（例如，识别信息流图中独立的操作）。
    - **Статические модели**: Широко используются для оптимизации компилятором, анализа программ и **выявления потенциального параллелизма** (напр., нахождение независимых операций в информационном графе).

- **Динамические модели (动态模型)**: 更复杂，主要用于理论研究、性能分析和调试，以理解程序的实际运行时行为。
    - **Динамические модели**: Более сложны, в основном используются в теоретических исследованиях, анализе производительности и отладке для понимания фактического поведения программы во время выполнения.



## 43. Понятия информационной зависимости и информационной независимости: критерий эквивалентности преобразования программ, ресурс параллелизма программ и алгоритмов.
--------------------------------------------------
一、 Понятия информационной зависимости и информационной независимости (信息依赖与信息独立的概念)
I. Понятия информационной зависимости и информационной независимости
--------------------------------------------------
- **Информационная зависимость (信息依赖)**: 两个操作（通常是转换器/赋值语句）如果访问**同一个变量（内存单元）**，则它们之间存在依赖关系。这比严格的信息流（数据流）关系更宽泛，因为信息流要求一个操作产生数据，另一个操作消耗该数据，而依赖关系仅要求访问同一内存位置（可能包括读-写、写-读、写-写等情况）。
    - **Информационная зависимость**: Две операции (обычно преобразователи/операторы присваивания) называются зависимыми, если они обращаются к **одной и той же переменной (ячейке памяти)**. Это отношение шире, чем строгая информационная связь (поток данных), которая требует, чтобы одна операция производила данные, а другая их потребляла. Зависимость же требует лишь обращения к одному месту в памяти (может включать случаи read-write, write-read, write-write).

- **Информационная независимость (信息独立)**: 如果两个操作之间**不存在**信息依赖关系（即它们访问完全不同的变量集合），则它们是信息独立的。
    - **Информационная независимость**: Две операции **не являются** информационно зависимыми, если они обращаются к непересекающимся множествам переменных (разным ячейкам памяти).

- **Практическое значение (实际意义)**: 依赖关系比信息流关系更容易通过静态分析确定（只需检查变量名/地址），这催生了**依赖图**（графы зависимостей）模型，广泛应用于自动并行化、优化和程序分析。
    - **Практическое значение**: Установить факт зависимости статически проще, чем факт информационной связи (достаточно проверить имена/адреса переменных). Это привело к появлению моделей **графов зависимостей**, широко используемых для автоматического распараллеливания, оптимизации и анализа программ.

--------------------------------------------------
二、 Критерий эквивалентности и ресурс параллелизма (等价性准则与并行性资源)
II. Критерий эквививалентности и ресурс параллелизма
--------------------------------------------------
**1. Критерий эквивалентности преобразований программ (程序转换的等价性准则):**
   - **Основа (基础)**: **Сохранение информационных зависимостей (保持信息依赖)** 是程序转换保持语义等价（即程序计算结果不变）的**基本准则**。
        - **Основа**: **Сохранение информационных зависимостей** является **фундаментальным критерием** семантической эквивалентности преобразований программ (т.е. сохранения результатов вычислений).
   - **Принцип (原理)**: 任何有效的程序优化、重组或并行化转换**不得违反**原始程序中存在的依赖关系。改变存在依赖关系的操作的执行顺序可能导致结果错误。
        - **Принцип**: Любое корректное преобразование программы (оптимизация, реорганизация, распараллеливание) **не должно нарушать** существующие в исходной программе информационные зависимости. Изменение порядка выполнения зависимых операций может привести к неверным результатам.
   - **Пример (例子)**: 循环展开、指令调度、向量化等转换必须确保所有依赖关系（真依赖、反依赖、输出依赖）在转换后得到满足。
        - **Пример**: Преобразования, такие как развертка циклов, планирование инструкций, векторизация, должны гарантировать сохранение всех типов зависимостей (истинных, анти-, выходных).

**2. Ресурс параллелизма программ и алгоритмов (程序与算法的并行性资源):**
   - **Определение (定义)**: 程序的**并行性资源**由其中**信息独立的操作**的数量和结构决定。独立操作越多，潜在的可同时执行的计算就越多。
        - **Определение**: **Ресурс параллелизма** программы определяется количеством и структурой **информационно независимых операций** в ней. Чем больше независимых операций, тем больше вычислений потенциально может выполняться одновременно.
   - **Выявление параллелизма (并行性发掘)**: 分析依赖关系（构建依赖图）是识别并行性的核心。**信息独立的操作**可以分配到不同的处理器或线程上并行执行，而不需要同步（除非存在其他类型的依赖，如控制依赖）。
        - **Выявление параллелизма**: Анализ зависимостей (построение графа зависимостей) — ключ к выявлению параллелизма. **Информационно независимые операции** могут быть распределены по разным процессорам или потокам для параллельного выполнения без необходимости синхронизации (если нет других видов зависимостей, например, по управлению).
   - **Ограничивающий фактор (限制因素)**: 依赖关系（特别是循环携带的依赖）是限制并行性的主要因素。打破非必要的依赖（例如通过变量重命名、循环变换）可以增加独立操作的数量，从而挖掘更多并行性。
        - **Ограничивающий фактор**: Зависимости (особенно переносимые в циклах) являются основным ограничивающим фактором для параллелизма. Устранение излишних зависимостей (напр., переименованием переменных, преобразованием циклов) может увеличить количество независимых операций и раскрыть дополнительный параллелизм.

--------------------------------------------------
**Связь понятий и их фундаментальная роль (概念的相互联系及其基础性作用)**
--------------------------------------------------
**Информационная структура (信息结构)**（由依赖和独立关系构成）是程序与算法分析的基石。**Зависимость (依赖)** 定义了程序转换必须遵守的**等价性边界**，而**Независимость (独立)** 则指明了可被利用的**并行性潜力**。两者共同构成了理解、优化和并行化计算过程的理论基础。
**Информационная структура** (состоящая из отношений зависимости и независимости) является основой анализа программ и алгоритмов. **Зависимость** определяет **границы эквивалентности** для преобразований программ, а **независимость** указывает на **потенциал параллелизма**, который может быть использован. Вместе они формируют теоретическую основу для понимания, оптимизации и распараллеливания вычислительных процессов.



## 44. Граф алгоритма. Взаимосвязь графа алгоритма и графовых моделей программ.
--------------------------------------------------
一、 算法图的定义与构建  
I. Определение и построение графа алгоритма  
--------------------------------------------------
1.  **基本定义**  
    1.  **Базовое определение**
    - **算法图**是在给定输入数据下，算法实现的**信息依赖图**。顶点表示算法中的操作，有向边表示操作间的信息依赖关系（即一个操作为另一个提供参数）。  
      ‑ **Граф алгоритма** — это **граф информационной зависимости реализации алгоритма** при фиксированных входных данных. Вершины соответствуют операциям, дуги — информационным зависимостям (поставка аргумента).

2.  **构建方法与特性**  
    2.  **Метод построения и свойства**
    - **构建**：将每个操作一对一映射到顶点。若操作 `u` 为操作 `v` 提供参数，则添加从顶点 `u` 到 `v` 的有向边。相互独立的操作间无边连接。  
      ‑ **Построение**: Каждой операции ставится в соответствие вершина. Если операция `u` поставляет аргумент операции `v`, проводится дуга `u -> v`. Независимые операции не связываются.
    - **参数化特性**：算法图几乎总是**依赖于输入数据的参数化图**。即使没有条件语句，数组大小等参数也会影响顶点（操作）的数量和边的集合。  
      ‑ **Параметричность**: Граф алгоритма почти всегда **зависит от входных данных (параметров)**, влияющих на число вершин и дуг.
    - **确定性 vs 非确定性**：
      - **确定性算法/程序**（无条件语句）：在程序的所有操作与图的顶点之间存在**一一对应关系**。  
        ‑ **Детерминированный алгоритм/программа** (без условных операторов): существует **взаимно-однозначное соответствие** между всеми операциями и вершинами.
      - **非确定性算法/程序**（有条件语句）：对于每个具体的输入数据，只存在程序的**一个操作子集**与图的顶点一一对应。不同输入对应不同子集。  
        ‑ **Недетерминированный алгоритм/программа** (с условными операторами): при каждом наборе входных данных соответствие существует лишь между **подмножеством операций** и вершинами.

3.  **图论属性**  
    3.  **Теоретико-графовые свойства**
    - 算法图是一个**有向无环多重图**。无环性源于程序只进行显式计算，任何值都不能通过自身定义。多重性意味着两个顶点间可以有多条边（多个依赖）。  
      ‑ Граф алгоритма — это **ориентированный ациклический мультиграф**. Ацикличность следует из того, что величина не может определяться через саму себя.

--------------------------------------------------
二、 关键路径及其与程序图模型的关系  
II. Критический путь и взаимосвязь с графовыми моделями программ  
--------------------------------------------------
1.  **关键路径**  
    1.  **Критический путь**
    - **定义**：有向无环图中**长度最长的路径**。  
      ‑ **Определение**: путь **максимальной длины** в ориентированном ациклическом графе.
    - **顶点标记与层级关系**：对于有 `n` 个顶点的有向无环图，存在一个数 `s < n`，使得所有顶点可以用索引 `1, 2, ..., s` 标记，且若存在从索引为 `i` 的顶点到索引为 `j` 的顶点的边，则必有 `i < j`。这表明图可以拓扑排序。  
      ‑ **Разметка вершин и уровни**: Все вершины можно так пометить индексами, что если есть дуга из вершины с индексом `i` в вершину с индексом `j`, то `i < j`.
    - **关键路径长度的意义**：标记图所需的最小索引数比其关键路径的长度**大1**。关键路径长度是算法**理论最小执行时间**（在无限资源下）的下界，是分析算法并行潜力的关键指标。  
      ‑ **Значение длины критического пути**: Минимальное число индексов для разметки на 1 **больше длины критического пути**. Его длина — нижняя оценка **теоретического минимального времени выполнения** алгоритма.

2.  **与程序图模型的相互关系**  
    2.  **Взаимосвязь с графовыми моделями программ**
    - **作为基础模型**：算法图是基于**信息依赖关系**的程序图模型的核心实例，它直观地展现了操作间的偏序关系，是分析程序属性和进行转换（如并行化）的基础。  
      ‑ **Как базовая модель**: Граф алгоритма — ключевой экземпляр графовых моделей программ, основанных на **информационных зависимостях**. Он визуализирует частичный порядок операций.
    - **双向对应**：一方面，任何算法/程序（在固定输入下）都可以表示为有向无环图（算法图）。另一方面，任何给定的有向无环图都可以通过为每个顶点分配一个具有相应数量参数的操作，而被视为某个算法的图。  
      ‑ **Взаимное соответствие**: Любой алгоритм можно представить ориентированным ациклическим графом. И наоборот, любой такой граф можно рассматривать как граф некоторого алгоритма.
    - **分析中的角色**：在算法并行化中，一个重要的任务是**分析性地求取关键路径长度作为问题外部参数的函数**。即使对于简单（如线性）类算法，关键路径长度的函数类型也可能很复杂。  
      ‑ **Роль в анализе**: При распараллеливании важная задача — **аналитическое нахождение длины критического пути как функции параметров задачи**.

--------------------------------------------------
核心总结 / Ключевой вывод  
--------------------------------------------------
- **算法图**是程序/算法在固定输入下的**信息依赖结构**的直观、形式化表示，其核心是**有向无环图**。  
- **关键路径**是该图中**最长的依赖链**，决定了算法的**理论最小执行时间**，是评估并行潜力和进行调度的关键。  
- **相互关系**：算法图是连接程序文本与并行计算模型的桥梁，它将程序语义转化为可分析的图结构，而图论性质（如关键路径）则为程序转换和优化提供了理论基础和量化指标。  

- **Граф алгоритма** — это наглядное и формальное представление **структуры информационных зависимостей** программы/алгоритма, по своей природе являющееся **ориентированным ациклическим графом**.  
- **Критический путь** — это **самая длинная цепочка зависимостей** в графе, определяющая **теоретический минимум времени выполнения** и служащая ключевой метрикой для оценки параллелизма.  
- **Взаимосвязь**: Граф алгоритма служит мостом между текстом программы и моделями параллельных вычислений, преобразуя семантику в анализируемую структуру, свойства которой (как длина критического пути) дают основу для преобразований и оптимизаций.



## 45. Виды параллелизма: конечный, массовый, координатный, скошенный.
--------------------------------------------------
一、 并行性类型概述  
I. Обзор видов параллелизма  
--------------------------------------------------
1. **有限并行 (Конечный параллелизм)**  
   ‑ **定义**：程序中可并行执行的部分是**有限且固定的**。并行任务的数量通常由算法本身的结构决定，不随问题规模显著增加。  
   ‑ **特征**：并行性规模有限，通常对应于算法中的**特定阶段**或**独立子任务**，如并行执行两个独立的函数或循环。  
   ‑ **示例**：在图像处理中，同时但独立地对图像的R、G、B三个通道应用相同的滤镜。  

   Определение: Части программы, которые могут выполняться параллельно, являются **фиксированными и ограниченными по количеству**. Масштаб параллелизма обычно определяется структурой алгоритма, а не размером задачи.  
   ‑ Характеристика: Ограниченный масштаб параллелизма, часто соответствует **определённым этапам** алгоритма или **независимым подзадачам**.  
   ‑ Пример: Одновременное и независимое применение одного фильтра к каналам R, G и B изображения.  

2. **大规模并行 (Массовый параллелизм / Data Parallelism)**  
   ‑ **定义**：对**大量同质数据**（如大型数组）的每个元素或每组元素**同时执行相同的操作**。并行任务数量**正比于数据规模**。  
   ‑ **特征**：是SIMD（单指令多数据）架构的理想模型。任务高度同质，通信和同步模式通常规则且简单。  
   ‑ **示例**：向量处理器上的数组运算、GPU上的像素处理、对庞大数据集中的每个记录应用相同的转换规则。  

   Определение: **Одинаковая операция** одновременно применяется к **каждому элементу или группе элементов большого однородного набора данных** (например, массива). Количество параллельных задач пропорционально объёму данных.  
   ‑ Характеристика: Идеальная модель для архитектуры SIMD. Задачи однородны, коммуникационные паттерны обычно регулярны и просты.  
   ‑ Пример: Операции над массивами на векторных процессорах, обработка пикселей на GPU, применение одинакового правила преобразования к каждой записи в огромном наборе данных.  

--------------------------------------------------
二、 基于计算域分解的特殊并行类型  
II. Специальные виды параллелизма на основе декомпозиции вычислительной области  
--------------------------------------------------
3. **坐标并行 (Координатный параллелизм / Geometric Parallelism)**  
   ‑ **定义**：将计算域（如网格、图像、矩阵）按**坐标方向**（如行、列、块）分解为多个子区域，每个处理器负责一个子区域的计算。是**大规模并行**的一种具体实现方式。  
   ‑ **特征**：并行性直接来源于问题的**空间几何结构**。任务间通常需要交换相邻子区域边界的数据（“光环交换”）。  
   ‑ **示例**：在数值模拟中，将大型计算网格分割成多个子网格，分配给不同的处理器进行并行求解偏微分方程。  

   Определение: Вычислительная область (например, сетка, изображение, матрица) разбивается на подобласти по **координатным направлениям** (строки, столбцы, блоки), и каждый процессор отвечает за вычисления в своей подобласти. Это конкретная форма **массового параллелизма**.  
   ‑ Характеристика: Параллелизм напрямую проистекает из **пространственно-геометрической структуры** задачи. Требуется обмен данными на границах соседних подобластей ("обмен граничными слоями").  
   ‑ Пример: При численном моделировании большая расчётная сетка разбивается на подсетки, распределяемые по процессорам для параллельного решения уравнений в частных производных.  

4. **斜向并行 (Скошенный параллелизм / Pipeline / Wavefront Parallelism)**  
   ‑ **定义**：将计算过程组织为一系列**级联阶段**，数据流顺序通过这些阶段。不同数据元素（或任务）处于处理流程的**不同阶段**，从而形成**时间上的重叠执行**。  
   ‑ **特征**：并行性体现在**任务流水线**或计算沿对角线方向（如矩阵）推进的“波浪前沿”上。提高了整体吞吐量，但存在流水线启动和排空的延迟。  
   ‑ **示例**：1) **指令/算术流水线**：处理器内的功能单元流水线。2) **软件流水线**：处理图像或数据流的流水线阶段（读入、处理、写出）。3) **波浪前沿法**：并行处理上三角矩阵，计算沿反对角线方向推进。  

   Определение: Вычислительный процесс организуется в виде последовательности **каскадных стадий (ступеней)**, через которые поток данных проходит последовательно. Разные элементы данных (или задачи) находятся на **разных стадиях** обработки, создавая **временное перекрытие** выполнения.  
   ‑ Характеристика: Параллелизм проявляется в виде **конвейера задач** или "фронта волны", движущегося по диагонали (например, в матрице). Повышает общую пропускную способность, но вносит задержки заполнения и осушения конвейера.  
   ‑ Пример: 1) **Инструкционный/арифметический конвейер** в процессоре. 2) **Программный конвейер** обработки изображений (чтение, обработка, запись). 3) **Волновой фронт (wavefront)**: Параллельная обработка верхнетреугольной матрицы, где вычисления продвигаются по антидиагоналям.  

--------------------------------------------------
总结与关系 / Резюме и взаимосвязь  
--------------------------------------------------
**大规模并行**和**坐标并行**关注的是**空间维度**上同时处理大量数据元素。**斜向并行**关注的是**时间维度**上对任务流进行阶段化重叠执行。**有限并行**则是上述各种并行模式中规模受限或仅局部存在的特例。在实际复杂程序中，这些并行类型**常常结合使用**。  

**Массовый** и **координатный** параллелизм связаны с одновременной обработкой множества элементов данных в **пространственном измерении**. **Скошенный** параллелизм связан с наложением по времени стадий обработки потока задач. **Конечный** параллелизм представляет собой ограниченный по масштабу или локальный случай перечисленных видов. В реальных сложных программах эти виды параллелизма **часто комбинируются**.



## 46. Ярусно-параллельная форма графа алгоритма, высота, ширина. Каноническая ЯПФ. Высота ЯПФ и длина критического пути графа алгоритма.
--------------------------------------------------
一、 Ярусно-параллельная форма (ЯПФ): основные понятия высоты и ширины (层并行形式：高度与宽度的基本概念)
I. Ярусно-параллельная форма (ЯПФ): основные понятия высоты и ширины
--------------------------------------------------
- **Определение ЯПФ (层并行形式的定义)**: ЯПФ 是算法图的一种严格并行形式，其中每个顶点被赋予一个索引（层号），表示所有以该顶点结束的路径长度都小于该索引。存在一种形式，使得以索引 k 顶点结束的最大路径长度正好为 k-1。
    - **Определение ЯПФ**: ЯПФ — это строгая параллельная форма графа алгоритма, в которой каждой вершине присвоен индекс (номер яруса), означающий, что длины всех путей, оканчивающихся в этой вершине, меньше этого индекса. Существует форма, где максимальная длина пути, оканчивающегося в вершине с индексом k, равна k-1.

- **Высота и ширина ЯПФ (ЯПФ的高度与宽度)**:
    - **Высота (высота)**: 并行形式中的层数（即使用的最大索引）。对于给定图，其高度等于**关键路径长度 + 1**（因为索引数比关键路径长度多1）。
        - **Высота**: Число ярусов в параллельной форме (максимальный используемый индекс). Для заданного графа высота равна **длине критического пути + 1** (поскольку число индексов на 1 больше длины критического пути).
    - **Ширина (ширина)**: 所有层中的最大顶点数，即最大层宽。它表示并行执行时所需的最大处理器数量。
        - **Ширина**: Максимальное число вершин в ярусе (максимальная ширина яруса). Обозначает максимальное количество процессоров, необходимых для параллельного выполнения.
    - **Ширина яруса (层宽)**: 单个层中的顶点数量。
        - **Ширина яруса**: Количество вершин в отдельном ярусе.

--------------------------------------------------
二、 Каноническая ЯПФ и её связь с критическим путём (规范ЯПФ及其与关键路径的关系)
II. Каноническая ЯПФ и её связь с критическим путём
--------------------------------------------------
- **Каноническая ЯПФ (规范ЯПФ)**: 这是一种特殊的严格并行形式，其中**所有输入顶点都位于索引为1的第一层**。对于给定的算法图，其规范ЯПФ是**唯一**的。
    - **Каноническая ЯПФ**: Это особая строгая параллельная форма, в которой **все входные вершины находятся в ярусе с индексом 1 (первом ярусе)**. Для заданного графа каноническая ЯПФ **единственна**.

- **Свойства канонической ЯПФ (规范ЯПФ的性质)**:
    - **Максимальность (最大性)**: 所有规范ЯПФ都是**最大并行形式**，即具有**最小高度**（等于关键路径长度+1），并且在某种意义上，每个层中都包含了尽可能多的顶点。
        - **Максимальность**: Все канонические ЯПФ являются **максимальными параллельными формами**, то есть имеют **минимальную высоту** (равную длине критического пути + 1) и, в определенном смысле, содержат максимально возможное число вершин в ярусах.
    - **Связь высоты и критического пути (高度与关键路径的关系)**: 规范ЯПФ的**高度**直接由图的**关键路径长度**决定：**Высота = Длина критического пути + 1**。这体现了并行执行的最小时间步数。
        - **Связь высоты и критического пути**: **Высота** канонической ЯПФ напрямую определяется **длиной критического пути** графа: **Высота = Длина критического пути + 1**. Это отражает минимальное число временных шагов для параллельного выполнения.

--------------------------------------------------
**Итоговое соотношение (最终关系总结)**
--------------------------------------------------
对于任何算法图，其规范层并行形式（Каноническая ЯПФ）提供了最优的层划分：**高度最小（等于关键路径长度+1）**，且**宽度**定义了并行资源需求。高度决定了理论上的最短执行时间，而宽度则反映了并行所需的峰值计算资源。
Для любого графа алгоритма его каноническая ярусно-параллельная форма обеспечивает оптимальное разделение на ярусы: **минимальная высота (равная длине критического пути + 1)** и **ширина**, определяющая потребность в параллельных ресурсах. Высота задаёт теоретически минимальное время выполнения, а ширина отражает пиковую потребность в вычислительных ресурсах.



## 47. Зависимость степени параллелизма от формы записи алгоритма (на примере реализации метода Гаусса).
--------------------------------------------------
一、 基本高斯消元法及其并行性限制  
I. Классический метод Гаусса и его ограничения параллелизма  
--------------------------------------------------
1. **算法核心与顺序依赖**  
   ‑ 高斯消元法求解稠密线性方程组（Ax = b）主要包括两个阶段：**前向消元**（将矩阵A化为上三角矩阵）和**回代求解**。  
   ‑ **基本（ijk）循环形式**：最直观的写法使用三层嵌套循环。外层 `k` 循环遍历主元行（从0到n-2），中层 `i` 循环遍历被消元行（k+1到n-1），内层 `j` 循环更新行内元素（k到n）。  
   ‑ **关键依赖**：对第 `i` 行的更新 (`A[i][j] -= A[i][k] * A[k][j] / A[k][k]`) **必须在**主元行 `k` 处理完成后才能开始。这形成了严格的**顺序依赖链**，导致**关键路径长**，整体并行度低。  

   Алгоритм и последовательные зависимости  
   ‑ Метод Гаусса решения СЛАУ включает **прямой ход** (приведение матрицы к верхнетреугольному виду) и **обратный ход**.  
   ‑ **Базовая (ijk) форма записи**: Три вложенных цикла. Внешний `k` по ведущим строкам, средний `i` по обнуляемым строкам, внутренний `j` по элементам строки.  
   ‑ **Ключевая зависимость**: Обновление строки `i` (`A[i][j] -= A[i][k] * A[k][j] / A[k][k]`) может начаться **только после** обработки ведущей строки `k`. Это создает строгую **последовательную цепочку**, длинный **критический путь** и низкую общую степень параллелизма.  

2. **并行度变化特征**  
   ‑ **可向量化部分**：内层 `j` 循环（更新一行内的多个元素）是独立的，可以进行**向量化**或在一个处理器核上以SIMD方式执行。  
   ‑ **可并行化部分**：中层 `i` 循环（对不同行的更新）在给定主元行 `k` 后是**相互独立**的，可以实现**行级并行**（例如，将不同的 `i` 分配给不同的处理器）。  
   ‑ **根本瓶颈**：外层 `k` 循环是**严格顺序**的。随着计算推进，可并行处理的行数 (`n-k-1`) **不断减少**，导致并行度在消元过程中**线性下降**，负载不平衡。  

   Характеристики изменения степени параллелизма  
   ‑ **Векторизуемая часть**: Внутренний цикл `j` (обновление элементов строки) независим, допускает **векторизацию** (SIMD).  
   ‑ **Параллелизуемая часть**: Средний цикл `i` (обновление разных строк) после фиксации строки `k` становится **независимым**, допускает **параллелизм на уровне строк** (распределение разных `i` по разным процессорам).  
   ‑ **Фундаментальное узкое место**: Внешний цикл `k` **строго последователен**. Число параллельно обрабатываемых строк (`n-k-1`) **уменьшается** по ходу вычислений, что приводит к **линейному снижению** степени параллелизма и дисбалансу нагрузки.  

--------------------------------------------------
二、 通过改变算法表达形式提升并行度  
II. Повышение степени параллелизма за счёт изменения формы записи алгоритма  
--------------------------------------------------
1. **延迟归一化与计算重构**  
   ‑ **问题**：基本形式中，`A[i][j]` 的更新立即依赖于主元 `A[k][k]` 的倒数，这强化了 `k` 循环的顺序性。  
   ‑ **修改方法**：将计算拆分为两步：1) 计算行因子 `L[i][k] = A[i][k] / A[k][k]`；2) 更新 `A[i][j] -= L[i][k] * A[k][j]`。  
   ‑ **效果**：步骤1) 在得到 `A[k][k]` 后可以**并行计算**所有 `L[i][k]` (i>k)。这增加了可并行工作的比例，特别是当矩阵规模大时。  

   Отложенная нормировка и реструктуризация вычислений  
   ‑ **Проблема**: В базовой форме обновление `A[i][j]` напрямую зависит от обратного значения `A[k][k]`, что усиливает последовательность цикла `k`.  
   ‑ **Модификация**: Разделение на два шага: 1) Вычисление множителей `L[i][k] = A[i][k] / A[k][k]`; 2) Обновление `A[i][j] -= L[i][k] * A[k][j]`.  
   ‑ **Эффект**: Шаг 1) после получения `A[k][k]` позволяет **параллельно вычислить** все `L[i][k]` (i>k). Это увеличивает долю параллельной работы.  

2. **面向块分解的算法形式 (Блочный алгоритм)**  
   ‑ **核心思想**：将矩阵划分为 **B x B** 的子块（块大小适合缓存）。算法在**块级别**上重新组织。  
   ‑ **修改后的操作**：1) **分解主块**：对当前对角块进行顺序的LU分解（此部分顺序，但块很小）。2) **更新尾随子矩阵**：利用已分解的块，对右下方的子矩阵进行**矩阵-矩阵乘法**形式的更新，例如 `A22 = A22 - L21 * U12`。  
   ‑ **关键提升**：矩阵-矩阵乘法 (`GEMM`) 是高度并行且高度优化的运算（BLAS 3级运算），具有**O(n³)计算量和O(n²)通信量**，能极大利用处理器缓存和多个计算核心。这显著**缩短了关键路径**，提升了整体并行度和效率。  

   Блочная форма записи алгоритма  
   ‑ **Идея**: Разбиение матрицы на подблоки размера **B x B**. Алгоритм переформулируется на **уровне блоков**.  
   ‑ **Модифицированные операции**: 1) **Факторизация ведущего блока**: LU-факторизация текущего диагонального блока (последовательно, но блок мал). 2) **Обновление хвостовой подматрицы**: Обновление оставшейся подматрицы с использованием разложенного блока принимает форму **операции матричного умножения**, напр., `A22 = A22 - L21 * U12`.  
   ‑ **Ключевое улучшение**: Операция матричного умножения (`GEMM`) — высокопараллельная и высокооптимизированная (BLAS level 3), с **высоким отношением операций к обращениям к памяти (O(n³)/O(n²))**). Это позволяет максимально использовать кэш и многоядерность, **существенно сокращает критический путь** и повышает общую степень параллелизма и эффективность.  

--------------------------------------------------
核心结论 / Ключевой вывод  
--------------------------------------------------
算法的并行潜力不仅取决于其数学本质，更取决于其**具体的程序实现形式**。通过**重构计算顺序**（如延迟归一化）和**提升计算粒度**（如采用面向块的算法，将内层操作转化为矩阵乘法），可以**显著改变计算图的结构**，缩短关键路径，暴露更多独立任务，从而极大地提高高斯消元法的可扩展并行度。  

Параллельный потенциал алгоритма зависит не только от его математической сути, но и от **конкретной формы его программной записи**. **Реструктуризация порядка вычислений** (например, отложенная нормировка) и **увеличение гранулярности операций** (например, переход к блочному алгоритму, сводящему внутренние операции к матричным умножениям) позволяют **существенно изменить граф алгоритма**, сократить критический путь, выявить больше независимых задач и тем самым резко повысить степень параллелизма и масштабируемость метода Гаусса.
